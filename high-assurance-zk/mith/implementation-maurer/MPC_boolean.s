	.text
	.p2align	5
	.globl	_dispatch
	.globl	dispatch
	.globl	_out_end5
	.globl	out_end5
	.globl	_out_start5
	.globl	out_start5
	.globl	_mult_end5
	.globl	mult_end5
	.globl	_mult_start5
	.globl	mult_start5
	.globl	_Smult5
	.globl	Smult5
	.globl	_const_end5
	.globl	const_end5
	.globl	_const_start5
	.globl	const_start5
	.globl	_input_end5
	.globl	input_end5
	.globl	_input_start5
	.globl	input_start5
	.globl	_add5
	.globl	add5
_dispatch:
dispatch:
	movq	%rsp, %r10
	subq	$232, %rsp
	andq	$-32, %rsp
	movq	%rdi, 224(%rsp)
	movq	%rsi, 216(%rsp)
	movq	%rdx, 208(%rsp)
	movq	%rcx, 200(%rsp)
	movq	%r8, 192(%rsp)
	movq	224(%rsp), %rax
	addq	$48, %rax
	movq	216(%rsp), %rcx
	movq	(%rcx), %rdx
	movq	%rdx, (%rsp)
	movq	8(%rcx), %rdx
	movq	%rdx, 8(%rsp)
	movq	16(%rcx), %rdx
	movq	%rdx, 16(%rsp)
	movq	24(%rcx), %rdx
	movq	%rdx, 24(%rsp)
	movq	32(%rcx), %rdx
	movq	%rdx, 32(%rsp)
	movq	40(%rcx), %rdx
	movq	%rdx, 40(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rdx
	movq	%rdx, 24(%rcx)
	movq	32(%rax), %rdx
	movq	%rdx, 32(%rcx)
	movq	40(%rax), %rdx
	movq	%rdx, 40(%rcx)
	movq	(%rsp), %rcx
	movq	%rcx, (%rax)
	movq	8(%rsp), %rcx
	movq	%rcx, 8(%rax)
	movq	16(%rsp), %rcx
	movq	%rcx, 16(%rax)
	movq	24(%rsp), %rcx
	movq	%rcx, 24(%rax)
	movq	32(%rsp), %rcx
	movq	%rcx, 32(%rax)
	movq	40(%rsp), %rcx
	movq	%rcx, 40(%rax)
	movq	224(%rsp), %rax
	addq	$96, %rax
	movq	208(%rsp), %rcx
	movq	(%rcx), %rdx
	movq	%rdx, (%rsp)
	movq	8(%rcx), %rdx
	movq	%rdx, 8(%rsp)
	movq	16(%rcx), %rdx
	movq	%rdx, 16(%rsp)
	movq	24(%rcx), %rdx
	movq	%rdx, 24(%rsp)
	movq	32(%rcx), %rdx
	movq	%rdx, 32(%rsp)
	movq	40(%rcx), %rdx
	movq	%rdx, 40(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rdx
	movq	%rdx, 24(%rcx)
	movq	32(%rax), %rdx
	movq	%rdx, 32(%rcx)
	movq	40(%rax), %rdx
	movq	%rdx, 40(%rcx)
	movq	(%rsp), %rcx
	movq	%rcx, (%rax)
	movq	8(%rsp), %rcx
	movq	%rcx, 8(%rax)
	movq	16(%rsp), %rcx
	movq	%rcx, 16(%rax)
	movq	24(%rsp), %rcx
	movq	%rcx, 24(%rax)
	movq	32(%rsp), %rcx
	movq	%rcx, 32(%rax)
	movq	40(%rsp), %rcx
	movq	%rcx, 40(%rax)
	movq	224(%rsp), %rax
	addq	$144, %rax
	movq	200(%rsp), %rcx
	movq	(%rcx), %rdx
	movq	%rdx, (%rsp)
	movq	8(%rcx), %rdx
	movq	%rdx, 8(%rsp)
	movq	16(%rcx), %rdx
	movq	%rdx, 16(%rsp)
	movq	24(%rcx), %rdx
	movq	%rdx, 24(%rsp)
	movq	32(%rcx), %rdx
	movq	%rdx, 32(%rsp)
	movq	40(%rcx), %rdx
	movq	%rdx, 40(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rdx
	movq	%rdx, 24(%rcx)
	movq	32(%rax), %rdx
	movq	%rdx, 32(%rcx)
	movq	40(%rax), %rdx
	movq	%rdx, 40(%rcx)
	movq	(%rsp), %rcx
	movq	%rcx, (%rax)
	movq	8(%rsp), %rcx
	movq	%rcx, 8(%rax)
	movq	16(%rsp), %rcx
	movq	%rcx, 16(%rax)
	movq	24(%rsp), %rcx
	movq	%rcx, 24(%rax)
	movq	32(%rsp), %rcx
	movq	%rcx, 32(%rax)
	movq	40(%rsp), %rcx
	movq	%rcx, 40(%rax)
	movq	224(%rsp), %rax
	addq	$192, %rax
	movq	192(%rsp), %rcx
	movq	(%rcx), %rdx
	movq	%rdx, (%rsp)
	movq	8(%rcx), %rdx
	movq	%rdx, 8(%rsp)
	movq	16(%rcx), %rdx
	movq	%rdx, 16(%rsp)
	movq	24(%rcx), %rdx
	movq	%rdx, 24(%rsp)
	movq	32(%rcx), %rdx
	movq	%rdx, 32(%rsp)
	movq	40(%rcx), %rdx
	movq	%rdx, 40(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rdx
	movq	%rdx, 24(%rcx)
	movq	32(%rax), %rdx
	movq	%rdx, 32(%rcx)
	movq	40(%rax), %rdx
	movq	%rdx, 40(%rcx)
	movq	(%rsp), %rcx
	movq	%rcx, (%rax)
	movq	8(%rsp), %rcx
	movq	%rcx, 8(%rax)
	movq	16(%rsp), %rcx
	movq	%rcx, 16(%rax)
	movq	24(%rsp), %rcx
	movq	%rcx, 24(%rax)
	movq	32(%rsp), %rcx
	movq	%rcx, 32(%rax)
	movq	40(%rsp), %rcx
	movq	%rcx, 40(%rax)
	movq	216(%rsp), %rax
	addq	$96, %rax
	movq	208(%rsp), %rcx
	addq	$48, %rcx
	movq	(%rcx), %rdx
	movq	%rdx, (%rsp)
	movq	8(%rcx), %rdx
	movq	%rdx, 8(%rsp)
	movq	16(%rcx), %rdx
	movq	%rdx, 16(%rsp)
	movq	24(%rcx), %rdx
	movq	%rdx, 24(%rsp)
	movq	32(%rcx), %rdx
	movq	%rdx, 32(%rsp)
	movq	40(%rcx), %rdx
	movq	%rdx, 40(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rdx
	movq	%rdx, 24(%rcx)
	movq	32(%rax), %rdx
	movq	%rdx, 32(%rcx)
	movq	40(%rax), %rdx
	movq	%rdx, 40(%rcx)
	movq	(%rsp), %rcx
	movq	%rcx, (%rax)
	movq	8(%rsp), %rcx
	movq	%rcx, 8(%rax)
	movq	16(%rsp), %rcx
	movq	%rcx, 16(%rax)
	movq	24(%rsp), %rcx
	movq	%rcx, 24(%rax)
	movq	32(%rsp), %rcx
	movq	%rcx, 32(%rax)
	movq	40(%rsp), %rcx
	movq	%rcx, 40(%rax)
	movq	216(%rsp), %rax
	addq	$144, %rax
	movq	200(%rsp), %rcx
	addq	$48, %rcx
	movq	(%rcx), %rdx
	movq	%rdx, (%rsp)
	movq	8(%rcx), %rdx
	movq	%rdx, 8(%rsp)
	movq	16(%rcx), %rdx
	movq	%rdx, 16(%rsp)
	movq	24(%rcx), %rdx
	movq	%rdx, 24(%rsp)
	movq	32(%rcx), %rdx
	movq	%rdx, 32(%rsp)
	movq	40(%rcx), %rdx
	movq	%rdx, 40(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rdx
	movq	%rdx, 24(%rcx)
	movq	32(%rax), %rdx
	movq	%rdx, 32(%rcx)
	movq	40(%rax), %rdx
	movq	%rdx, 40(%rcx)
	movq	(%rsp), %rcx
	movq	%rcx, (%rax)
	movq	8(%rsp), %rcx
	movq	%rcx, 8(%rax)
	movq	16(%rsp), %rcx
	movq	%rcx, 16(%rax)
	movq	24(%rsp), %rcx
	movq	%rcx, 24(%rax)
	movq	32(%rsp), %rcx
	movq	%rcx, 32(%rax)
	movq	40(%rsp), %rcx
	movq	%rcx, 40(%rax)
	movq	216(%rsp), %rax
	addq	$192, %rax
	movq	192(%rsp), %rcx
	addq	$48, %rcx
	movq	(%rcx), %rdx
	movq	%rdx, (%rsp)
	movq	8(%rcx), %rdx
	movq	%rdx, 8(%rsp)
	movq	16(%rcx), %rdx
	movq	%rdx, 16(%rsp)
	movq	24(%rcx), %rdx
	movq	%rdx, 24(%rsp)
	movq	32(%rcx), %rdx
	movq	%rdx, 32(%rsp)
	movq	40(%rcx), %rdx
	movq	%rdx, 40(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rdx
	movq	%rdx, 24(%rcx)
	movq	32(%rax), %rdx
	movq	%rdx, 32(%rcx)
	movq	40(%rax), %rdx
	movq	%rdx, 40(%rcx)
	movq	(%rsp), %rcx
	movq	%rcx, (%rax)
	movq	8(%rsp), %rcx
	movq	%rcx, 8(%rax)
	movq	16(%rsp), %rcx
	movq	%rcx, 16(%rax)
	movq	24(%rsp), %rcx
	movq	%rcx, 24(%rax)
	movq	32(%rsp), %rcx
	movq	%rcx, 32(%rax)
	movq	40(%rsp), %rcx
	movq	%rcx, 40(%rax)
	movq	208(%rsp), %rax
	addq	$144, %rax
	movq	200(%rsp), %rcx
	addq	$96, %rcx
	movq	(%rcx), %rdx
	movq	%rdx, (%rsp)
	movq	8(%rcx), %rdx
	movq	%rdx, 8(%rsp)
	movq	16(%rcx), %rdx
	movq	%rdx, 16(%rsp)
	movq	24(%rcx), %rdx
	movq	%rdx, 24(%rsp)
	movq	32(%rcx), %rdx
	movq	%rdx, 32(%rsp)
	movq	40(%rcx), %rdx
	movq	%rdx, 40(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rdx
	movq	%rdx, 24(%rcx)
	movq	32(%rax), %rdx
	movq	%rdx, 32(%rcx)
	movq	40(%rax), %rdx
	movq	%rdx, 40(%rcx)
	movq	(%rsp), %rcx
	movq	%rcx, (%rax)
	movq	8(%rsp), %rcx
	movq	%rcx, 8(%rax)
	movq	16(%rsp), %rcx
	movq	%rcx, 16(%rax)
	movq	24(%rsp), %rcx
	movq	%rcx, 24(%rax)
	movq	32(%rsp), %rcx
	movq	%rcx, 32(%rax)
	movq	40(%rsp), %rcx
	movq	%rcx, 40(%rax)
	movq	208(%rsp), %rax
	addq	$192, %rax
	movq	192(%rsp), %rcx
	addq	$96, %rcx
	movq	(%rcx), %rdx
	movq	%rdx, (%rsp)
	movq	8(%rcx), %rdx
	movq	%rdx, 8(%rsp)
	movq	16(%rcx), %rdx
	movq	%rdx, 16(%rsp)
	movq	24(%rcx), %rdx
	movq	%rdx, 24(%rsp)
	movq	32(%rcx), %rdx
	movq	%rdx, 32(%rsp)
	movq	40(%rcx), %rdx
	movq	%rdx, 40(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rdx
	movq	%rdx, 24(%rcx)
	movq	32(%rax), %rdx
	movq	%rdx, 32(%rcx)
	movq	40(%rax), %rdx
	movq	%rdx, 40(%rcx)
	movq	(%rsp), %rcx
	movq	%rcx, (%rax)
	movq	8(%rsp), %rcx
	movq	%rcx, 8(%rax)
	movq	16(%rsp), %rcx
	movq	%rcx, 16(%rax)
	movq	24(%rsp), %rcx
	movq	%rcx, 24(%rax)
	movq	32(%rsp), %rcx
	movq	%rcx, 32(%rax)
	movq	40(%rsp), %rcx
	movq	%rcx, 40(%rax)
	movq	200(%rsp), %rax
	addq	$192, %rax
	movq	192(%rsp), %rcx
	addq	$144, %rcx
	movq	(%rcx), %rdx
	movq	%rdx, (%rsp)
	movq	8(%rcx), %rdx
	movq	%rdx, 8(%rsp)
	movq	16(%rcx), %rdx
	movq	%rdx, 16(%rsp)
	movq	24(%rcx), %rdx
	movq	%rdx, 24(%rsp)
	movq	32(%rcx), %rdx
	movq	%rdx, 32(%rsp)
	movq	40(%rcx), %rdx
	movq	%rdx, 40(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rdx
	movq	%rdx, 24(%rcx)
	movq	32(%rax), %rdx
	movq	%rdx, 32(%rcx)
	movq	40(%rax), %rdx
	movq	%rdx, 40(%rcx)
	movq	(%rsp), %rcx
	movq	%rcx, (%rax)
	movq	8(%rsp), %rcx
	movq	%rcx, 8(%rax)
	movq	16(%rsp), %rcx
	movq	%rcx, 16(%rax)
	movq	24(%rsp), %rcx
	movq	%rcx, 24(%rax)
	movq	32(%rsp), %rcx
	movq	%rcx, 32(%rax)
	movq	40(%rsp), %rcx
	movq	%rcx, 40(%rax)
	movq	%r10, %rsp
	ret 
_out_end5:
out_end5:
	movq	%rsp, %r10
	subq	$24, %rsp
	andq	$-32, %rsp
	movq	%rdi, 16(%rsp)
	movq	%rsi, (%rsp)
	movq	16(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, (%rsi)
	movq	16(%rsp), %rax
	addq	$8, %rax
	movq	%rax, 8(%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$16, %rax
	movq	%rax, 8(%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$24, %rax
	movq	%rax, 8(%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$32, %rax
	movq	%rax, 8(%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$40, %rax
	movq	%rax, 8(%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$48, %rax
	movq	%rax, 8(%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$48, %rax
	addq	$8, %rax
	movq	%rax, 8(%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$48, %rax
	addq	$24, %rax
	movq	%rax, 8(%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$96, %rax
	addq	$8, %rax
	movq	%rax, 16(%rsp)
	movq	16(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	%r10, %rsp
	ret 
_out_start5:
out_start5:
	imulq	$6, %rsi, %rax
	imulq	$8, %rax, %rax
	addq	%rax, %rdi
	movq	%rdx, %rax
	movq	(%rdi), %rcx
	movq	%rcx, (%rax)
	movq	8(%rdi), %rcx
	movq	%rcx, 8(%rax)
	movq	16(%rdi), %rcx
	movq	%rcx, 16(%rax)
	movq	24(%rdi), %rcx
	movq	%rcx, 24(%rax)
	movq	32(%rdi), %rcx
	movq	%rcx, 32(%rax)
	movq	40(%rdi), %rcx
	movq	%rcx, 40(%rax)
	movq	%rdx, %rax
	addq	$48, %rax
	movq	(%rdi), %rcx
	movq	%rcx, (%rax)
	movq	8(%rdi), %rcx
	movq	%rcx, 8(%rax)
	movq	16(%rdi), %rcx
	movq	%rcx, 16(%rax)
	movq	24(%rdi), %rcx
	movq	%rcx, 24(%rax)
	movq	32(%rdi), %rcx
	movq	%rcx, 32(%rax)
	movq	40(%rdi), %rcx
	movq	%rcx, 40(%rax)
	movq	%rdx, %rax
	addq	$96, %rax
	movq	(%rdi), %rcx
	movq	%rcx, (%rax)
	movq	8(%rdi), %rcx
	movq	%rcx, 8(%rax)
	movq	16(%rdi), %rcx
	movq	%rcx, 16(%rax)
	movq	24(%rdi), %rcx
	movq	%rcx, 24(%rax)
	movq	32(%rdi), %rcx
	movq	%rcx, 32(%rax)
	movq	40(%rdi), %rcx
	movq	%rcx, 40(%rax)
	movq	%rdx, %rax
	addq	$144, %rax
	movq	(%rdi), %rcx
	movq	%rcx, (%rax)
	movq	8(%rdi), %rcx
	movq	%rcx, 8(%rax)
	movq	16(%rdi), %rcx
	movq	%rcx, 16(%rax)
	movq	24(%rdi), %rcx
	movq	%rcx, 24(%rax)
	movq	32(%rdi), %rcx
	movq	%rcx, 32(%rax)
	movq	40(%rdi), %rcx
	movq	%rcx, 40(%rax)
	addq	$192, %rdx
	movq	(%rdi), %rax
	movq	%rax, (%rdx)
	movq	8(%rdi), %rax
	movq	%rax, 8(%rdx)
	movq	16(%rdi), %rax
	movq	%rax, 16(%rdx)
	movq	24(%rdi), %rax
	movq	%rax, 24(%rdx)
	movq	32(%rdi), %rax
	movq	%rax, 32(%rdx)
	movq	40(%rdi), %rax
	movq	%rax, 40(%rdx)
	ret 
_mult_end5:
mult_end5:
	movq	%rsp, %r10
	subq	$48, %rsp
	andq	$-32, %rsp
	movq	%rdx, 40(%rsp)
	imulq	$6, %rdx, %rax
	imulq	$8, %rax, %rax
	movq	%rdi, 32(%rsp)
	addq	%rax, %rsi
	movq	%rsi, 24(%rsp)
	movq	32(%rsp), %rax
	movq	%rax, 16(%rsp)
	movq	16(%rsp), %rax
	movq	24(%rsp), %rcx
	movq	(%rax), %rax
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$8, %rax
	movq	24(%rsp), %rcx
	addq	$8, %rcx
	movq	(%rax), %rax
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$16, %rax
	movq	24(%rsp), %rcx
	addq	$16, %rcx
	movq	(%rax), %rax
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$24, %rax
	movq	24(%rsp), %rcx
	addq	$24, %rcx
	movq	(%rax), %rax
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$32, %rax
	movq	24(%rsp), %rcx
	addq	$32, %rcx
	movq	(%rax), %rax
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$40, %rax
	movq	24(%rsp), %rcx
	addq	$40, %rcx
	movq	(%rax), %rax
	movq	%rax, (%rcx)
	movq	32(%rsp), %rax
	addq	$48, %rax
	movq	%rax, 16(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 8(%rsp)
	movq	24(%rsp), %rax
	movq	%rax, (%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$8, %rax
	movq	%rax, 8(%rsp)
	movq	24(%rsp), %rax
	addq	$8, %rax
	movq	%rax, (%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$16, %rax
	movq	%rax, 8(%rsp)
	movq	24(%rsp), %rax
	addq	$16, %rax
	movq	%rax, (%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$24, %rax
	movq	%rax, 8(%rsp)
	movq	24(%rsp), %rax
	addq	$24, %rax
	movq	%rax, (%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$32, %rax
	movq	%rax, 8(%rsp)
	movq	24(%rsp), %rax
	addq	$32, %rax
	movq	%rax, (%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$40, %rax
	movq	%rax, 16(%rsp)
	movq	24(%rsp), %rax
	addq	$40, %rax
	movq	%rax, 8(%rsp)
	movq	16(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	32(%rsp), %rax
	addq	$96, %rax
	movq	%rax, 16(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 8(%rsp)
	movq	24(%rsp), %rax
	movq	%rax, (%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$8, %rax
	movq	%rax, 8(%rsp)
	movq	24(%rsp), %rax
	addq	$8, %rax
	movq	%rax, (%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$16, %rax
	movq	%rax, 8(%rsp)
	movq	24(%rsp), %rax
	addq	$16, %rax
	movq	%rax, (%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$24, %rax
	movq	%rax, 8(%rsp)
	movq	24(%rsp), %rax
	addq	$24, %rax
	movq	%rax, (%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$32, %rax
	movq	%rax, 8(%rsp)
	movq	24(%rsp), %rax
	addq	$32, %rax
	movq	%rax, (%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$40, %rax
	movq	%rax, 16(%rsp)
	movq	24(%rsp), %rax
	addq	$40, %rax
	movq	%rax, 8(%rsp)
	movq	16(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	32(%rsp), %rax
	addq	$144, %rax
	movq	%rax, 16(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 8(%rsp)
	movq	24(%rsp), %rax
	movq	%rax, (%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$8, %rax
	movq	%rax, 8(%rsp)
	movq	24(%rsp), %rax
	addq	$8, %rax
	movq	%rax, (%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$16, %rax
	movq	%rax, 8(%rsp)
	movq	24(%rsp), %rax
	addq	$16, %rax
	movq	%rax, (%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$24, %rax
	movq	%rax, 8(%rsp)
	movq	24(%rsp), %rax
	addq	$24, %rax
	movq	%rax, (%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$32, %rax
	movq	%rax, 8(%rsp)
	movq	24(%rsp), %rax
	addq	$32, %rax
	movq	%rax, (%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$40, %rax
	movq	%rax, 16(%rsp)
	movq	24(%rsp), %rax
	addq	$40, %rax
	movq	%rax, 8(%rsp)
	movq	16(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	32(%rsp), %rax
	addq	$192, %rax
	movq	%rax, 32(%rsp)
	movq	32(%rsp), %rax
	movq	%rax, 16(%rsp)
	movq	24(%rsp), %rax
	movq	%rax, 8(%rsp)
	movq	16(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	32(%rsp), %rax
	addq	$8, %rax
	movq	%rax, 16(%rsp)
	movq	24(%rsp), %rax
	addq	$8, %rax
	movq	%rax, 8(%rsp)
	movq	16(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	32(%rsp), %rax
	addq	$16, %rax
	movq	%rax, 16(%rsp)
	movq	24(%rsp), %rax
	addq	$16, %rax
	movq	%rax, 8(%rsp)
	movq	16(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	32(%rsp), %rax
	addq	$24, %rax
	movq	%rax, 16(%rsp)
	movq	24(%rsp), %rax
	addq	$24, %rax
	movq	%rax, 8(%rsp)
	movq	16(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	32(%rsp), %rax
	addq	$32, %rax
	movq	%rax, 16(%rsp)
	movq	24(%rsp), %rax
	addq	$32, %rax
	movq	%rax, 8(%rsp)
	movq	16(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	32(%rsp), %rax
	addq	$40, %rax
	movq	%rax, 32(%rsp)
	movq	24(%rsp), %rax
	addq	$40, %rax
	movq	%rax, 24(%rsp)
	movq	32(%rsp), %rax
	movq	24(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	24(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	40(%rsp), %rax
	incq	%rax
	movq	%r10, %rsp
	ret 
_mult_start5:
mult_start5:
	movq	%rsp, %r10
	subq	$64, %rsp
	andq	$-32, %rsp
	movq	$0, (%rcx)
	movq	%r8, 56(%rsp)
	movq	%rcx, 32(%rsp)
	movq	%rdi, 24(%rsp)
	movq	%rsi, 8(%rsp)
	movq	%rdx, (%rsp)
	addq	$8, %rcx
	movq	%rcx, 16(%rsp)
	movq	8(%rsp), %rax
	imulq	$6, %rax, %rax
	imulq	$6, (%rsp), %rcx
	imulq	$8, %rax, %rax
	movq	24(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	24(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	movq	48(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	andq	%rcx, %rax
	movq	16(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	imulq	$6, %rax, %rax
	imulq	$6, (%rsp), %rcx
	incq	%rcx
	imulq	$8, %rax, %rax
	movq	24(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	24(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	movq	48(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	andq	%rcx, %rax
	movq	16(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	imulq	$6, %rax, %rax
	imulq	$6, (%rsp), %rcx
	addq	$2, %rcx
	imulq	$8, %rax, %rax
	movq	24(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	24(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	movq	48(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	andq	%rcx, %rax
	movq	16(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	imulq	$6, %rax, %rax
	imulq	$6, (%rsp), %rcx
	addq	$4, %rcx
	imulq	$8, %rax, %rax
	movq	24(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	24(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	movq	48(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	andq	%rcx, %rax
	movq	16(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	imulq	$6, %rax, %rax
	incq	%rax
	imulq	$6, (%rsp), %rcx
	addq	$3, %rcx
	imulq	$8, %rax, %rax
	movq	24(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	24(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	movq	48(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	andq	%rcx, %rax
	movq	16(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	imulq	$6, %rax, %rax
	incq	%rax
	imulq	$6, (%rsp), %rcx
	addq	$4, %rcx
	imulq	$8, %rax, %rax
	movq	24(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	24(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	movq	48(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	andq	%rcx, %rax
	movq	16(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	imulq	$6, %rax, %rax
	incq	%rax
	imulq	$6, (%rsp), %rcx
	addq	$5, %rcx
	imulq	$8, %rax, %rax
	movq	24(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	24(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	movq	48(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	andq	%rcx, %rax
	movq	16(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	imulq	$6, %rax, %rax
	addq	$2, %rax
	imulq	$6, (%rsp), %rcx
	imulq	$8, %rax, %rax
	movq	24(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	24(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	movq	48(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	andq	%rcx, %rax
	movq	16(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	imulq	$6, %rax, %rax
	addq	$2, %rax
	imulq	$6, (%rsp), %rcx
	addq	$2, %rcx
	imulq	$8, %rax, %rax
	movq	24(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	24(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	movq	48(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	andq	%rcx, %rax
	movq	16(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	imulq	$6, %rax, %rax
	addq	$2, %rax
	imulq	$6, (%rsp), %rcx
	addq	$3, %rcx
	imulq	$8, %rax, %rax
	movq	24(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	24(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	movq	48(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	andq	%rcx, %rax
	movq	16(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	imulq	$6, %rax, %rax
	addq	$2, %rax
	imulq	$6, (%rsp), %rcx
	addq	$4, %rcx
	imulq	$8, %rax, %rax
	movq	24(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	24(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	movq	48(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	andq	%rcx, %rax
	movq	16(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	imulq	$6, %rax, %rax
	addq	$3, %rax
	imulq	$6, (%rsp), %rcx
	imulq	$8, %rax, %rax
	movq	24(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	24(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	movq	48(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	andq	%rcx, %rax
	movq	16(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	imulq	$6, %rax, %rax
	addq	$3, %rax
	imulq	$6, (%rsp), %rcx
	incq	%rcx
	imulq	$8, %rax, %rax
	movq	24(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	24(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	movq	48(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	andq	%rcx, %rax
	movq	16(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	imulq	$6, %rax, %rax
	addq	$3, %rax
	imulq	$6, (%rsp), %rcx
	addq	$2, %rcx
	imulq	$8, %rax, %rax
	movq	24(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	24(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	movq	48(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	andq	%rcx, %rax
	movq	16(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	imulq	$6, %rax, %rax
	addq	$3, %rax
	imulq	$6, (%rsp), %rcx
	addq	$5, %rcx
	imulq	$8, %rax, %rax
	movq	24(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	24(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	movq	48(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	andq	%rcx, %rax
	movq	16(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	imulq	$6, %rax, %rax
	addq	$4, %rax
	imulq	$6, (%rsp), %rcx
	incq	%rcx
	imulq	$8, %rax, %rax
	movq	24(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	24(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	movq	48(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	andq	%rcx, %rax
	movq	16(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	imulq	$6, %rax, %rax
	addq	$4, %rax
	imulq	$6, (%rsp), %rcx
	addq	$2, %rcx
	imulq	$8, %rax, %rax
	movq	24(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	24(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	movq	48(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	andq	%rcx, %rax
	movq	16(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	imulq	$6, %rax, %rax
	addq	$4, %rax
	imulq	$6, (%rsp), %rcx
	addq	$3, %rcx
	imulq	$8, %rax, %rax
	movq	24(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	24(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	movq	48(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	andq	%rcx, %rax
	movq	16(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	imulq	$6, %rax, %rax
	addq	$5, %rax
	imulq	$6, (%rsp), %rcx
	imulq	$8, %rax, %rax
	movq	24(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	24(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	movq	48(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	andq	%rcx, %rax
	movq	16(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	imulq	$6, %rax, %rax
	addq	$5, %rax
	imulq	$6, (%rsp), %rcx
	addq	$3, %rcx
	imulq	$8, %rax, %rax
	movq	24(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	24(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	movq	48(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	andq	%rcx, %rax
	movq	16(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	32(%rsp), %rax
	movq	56(%rsp), %rcx
	movq	16(%rsp), %rdx
	movq	%rax, 24(%rsp)
	movq	(%rcx), %rax
	movq	%rax, (%rdx)
	movq	56(%rsp), %rax
	addq	$8, %rax
	movq	%rax, 48(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 40(%rsp)
	movq	48(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	40(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	56(%rsp), %rax
	addq	$16, %rax
	movq	%rax, 48(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 40(%rsp)
	movq	48(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	40(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	56(%rsp), %rax
	addq	$24, %rax
	movq	%rax, 48(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 40(%rsp)
	movq	48(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	40(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	56(%rsp), %rax
	addq	$32, %rax
	movq	%rax, 48(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 40(%rsp)
	movq	48(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	40(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	56(%rsp), %rax
	addq	$40, %rax
	movq	%rax, 48(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 40(%rsp)
	movq	48(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	40(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	56(%rsp), %rax
	addq	$48, %rax
	movq	%rax, 48(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 40(%rsp)
	movq	48(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	40(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	56(%rsp), %rax
	addq	$56, %rax
	movq	%rax, 48(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 40(%rsp)
	movq	48(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	40(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	56(%rsp), %rax
	addq	$64, %rax
	movq	%rax, 48(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 40(%rsp)
	movq	48(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	40(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	40(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	56(%rsp), %rax
	movq	%rax, %rcx
	movq	32(%rsp), %rdx
	addq	$40, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$16, %rdx
	addq	$64, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$56, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$32, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$48, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$8, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$16, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	addq	$8, %rdx
	movq	32(%rsp), %rcx
	addq	$8, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$24, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$64, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$56, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$48, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$16, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$40, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	addq	$8, %rdx
	movq	32(%rsp), %rcx
	addq	$8, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$24, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$24, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$64, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$32, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$48, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$8, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$56, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$32, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$8, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$16, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	addq	$8, %rdx
	addq	$40, %rax
	movq	(%rax), %rax
	movq	%rax, (%rdx)
	movq	%r10, %rsp
	ret 
_Smult5:
Smult5:
	movq	%rsp, %r10
	subq	$48, %rsp
	andq	$-32, %rsp
	movq	%rdi, 40(%rsp)
	movq	%rsi, 32(%rsp)
	movq	%rcx, 24(%rsp)
	imulq	$6, %rdx, %rax
	imulq	$8, %rax, %rax
	movq	40(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, (%rsp)
	movq	32(%rsp), %rax
	movq	24(%rsp), %rcx
	imulq	$6, %rax, %rax
	imulq	$6, %rcx, %rcx
	imulq	$8, %rax, %rax
	movq	40(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 16(%rsp)
	imulq	$8, %rcx, %rax
	movq	40(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 8(%rsp)
	movq	16(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	andq	%rcx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	32(%rsp), %rax
	movq	24(%rsp), %rcx
	imulq	$6, %rax, %rax
	incq	%rax
	imulq	$6, %rcx, %rcx
	incq	%rcx
	imulq	$8, %rax, %rax
	movq	40(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 16(%rsp)
	imulq	$8, %rcx, %rax
	movq	40(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 8(%rsp)
	movq	16(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	andq	%rcx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	32(%rsp), %rax
	movq	24(%rsp), %rcx
	imulq	$6, %rax, %rax
	addq	$2, %rax
	imulq	$6, %rcx, %rcx
	addq	$2, %rcx
	imulq	$8, %rax, %rax
	movq	40(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 16(%rsp)
	imulq	$8, %rcx, %rax
	movq	40(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 8(%rsp)
	movq	16(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	andq	%rcx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	32(%rsp), %rax
	movq	24(%rsp), %rcx
	imulq	$6, %rax, %rax
	addq	$3, %rax
	imulq	$6, %rcx, %rcx
	addq	$3, %rcx
	imulq	$8, %rax, %rax
	movq	40(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 8(%rsp)
	imulq	$8, %rcx, %rax
	movq	40(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 16(%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	andq	%rcx, %rax
	movq	16(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	32(%rsp), %rax
	movq	24(%rsp), %rcx
	imulq	$6, %rax, %rax
	addq	$4, %rax
	imulq	$6, %rcx, %rcx
	addq	$4, %rcx
	imulq	$8, %rax, %rax
	movq	40(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 16(%rsp)
	imulq	$8, %rcx, %rax
	movq	40(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 8(%rsp)
	movq	16(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	andq	%rcx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	32(%rsp), %rax
	movq	24(%rsp), %rcx
	imulq	$6, %rax, %rax
	addq	$5, %rax
	imulq	$6, %rcx, %rcx
	addq	$5, %rcx
	imulq	$8, %rax, %rax
	movq	40(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 32(%rsp)
	imulq	$8, %rcx, %rax
	movq	40(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	movq	32(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	andq	%rcx, %rax
	movq	40(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	incq	%rax
	movq	%r10, %rsp
	ret 
_const_end5:
const_end5:
	movq	%rdx, %rax
	imulq	$6, %rax, %rcx
	imulq	$8, %rcx, %rcx
	addq	%rcx, %rsi
	movq	(%rdi), %rcx
	movq	%rcx, (%rsi)
	movq	8(%rdi), %rcx
	movq	%rcx, 8(%rsi)
	movq	16(%rdi), %rcx
	movq	%rcx, 16(%rsi)
	movq	24(%rdi), %rcx
	movq	%rcx, 24(%rsi)
	movq	32(%rdi), %rcx
	movq	%rcx, 32(%rsi)
	movq	40(%rdi), %rcx
	movq	%rcx, 40(%rsi)
	incq	%rax
	ret 
_const_start5:
const_start5:
	movq	%rsp, %r10
	subq	$24, %rsp
	andq	$-32, %rsp
	movq	%rdi, 8(%rsp)
	movq	%rsi, 16(%rsp)
	movq	$0, (%rsi)
	addq	$16, %rsi
	movq	%rsi, (%rsp)
	movq	16(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	16(%rsp), %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	$0, (%rdx)
	addq	$8, %rdx
	addq	$8, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	$0, (%rdx)
	addq	$8, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	$0, (%rdx)
	addq	$8, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	addq	$8, %rdx
	movq	(%rax), %rax
	movq	%rax, (%rdx)
	movq	%r10, %rsp
	ret 
_input_end5:
input_end5:
	movq	%rdx, %rax
	imulq	$6, %rax, %rcx
	imulq	$8, %rcx, %rcx
	addq	%rcx, %rsi
	movq	(%rdi), %rcx
	movq	%rcx, (%rsi)
	movq	8(%rdi), %rcx
	movq	%rcx, 8(%rsi)
	movq	16(%rdi), %rcx
	movq	%rcx, 16(%rsi)
	movq	24(%rdi), %rcx
	movq	%rcx, 24(%rsi)
	movq	32(%rdi), %rcx
	movq	%rcx, 32(%rsi)
	movq	40(%rdi), %rcx
	movq	%rcx, 40(%rsi)
	incq	%rax
	ret 
_input_start5:
input_start5:
	movq	%rsp, %r10
	subq	$48, %rsp
	andq	$-32, %rsp
	movq	%rsi, 40(%rsp)
	addq	$8, %rsi
	movq	%rsi, 24(%rsp)
	movq	%rdx, 32(%rsp)
	movq	32(%rsp), %rax
	movq	24(%rsp), %rcx
	movq	%rdi, 16(%rsp)
	movq	(%rax), %rax
	movq	%rax, (%rcx)
	movq	32(%rsp), %rax
	addq	$8, %rax
	movq	%rax, 8(%rsp)
	movq	24(%rsp), %rax
	movq	%rax, (%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	32(%rsp), %rax
	addq	$16, %rax
	movq	%rax, 8(%rsp)
	movq	24(%rsp), %rax
	movq	%rax, (%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	32(%rsp), %rax
	addq	$24, %rax
	movq	%rax, 8(%rsp)
	movq	24(%rsp), %rax
	movq	%rax, (%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	32(%rsp), %rax
	addq	$32, %rax
	movq	%rax, 8(%rsp)
	movq	24(%rsp), %rax
	movq	%rax, (%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	32(%rsp), %rax
	addq	$40, %rax
	movq	%rax, 8(%rsp)
	movq	24(%rsp), %rax
	movq	%rax, (%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	32(%rsp), %rax
	addq	$48, %rax
	movq	%rax, 8(%rsp)
	movq	24(%rsp), %rax
	movq	%rax, (%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	32(%rsp), %rax
	addq	$56, %rax
	movq	%rax, 8(%rsp)
	movq	24(%rsp), %rax
	movq	%rax, (%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	32(%rsp), %rax
	addq	$64, %rax
	movq	%rax, 8(%rsp)
	movq	8(%rsp), %rax
	movq	24(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	24(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	movq	24(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	24(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	32(%rsp), %rax
	movq	%rax, %rcx
	movq	40(%rsp), %rdx
	addq	$40, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$16, %rdx
	addq	$64, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$56, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$32, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$48, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$8, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$16, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	addq	$8, %rdx
	movq	40(%rsp), %rcx
	addq	$8, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$24, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$64, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$56, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$48, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$16, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$40, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	addq	$8, %rdx
	movq	40(%rsp), %rcx
	addq	$8, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$24, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$24, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$64, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$32, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$48, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$8, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$56, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$32, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$8, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$16, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	addq	$8, %rdx
	addq	$40, %rax
	movq	(%rax), %rax
	movq	%rax, (%rdx)
	movq	%r10, %rsp
	ret 
_add5:
add5:
	movq	%rsp, %r10
	subq	$56, %rsp
	andq	$-32, %rsp
	movq	%rdi, 48(%rsp)
	movq	%rsi, 40(%rsp)
	movq	%rdx, 32(%rsp)
	movq	%rcx, 24(%rsp)
	movq	40(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	24(%rsp), %rdx
	imulq	$6, %rax, %rax
	imulq	$6, %rcx, %rcx
	imulq	$6, %rdx, %rdx
	imulq	$8, %rax, %rax
	movq	48(%rsp), %rsi
	addq	%rax, %rsi
	movq	%rsi, 16(%rsp)
	imulq	$8, %rcx, %rax
	movq	48(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 8(%rsp)
	imulq	$8, %rdx, %rax
	movq	48(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, (%rsp)
	movq	16(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	40(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	24(%rsp), %rdx
	imulq	$6, %rax, %rax
	incq	%rax
	imulq	$6, %rcx, %rcx
	incq	%rcx
	imulq	$6, %rdx, %rdx
	incq	%rdx
	imulq	$8, %rax, %rax
	movq	48(%rsp), %rsi
	addq	%rax, %rsi
	movq	%rsi, 16(%rsp)
	imulq	$8, %rcx, %rax
	movq	48(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 8(%rsp)
	imulq	$8, %rdx, %rax
	movq	48(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, (%rsp)
	movq	16(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	40(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	24(%rsp), %rdx
	imulq	$6, %rax, %rax
	addq	$2, %rax
	imulq	$6, %rcx, %rcx
	addq	$2, %rcx
	imulq	$6, %rdx, %rdx
	addq	$2, %rdx
	imulq	$8, %rax, %rax
	movq	48(%rsp), %rsi
	addq	%rax, %rsi
	movq	%rsi, 16(%rsp)
	imulq	$8, %rcx, %rax
	movq	48(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 8(%rsp)
	imulq	$8, %rdx, %rax
	movq	48(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, (%rsp)
	movq	16(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	40(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	24(%rsp), %rdx
	imulq	$6, %rax, %rax
	addq	$3, %rax
	imulq	$6, %rcx, %rcx
	addq	$3, %rcx
	imulq	$6, %rdx, %rdx
	addq	$3, %rdx
	imulq	$8, %rax, %rax
	movq	48(%rsp), %rsi
	addq	%rax, %rsi
	movq	%rsi, 16(%rsp)
	imulq	$8, %rcx, %rax
	movq	48(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 8(%rsp)
	imulq	$8, %rdx, %rax
	movq	48(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, (%rsp)
	movq	16(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	40(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	24(%rsp), %rdx
	imulq	$6, %rax, %rax
	addq	$4, %rax
	imulq	$6, %rcx, %rcx
	addq	$4, %rcx
	imulq	$6, %rdx, %rdx
	addq	$4, %rdx
	imulq	$8, %rax, %rax
	movq	48(%rsp), %rsi
	addq	%rax, %rsi
	movq	%rsi, 16(%rsp)
	imulq	$8, %rcx, %rax
	movq	48(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 8(%rsp)
	imulq	$8, %rdx, %rax
	movq	48(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, (%rsp)
	movq	16(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	40(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	24(%rsp), %rdx
	imulq	$6, %rax, %rax
	addq	$5, %rax
	imulq	$6, %rcx, %rcx
	addq	$5, %rcx
	imulq	$6, %rdx, %rdx
	addq	$5, %rdx
	imulq	$8, %rax, %rax
	movq	48(%rsp), %rsi
	addq	%rax, %rsi
	movq	%rsi, 40(%rsp)
	imulq	$8, %rcx, %rax
	movq	48(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 32(%rsp)
	imulq	$8, %rdx, %rax
	movq	48(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 48(%rsp)
	movq	40(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	xorq	%rcx, %rax
	movq	48(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	incq	%rax
	movq	%r10, %rsp
	ret 
