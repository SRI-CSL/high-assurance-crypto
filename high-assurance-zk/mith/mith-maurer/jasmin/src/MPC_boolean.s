	.text
	.p2align	5
	.globl	_dispatch
	.globl	dispatch
	.globl	_out_end5
	.globl	out_end5
	.globl	_out_start5
	.globl	out_start5
	.globl	_mult_end5
	.globl	mult_end5
	.globl	_mult_start5
	.globl	mult_start5
	.globl	_Smult5
	.globl	Smult5
	.globl	_const_end5
	.globl	const_end5
	.globl	_const_start5
	.globl	const_start5
	.globl	_input_end5
	.globl	input_end5
	.globl	_input_start5
	.globl	input_start5
	.globl	_add5
	.globl	add5
_dispatch:
dispatch:
	movq	%rsp, %r10
	leaq	-232(%rsp), %rsp
	andq	$-8, %rsp
	movq	%rdi, (%rsp)
	movq	%rsi, 8(%rsp)
	movq	%rdx, 16(%rsp)
	movq	%rcx, 24(%rsp)
	movq	%r8, 32(%rsp)
	movq	(%rsp), %rax
	addq	$192, %rax
	movq	8(%rsp), %rcx
	movq	(%rcx), %rdx
	movq	%rdx, 40(%rsp)
	movq	8(%rcx), %rdx
	movq	%rdx, 48(%rsp)
	movq	16(%rcx), %rdx
	movq	%rdx, 56(%rsp)
	movq	24(%rcx), %rdx
	movq	%rdx, 64(%rsp)
	movq	32(%rcx), %rdx
	movq	%rdx, 72(%rsp)
	movq	40(%rcx), %rdx
	movq	%rdx, 80(%rsp)
	movq	48(%rcx), %rdx
	movq	%rdx, 88(%rsp)
	movq	56(%rcx), %rdx
	movq	%rdx, 96(%rsp)
	movq	64(%rcx), %rdx
	movq	%rdx, 104(%rsp)
	movq	72(%rcx), %rdx
	movq	%rdx, 112(%rsp)
	movq	80(%rcx), %rdx
	movq	%rdx, 120(%rsp)
	movq	88(%rcx), %rdx
	movq	%rdx, 128(%rsp)
	movq	96(%rcx), %rdx
	movq	%rdx, 136(%rsp)
	movq	104(%rcx), %rdx
	movq	%rdx, 144(%rsp)
	movq	112(%rcx), %rdx
	movq	%rdx, 152(%rsp)
	movq	120(%rcx), %rdx
	movq	%rdx, 160(%rsp)
	movq	128(%rcx), %rdx
	movq	%rdx, 168(%rsp)
	movq	136(%rcx), %rdx
	movq	%rdx, 176(%rsp)
	movq	144(%rcx), %rdx
	movq	%rdx, 184(%rsp)
	movq	152(%rcx), %rdx
	movq	%rdx, 192(%rsp)
	movq	160(%rcx), %rdx
	movq	%rdx, 200(%rsp)
	movq	168(%rcx), %rdx
	movq	%rdx, 208(%rsp)
	movq	176(%rcx), %rdx
	movq	%rdx, 216(%rsp)
	movq	184(%rcx), %rdx
	movq	%rdx, 224(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rdx
	movq	%rdx, 24(%rcx)
	movq	32(%rax), %rdx
	movq	%rdx, 32(%rcx)
	movq	40(%rax), %rdx
	movq	%rdx, 40(%rcx)
	movq	48(%rax), %rdx
	movq	%rdx, 48(%rcx)
	movq	56(%rax), %rdx
	movq	%rdx, 56(%rcx)
	movq	64(%rax), %rdx
	movq	%rdx, 64(%rcx)
	movq	72(%rax), %rdx
	movq	%rdx, 72(%rcx)
	movq	80(%rax), %rdx
	movq	%rdx, 80(%rcx)
	movq	88(%rax), %rdx
	movq	%rdx, 88(%rcx)
	movq	96(%rax), %rdx
	movq	%rdx, 96(%rcx)
	movq	104(%rax), %rdx
	movq	%rdx, 104(%rcx)
	movq	112(%rax), %rdx
	movq	%rdx, 112(%rcx)
	movq	120(%rax), %rdx
	movq	%rdx, 120(%rcx)
	movq	128(%rax), %rdx
	movq	%rdx, 128(%rcx)
	movq	136(%rax), %rdx
	movq	%rdx, 136(%rcx)
	movq	144(%rax), %rdx
	movq	%rdx, 144(%rcx)
	movq	152(%rax), %rdx
	movq	%rdx, 152(%rcx)
	movq	160(%rax), %rdx
	movq	%rdx, 160(%rcx)
	movq	168(%rax), %rdx
	movq	%rdx, 168(%rcx)
	movq	176(%rax), %rdx
	movq	%rdx, 176(%rcx)
	movq	184(%rax), %rdx
	movq	%rdx, 184(%rcx)
	movq	40(%rsp), %rcx
	movq	%rcx, (%rax)
	movq	48(%rsp), %rcx
	movq	%rcx, 8(%rax)
	movq	56(%rsp), %rcx
	movq	%rcx, 16(%rax)
	movq	64(%rsp), %rcx
	movq	%rcx, 24(%rax)
	movq	72(%rsp), %rcx
	movq	%rcx, 32(%rax)
	movq	80(%rsp), %rcx
	movq	%rcx, 40(%rax)
	movq	88(%rsp), %rcx
	movq	%rcx, 48(%rax)
	movq	96(%rsp), %rcx
	movq	%rcx, 56(%rax)
	movq	104(%rsp), %rcx
	movq	%rcx, 64(%rax)
	movq	112(%rsp), %rcx
	movq	%rcx, 72(%rax)
	movq	120(%rsp), %rcx
	movq	%rcx, 80(%rax)
	movq	128(%rsp), %rcx
	movq	%rcx, 88(%rax)
	movq	136(%rsp), %rcx
	movq	%rcx, 96(%rax)
	movq	144(%rsp), %rcx
	movq	%rcx, 104(%rax)
	movq	152(%rsp), %rcx
	movq	%rcx, 112(%rax)
	movq	160(%rsp), %rcx
	movq	%rcx, 120(%rax)
	movq	168(%rsp), %rcx
	movq	%rcx, 128(%rax)
	movq	176(%rsp), %rcx
	movq	%rcx, 136(%rax)
	movq	184(%rsp), %rcx
	movq	%rcx, 144(%rax)
	movq	192(%rsp), %rcx
	movq	%rcx, 152(%rax)
	movq	200(%rsp), %rcx
	movq	%rcx, 160(%rax)
	movq	208(%rsp), %rcx
	movq	%rcx, 168(%rax)
	movq	216(%rsp), %rcx
	movq	%rcx, 176(%rax)
	movq	224(%rsp), %rcx
	movq	%rcx, 184(%rax)
	movq	(%rsp), %rax
	addq	$384, %rax
	movq	16(%rsp), %rcx
	movq	(%rcx), %rdx
	movq	%rdx, 40(%rsp)
	movq	8(%rcx), %rdx
	movq	%rdx, 48(%rsp)
	movq	16(%rcx), %rdx
	movq	%rdx, 56(%rsp)
	movq	24(%rcx), %rdx
	movq	%rdx, 64(%rsp)
	movq	32(%rcx), %rdx
	movq	%rdx, 72(%rsp)
	movq	40(%rcx), %rdx
	movq	%rdx, 80(%rsp)
	movq	48(%rcx), %rdx
	movq	%rdx, 88(%rsp)
	movq	56(%rcx), %rdx
	movq	%rdx, 96(%rsp)
	movq	64(%rcx), %rdx
	movq	%rdx, 104(%rsp)
	movq	72(%rcx), %rdx
	movq	%rdx, 112(%rsp)
	movq	80(%rcx), %rdx
	movq	%rdx, 120(%rsp)
	movq	88(%rcx), %rdx
	movq	%rdx, 128(%rsp)
	movq	96(%rcx), %rdx
	movq	%rdx, 136(%rsp)
	movq	104(%rcx), %rdx
	movq	%rdx, 144(%rsp)
	movq	112(%rcx), %rdx
	movq	%rdx, 152(%rsp)
	movq	120(%rcx), %rdx
	movq	%rdx, 160(%rsp)
	movq	128(%rcx), %rdx
	movq	%rdx, 168(%rsp)
	movq	136(%rcx), %rdx
	movq	%rdx, 176(%rsp)
	movq	144(%rcx), %rdx
	movq	%rdx, 184(%rsp)
	movq	152(%rcx), %rdx
	movq	%rdx, 192(%rsp)
	movq	160(%rcx), %rdx
	movq	%rdx, 200(%rsp)
	movq	168(%rcx), %rdx
	movq	%rdx, 208(%rsp)
	movq	176(%rcx), %rdx
	movq	%rdx, 216(%rsp)
	movq	184(%rcx), %rdx
	movq	%rdx, 224(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rdx
	movq	%rdx, 24(%rcx)
	movq	32(%rax), %rdx
	movq	%rdx, 32(%rcx)
	movq	40(%rax), %rdx
	movq	%rdx, 40(%rcx)
	movq	48(%rax), %rdx
	movq	%rdx, 48(%rcx)
	movq	56(%rax), %rdx
	movq	%rdx, 56(%rcx)
	movq	64(%rax), %rdx
	movq	%rdx, 64(%rcx)
	movq	72(%rax), %rdx
	movq	%rdx, 72(%rcx)
	movq	80(%rax), %rdx
	movq	%rdx, 80(%rcx)
	movq	88(%rax), %rdx
	movq	%rdx, 88(%rcx)
	movq	96(%rax), %rdx
	movq	%rdx, 96(%rcx)
	movq	104(%rax), %rdx
	movq	%rdx, 104(%rcx)
	movq	112(%rax), %rdx
	movq	%rdx, 112(%rcx)
	movq	120(%rax), %rdx
	movq	%rdx, 120(%rcx)
	movq	128(%rax), %rdx
	movq	%rdx, 128(%rcx)
	movq	136(%rax), %rdx
	movq	%rdx, 136(%rcx)
	movq	144(%rax), %rdx
	movq	%rdx, 144(%rcx)
	movq	152(%rax), %rdx
	movq	%rdx, 152(%rcx)
	movq	160(%rax), %rdx
	movq	%rdx, 160(%rcx)
	movq	168(%rax), %rdx
	movq	%rdx, 168(%rcx)
	movq	176(%rax), %rdx
	movq	%rdx, 176(%rcx)
	movq	184(%rax), %rdx
	movq	%rdx, 184(%rcx)
	movq	40(%rsp), %rcx
	movq	%rcx, (%rax)
	movq	48(%rsp), %rcx
	movq	%rcx, 8(%rax)
	movq	56(%rsp), %rcx
	movq	%rcx, 16(%rax)
	movq	64(%rsp), %rcx
	movq	%rcx, 24(%rax)
	movq	72(%rsp), %rcx
	movq	%rcx, 32(%rax)
	movq	80(%rsp), %rcx
	movq	%rcx, 40(%rax)
	movq	88(%rsp), %rcx
	movq	%rcx, 48(%rax)
	movq	96(%rsp), %rcx
	movq	%rcx, 56(%rax)
	movq	104(%rsp), %rcx
	movq	%rcx, 64(%rax)
	movq	112(%rsp), %rcx
	movq	%rcx, 72(%rax)
	movq	120(%rsp), %rcx
	movq	%rcx, 80(%rax)
	movq	128(%rsp), %rcx
	movq	%rcx, 88(%rax)
	movq	136(%rsp), %rcx
	movq	%rcx, 96(%rax)
	movq	144(%rsp), %rcx
	movq	%rcx, 104(%rax)
	movq	152(%rsp), %rcx
	movq	%rcx, 112(%rax)
	movq	160(%rsp), %rcx
	movq	%rcx, 120(%rax)
	movq	168(%rsp), %rcx
	movq	%rcx, 128(%rax)
	movq	176(%rsp), %rcx
	movq	%rcx, 136(%rax)
	movq	184(%rsp), %rcx
	movq	%rcx, 144(%rax)
	movq	192(%rsp), %rcx
	movq	%rcx, 152(%rax)
	movq	200(%rsp), %rcx
	movq	%rcx, 160(%rax)
	movq	208(%rsp), %rcx
	movq	%rcx, 168(%rax)
	movq	216(%rsp), %rcx
	movq	%rcx, 176(%rax)
	movq	224(%rsp), %rcx
	movq	%rcx, 184(%rax)
	movq	(%rsp), %rax
	addq	$576, %rax
	movq	24(%rsp), %rcx
	movq	(%rcx), %rdx
	movq	%rdx, 40(%rsp)
	movq	8(%rcx), %rdx
	movq	%rdx, 48(%rsp)
	movq	16(%rcx), %rdx
	movq	%rdx, 56(%rsp)
	movq	24(%rcx), %rdx
	movq	%rdx, 64(%rsp)
	movq	32(%rcx), %rdx
	movq	%rdx, 72(%rsp)
	movq	40(%rcx), %rdx
	movq	%rdx, 80(%rsp)
	movq	48(%rcx), %rdx
	movq	%rdx, 88(%rsp)
	movq	56(%rcx), %rdx
	movq	%rdx, 96(%rsp)
	movq	64(%rcx), %rdx
	movq	%rdx, 104(%rsp)
	movq	72(%rcx), %rdx
	movq	%rdx, 112(%rsp)
	movq	80(%rcx), %rdx
	movq	%rdx, 120(%rsp)
	movq	88(%rcx), %rdx
	movq	%rdx, 128(%rsp)
	movq	96(%rcx), %rdx
	movq	%rdx, 136(%rsp)
	movq	104(%rcx), %rdx
	movq	%rdx, 144(%rsp)
	movq	112(%rcx), %rdx
	movq	%rdx, 152(%rsp)
	movq	120(%rcx), %rdx
	movq	%rdx, 160(%rsp)
	movq	128(%rcx), %rdx
	movq	%rdx, 168(%rsp)
	movq	136(%rcx), %rdx
	movq	%rdx, 176(%rsp)
	movq	144(%rcx), %rdx
	movq	%rdx, 184(%rsp)
	movq	152(%rcx), %rdx
	movq	%rdx, 192(%rsp)
	movq	160(%rcx), %rdx
	movq	%rdx, 200(%rsp)
	movq	168(%rcx), %rdx
	movq	%rdx, 208(%rsp)
	movq	176(%rcx), %rdx
	movq	%rdx, 216(%rsp)
	movq	184(%rcx), %rdx
	movq	%rdx, 224(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rdx
	movq	%rdx, 24(%rcx)
	movq	32(%rax), %rdx
	movq	%rdx, 32(%rcx)
	movq	40(%rax), %rdx
	movq	%rdx, 40(%rcx)
	movq	48(%rax), %rdx
	movq	%rdx, 48(%rcx)
	movq	56(%rax), %rdx
	movq	%rdx, 56(%rcx)
	movq	64(%rax), %rdx
	movq	%rdx, 64(%rcx)
	movq	72(%rax), %rdx
	movq	%rdx, 72(%rcx)
	movq	80(%rax), %rdx
	movq	%rdx, 80(%rcx)
	movq	88(%rax), %rdx
	movq	%rdx, 88(%rcx)
	movq	96(%rax), %rdx
	movq	%rdx, 96(%rcx)
	movq	104(%rax), %rdx
	movq	%rdx, 104(%rcx)
	movq	112(%rax), %rdx
	movq	%rdx, 112(%rcx)
	movq	120(%rax), %rdx
	movq	%rdx, 120(%rcx)
	movq	128(%rax), %rdx
	movq	%rdx, 128(%rcx)
	movq	136(%rax), %rdx
	movq	%rdx, 136(%rcx)
	movq	144(%rax), %rdx
	movq	%rdx, 144(%rcx)
	movq	152(%rax), %rdx
	movq	%rdx, 152(%rcx)
	movq	160(%rax), %rdx
	movq	%rdx, 160(%rcx)
	movq	168(%rax), %rdx
	movq	%rdx, 168(%rcx)
	movq	176(%rax), %rdx
	movq	%rdx, 176(%rcx)
	movq	184(%rax), %rdx
	movq	%rdx, 184(%rcx)
	movq	40(%rsp), %rcx
	movq	%rcx, (%rax)
	movq	48(%rsp), %rcx
	movq	%rcx, 8(%rax)
	movq	56(%rsp), %rcx
	movq	%rcx, 16(%rax)
	movq	64(%rsp), %rcx
	movq	%rcx, 24(%rax)
	movq	72(%rsp), %rcx
	movq	%rcx, 32(%rax)
	movq	80(%rsp), %rcx
	movq	%rcx, 40(%rax)
	movq	88(%rsp), %rcx
	movq	%rcx, 48(%rax)
	movq	96(%rsp), %rcx
	movq	%rcx, 56(%rax)
	movq	104(%rsp), %rcx
	movq	%rcx, 64(%rax)
	movq	112(%rsp), %rcx
	movq	%rcx, 72(%rax)
	movq	120(%rsp), %rcx
	movq	%rcx, 80(%rax)
	movq	128(%rsp), %rcx
	movq	%rcx, 88(%rax)
	movq	136(%rsp), %rcx
	movq	%rcx, 96(%rax)
	movq	144(%rsp), %rcx
	movq	%rcx, 104(%rax)
	movq	152(%rsp), %rcx
	movq	%rcx, 112(%rax)
	movq	160(%rsp), %rcx
	movq	%rcx, 120(%rax)
	movq	168(%rsp), %rcx
	movq	%rcx, 128(%rax)
	movq	176(%rsp), %rcx
	movq	%rcx, 136(%rax)
	movq	184(%rsp), %rcx
	movq	%rcx, 144(%rax)
	movq	192(%rsp), %rcx
	movq	%rcx, 152(%rax)
	movq	200(%rsp), %rcx
	movq	%rcx, 160(%rax)
	movq	208(%rsp), %rcx
	movq	%rcx, 168(%rax)
	movq	216(%rsp), %rcx
	movq	%rcx, 176(%rax)
	movq	224(%rsp), %rcx
	movq	%rcx, 184(%rax)
	movq	(%rsp), %rax
	addq	$768, %rax
	movq	32(%rsp), %rcx
	movq	(%rcx), %rdx
	movq	%rdx, 40(%rsp)
	movq	8(%rcx), %rdx
	movq	%rdx, 48(%rsp)
	movq	16(%rcx), %rdx
	movq	%rdx, 56(%rsp)
	movq	24(%rcx), %rdx
	movq	%rdx, 64(%rsp)
	movq	32(%rcx), %rdx
	movq	%rdx, 72(%rsp)
	movq	40(%rcx), %rdx
	movq	%rdx, 80(%rsp)
	movq	48(%rcx), %rdx
	movq	%rdx, 88(%rsp)
	movq	56(%rcx), %rdx
	movq	%rdx, 96(%rsp)
	movq	64(%rcx), %rdx
	movq	%rdx, 104(%rsp)
	movq	72(%rcx), %rdx
	movq	%rdx, 112(%rsp)
	movq	80(%rcx), %rdx
	movq	%rdx, 120(%rsp)
	movq	88(%rcx), %rdx
	movq	%rdx, 128(%rsp)
	movq	96(%rcx), %rdx
	movq	%rdx, 136(%rsp)
	movq	104(%rcx), %rdx
	movq	%rdx, 144(%rsp)
	movq	112(%rcx), %rdx
	movq	%rdx, 152(%rsp)
	movq	120(%rcx), %rdx
	movq	%rdx, 160(%rsp)
	movq	128(%rcx), %rdx
	movq	%rdx, 168(%rsp)
	movq	136(%rcx), %rdx
	movq	%rdx, 176(%rsp)
	movq	144(%rcx), %rdx
	movq	%rdx, 184(%rsp)
	movq	152(%rcx), %rdx
	movq	%rdx, 192(%rsp)
	movq	160(%rcx), %rdx
	movq	%rdx, 200(%rsp)
	movq	168(%rcx), %rdx
	movq	%rdx, 208(%rsp)
	movq	176(%rcx), %rdx
	movq	%rdx, 216(%rsp)
	movq	184(%rcx), %rdx
	movq	%rdx, 224(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rdx
	movq	%rdx, 24(%rcx)
	movq	32(%rax), %rdx
	movq	%rdx, 32(%rcx)
	movq	40(%rax), %rdx
	movq	%rdx, 40(%rcx)
	movq	48(%rax), %rdx
	movq	%rdx, 48(%rcx)
	movq	56(%rax), %rdx
	movq	%rdx, 56(%rcx)
	movq	64(%rax), %rdx
	movq	%rdx, 64(%rcx)
	movq	72(%rax), %rdx
	movq	%rdx, 72(%rcx)
	movq	80(%rax), %rdx
	movq	%rdx, 80(%rcx)
	movq	88(%rax), %rdx
	movq	%rdx, 88(%rcx)
	movq	96(%rax), %rdx
	movq	%rdx, 96(%rcx)
	movq	104(%rax), %rdx
	movq	%rdx, 104(%rcx)
	movq	112(%rax), %rdx
	movq	%rdx, 112(%rcx)
	movq	120(%rax), %rdx
	movq	%rdx, 120(%rcx)
	movq	128(%rax), %rdx
	movq	%rdx, 128(%rcx)
	movq	136(%rax), %rdx
	movq	%rdx, 136(%rcx)
	movq	144(%rax), %rdx
	movq	%rdx, 144(%rcx)
	movq	152(%rax), %rdx
	movq	%rdx, 152(%rcx)
	movq	160(%rax), %rdx
	movq	%rdx, 160(%rcx)
	movq	168(%rax), %rdx
	movq	%rdx, 168(%rcx)
	movq	176(%rax), %rdx
	movq	%rdx, 176(%rcx)
	movq	184(%rax), %rdx
	movq	%rdx, 184(%rcx)
	movq	40(%rsp), %rcx
	movq	%rcx, (%rax)
	movq	48(%rsp), %rcx
	movq	%rcx, 8(%rax)
	movq	56(%rsp), %rcx
	movq	%rcx, 16(%rax)
	movq	64(%rsp), %rcx
	movq	%rcx, 24(%rax)
	movq	72(%rsp), %rcx
	movq	%rcx, 32(%rax)
	movq	80(%rsp), %rcx
	movq	%rcx, 40(%rax)
	movq	88(%rsp), %rcx
	movq	%rcx, 48(%rax)
	movq	96(%rsp), %rcx
	movq	%rcx, 56(%rax)
	movq	104(%rsp), %rcx
	movq	%rcx, 64(%rax)
	movq	112(%rsp), %rcx
	movq	%rcx, 72(%rax)
	movq	120(%rsp), %rcx
	movq	%rcx, 80(%rax)
	movq	128(%rsp), %rcx
	movq	%rcx, 88(%rax)
	movq	136(%rsp), %rcx
	movq	%rcx, 96(%rax)
	movq	144(%rsp), %rcx
	movq	%rcx, 104(%rax)
	movq	152(%rsp), %rcx
	movq	%rcx, 112(%rax)
	movq	160(%rsp), %rcx
	movq	%rcx, 120(%rax)
	movq	168(%rsp), %rcx
	movq	%rcx, 128(%rax)
	movq	176(%rsp), %rcx
	movq	%rcx, 136(%rax)
	movq	184(%rsp), %rcx
	movq	%rcx, 144(%rax)
	movq	192(%rsp), %rcx
	movq	%rcx, 152(%rax)
	movq	200(%rsp), %rcx
	movq	%rcx, 160(%rax)
	movq	208(%rsp), %rcx
	movq	%rcx, 168(%rax)
	movq	216(%rsp), %rcx
	movq	%rcx, 176(%rax)
	movq	224(%rsp), %rcx
	movq	%rcx, 184(%rax)
	movq	8(%rsp), %rax
	addq	$384, %rax
	movq	16(%rsp), %rcx
	addq	$192, %rcx
	movq	(%rcx), %rdx
	movq	%rdx, 40(%rsp)
	movq	8(%rcx), %rdx
	movq	%rdx, 48(%rsp)
	movq	16(%rcx), %rdx
	movq	%rdx, 56(%rsp)
	movq	24(%rcx), %rdx
	movq	%rdx, 64(%rsp)
	movq	32(%rcx), %rdx
	movq	%rdx, 72(%rsp)
	movq	40(%rcx), %rdx
	movq	%rdx, 80(%rsp)
	movq	48(%rcx), %rdx
	movq	%rdx, 88(%rsp)
	movq	56(%rcx), %rdx
	movq	%rdx, 96(%rsp)
	movq	64(%rcx), %rdx
	movq	%rdx, 104(%rsp)
	movq	72(%rcx), %rdx
	movq	%rdx, 112(%rsp)
	movq	80(%rcx), %rdx
	movq	%rdx, 120(%rsp)
	movq	88(%rcx), %rdx
	movq	%rdx, 128(%rsp)
	movq	96(%rcx), %rdx
	movq	%rdx, 136(%rsp)
	movq	104(%rcx), %rdx
	movq	%rdx, 144(%rsp)
	movq	112(%rcx), %rdx
	movq	%rdx, 152(%rsp)
	movq	120(%rcx), %rdx
	movq	%rdx, 160(%rsp)
	movq	128(%rcx), %rdx
	movq	%rdx, 168(%rsp)
	movq	136(%rcx), %rdx
	movq	%rdx, 176(%rsp)
	movq	144(%rcx), %rdx
	movq	%rdx, 184(%rsp)
	movq	152(%rcx), %rdx
	movq	%rdx, 192(%rsp)
	movq	160(%rcx), %rdx
	movq	%rdx, 200(%rsp)
	movq	168(%rcx), %rdx
	movq	%rdx, 208(%rsp)
	movq	176(%rcx), %rdx
	movq	%rdx, 216(%rsp)
	movq	184(%rcx), %rdx
	movq	%rdx, 224(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rdx
	movq	%rdx, 24(%rcx)
	movq	32(%rax), %rdx
	movq	%rdx, 32(%rcx)
	movq	40(%rax), %rdx
	movq	%rdx, 40(%rcx)
	movq	48(%rax), %rdx
	movq	%rdx, 48(%rcx)
	movq	56(%rax), %rdx
	movq	%rdx, 56(%rcx)
	movq	64(%rax), %rdx
	movq	%rdx, 64(%rcx)
	movq	72(%rax), %rdx
	movq	%rdx, 72(%rcx)
	movq	80(%rax), %rdx
	movq	%rdx, 80(%rcx)
	movq	88(%rax), %rdx
	movq	%rdx, 88(%rcx)
	movq	96(%rax), %rdx
	movq	%rdx, 96(%rcx)
	movq	104(%rax), %rdx
	movq	%rdx, 104(%rcx)
	movq	112(%rax), %rdx
	movq	%rdx, 112(%rcx)
	movq	120(%rax), %rdx
	movq	%rdx, 120(%rcx)
	movq	128(%rax), %rdx
	movq	%rdx, 128(%rcx)
	movq	136(%rax), %rdx
	movq	%rdx, 136(%rcx)
	movq	144(%rax), %rdx
	movq	%rdx, 144(%rcx)
	movq	152(%rax), %rdx
	movq	%rdx, 152(%rcx)
	movq	160(%rax), %rdx
	movq	%rdx, 160(%rcx)
	movq	168(%rax), %rdx
	movq	%rdx, 168(%rcx)
	movq	176(%rax), %rdx
	movq	%rdx, 176(%rcx)
	movq	184(%rax), %rdx
	movq	%rdx, 184(%rcx)
	movq	40(%rsp), %rcx
	movq	%rcx, (%rax)
	movq	48(%rsp), %rcx
	movq	%rcx, 8(%rax)
	movq	56(%rsp), %rcx
	movq	%rcx, 16(%rax)
	movq	64(%rsp), %rcx
	movq	%rcx, 24(%rax)
	movq	72(%rsp), %rcx
	movq	%rcx, 32(%rax)
	movq	80(%rsp), %rcx
	movq	%rcx, 40(%rax)
	movq	88(%rsp), %rcx
	movq	%rcx, 48(%rax)
	movq	96(%rsp), %rcx
	movq	%rcx, 56(%rax)
	movq	104(%rsp), %rcx
	movq	%rcx, 64(%rax)
	movq	112(%rsp), %rcx
	movq	%rcx, 72(%rax)
	movq	120(%rsp), %rcx
	movq	%rcx, 80(%rax)
	movq	128(%rsp), %rcx
	movq	%rcx, 88(%rax)
	movq	136(%rsp), %rcx
	movq	%rcx, 96(%rax)
	movq	144(%rsp), %rcx
	movq	%rcx, 104(%rax)
	movq	152(%rsp), %rcx
	movq	%rcx, 112(%rax)
	movq	160(%rsp), %rcx
	movq	%rcx, 120(%rax)
	movq	168(%rsp), %rcx
	movq	%rcx, 128(%rax)
	movq	176(%rsp), %rcx
	movq	%rcx, 136(%rax)
	movq	184(%rsp), %rcx
	movq	%rcx, 144(%rax)
	movq	192(%rsp), %rcx
	movq	%rcx, 152(%rax)
	movq	200(%rsp), %rcx
	movq	%rcx, 160(%rax)
	movq	208(%rsp), %rcx
	movq	%rcx, 168(%rax)
	movq	216(%rsp), %rcx
	movq	%rcx, 176(%rax)
	movq	224(%rsp), %rcx
	movq	%rcx, 184(%rax)
	movq	8(%rsp), %rax
	addq	$576, %rax
	movq	24(%rsp), %rcx
	addq	$192, %rcx
	movq	(%rcx), %rdx
	movq	%rdx, 40(%rsp)
	movq	8(%rcx), %rdx
	movq	%rdx, 48(%rsp)
	movq	16(%rcx), %rdx
	movq	%rdx, 56(%rsp)
	movq	24(%rcx), %rdx
	movq	%rdx, 64(%rsp)
	movq	32(%rcx), %rdx
	movq	%rdx, 72(%rsp)
	movq	40(%rcx), %rdx
	movq	%rdx, 80(%rsp)
	movq	48(%rcx), %rdx
	movq	%rdx, 88(%rsp)
	movq	56(%rcx), %rdx
	movq	%rdx, 96(%rsp)
	movq	64(%rcx), %rdx
	movq	%rdx, 104(%rsp)
	movq	72(%rcx), %rdx
	movq	%rdx, 112(%rsp)
	movq	80(%rcx), %rdx
	movq	%rdx, 120(%rsp)
	movq	88(%rcx), %rdx
	movq	%rdx, 128(%rsp)
	movq	96(%rcx), %rdx
	movq	%rdx, 136(%rsp)
	movq	104(%rcx), %rdx
	movq	%rdx, 144(%rsp)
	movq	112(%rcx), %rdx
	movq	%rdx, 152(%rsp)
	movq	120(%rcx), %rdx
	movq	%rdx, 160(%rsp)
	movq	128(%rcx), %rdx
	movq	%rdx, 168(%rsp)
	movq	136(%rcx), %rdx
	movq	%rdx, 176(%rsp)
	movq	144(%rcx), %rdx
	movq	%rdx, 184(%rsp)
	movq	152(%rcx), %rdx
	movq	%rdx, 192(%rsp)
	movq	160(%rcx), %rdx
	movq	%rdx, 200(%rsp)
	movq	168(%rcx), %rdx
	movq	%rdx, 208(%rsp)
	movq	176(%rcx), %rdx
	movq	%rdx, 216(%rsp)
	movq	184(%rcx), %rdx
	movq	%rdx, 224(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rdx
	movq	%rdx, 24(%rcx)
	movq	32(%rax), %rdx
	movq	%rdx, 32(%rcx)
	movq	40(%rax), %rdx
	movq	%rdx, 40(%rcx)
	movq	48(%rax), %rdx
	movq	%rdx, 48(%rcx)
	movq	56(%rax), %rdx
	movq	%rdx, 56(%rcx)
	movq	64(%rax), %rdx
	movq	%rdx, 64(%rcx)
	movq	72(%rax), %rdx
	movq	%rdx, 72(%rcx)
	movq	80(%rax), %rdx
	movq	%rdx, 80(%rcx)
	movq	88(%rax), %rdx
	movq	%rdx, 88(%rcx)
	movq	96(%rax), %rdx
	movq	%rdx, 96(%rcx)
	movq	104(%rax), %rdx
	movq	%rdx, 104(%rcx)
	movq	112(%rax), %rdx
	movq	%rdx, 112(%rcx)
	movq	120(%rax), %rdx
	movq	%rdx, 120(%rcx)
	movq	128(%rax), %rdx
	movq	%rdx, 128(%rcx)
	movq	136(%rax), %rdx
	movq	%rdx, 136(%rcx)
	movq	144(%rax), %rdx
	movq	%rdx, 144(%rcx)
	movq	152(%rax), %rdx
	movq	%rdx, 152(%rcx)
	movq	160(%rax), %rdx
	movq	%rdx, 160(%rcx)
	movq	168(%rax), %rdx
	movq	%rdx, 168(%rcx)
	movq	176(%rax), %rdx
	movq	%rdx, 176(%rcx)
	movq	184(%rax), %rdx
	movq	%rdx, 184(%rcx)
	movq	40(%rsp), %rcx
	movq	%rcx, (%rax)
	movq	48(%rsp), %rcx
	movq	%rcx, 8(%rax)
	movq	56(%rsp), %rcx
	movq	%rcx, 16(%rax)
	movq	64(%rsp), %rcx
	movq	%rcx, 24(%rax)
	movq	72(%rsp), %rcx
	movq	%rcx, 32(%rax)
	movq	80(%rsp), %rcx
	movq	%rcx, 40(%rax)
	movq	88(%rsp), %rcx
	movq	%rcx, 48(%rax)
	movq	96(%rsp), %rcx
	movq	%rcx, 56(%rax)
	movq	104(%rsp), %rcx
	movq	%rcx, 64(%rax)
	movq	112(%rsp), %rcx
	movq	%rcx, 72(%rax)
	movq	120(%rsp), %rcx
	movq	%rcx, 80(%rax)
	movq	128(%rsp), %rcx
	movq	%rcx, 88(%rax)
	movq	136(%rsp), %rcx
	movq	%rcx, 96(%rax)
	movq	144(%rsp), %rcx
	movq	%rcx, 104(%rax)
	movq	152(%rsp), %rcx
	movq	%rcx, 112(%rax)
	movq	160(%rsp), %rcx
	movq	%rcx, 120(%rax)
	movq	168(%rsp), %rcx
	movq	%rcx, 128(%rax)
	movq	176(%rsp), %rcx
	movq	%rcx, 136(%rax)
	movq	184(%rsp), %rcx
	movq	%rcx, 144(%rax)
	movq	192(%rsp), %rcx
	movq	%rcx, 152(%rax)
	movq	200(%rsp), %rcx
	movq	%rcx, 160(%rax)
	movq	208(%rsp), %rcx
	movq	%rcx, 168(%rax)
	movq	216(%rsp), %rcx
	movq	%rcx, 176(%rax)
	movq	224(%rsp), %rcx
	movq	%rcx, 184(%rax)
	movq	8(%rsp), %rax
	addq	$768, %rax
	movq	32(%rsp), %rcx
	addq	$192, %rcx
	movq	(%rcx), %rdx
	movq	%rdx, 40(%rsp)
	movq	8(%rcx), %rdx
	movq	%rdx, 48(%rsp)
	movq	16(%rcx), %rdx
	movq	%rdx, 56(%rsp)
	movq	24(%rcx), %rdx
	movq	%rdx, 64(%rsp)
	movq	32(%rcx), %rdx
	movq	%rdx, 72(%rsp)
	movq	40(%rcx), %rdx
	movq	%rdx, 80(%rsp)
	movq	48(%rcx), %rdx
	movq	%rdx, 88(%rsp)
	movq	56(%rcx), %rdx
	movq	%rdx, 96(%rsp)
	movq	64(%rcx), %rdx
	movq	%rdx, 104(%rsp)
	movq	72(%rcx), %rdx
	movq	%rdx, 112(%rsp)
	movq	80(%rcx), %rdx
	movq	%rdx, 120(%rsp)
	movq	88(%rcx), %rdx
	movq	%rdx, 128(%rsp)
	movq	96(%rcx), %rdx
	movq	%rdx, 136(%rsp)
	movq	104(%rcx), %rdx
	movq	%rdx, 144(%rsp)
	movq	112(%rcx), %rdx
	movq	%rdx, 152(%rsp)
	movq	120(%rcx), %rdx
	movq	%rdx, 160(%rsp)
	movq	128(%rcx), %rdx
	movq	%rdx, 168(%rsp)
	movq	136(%rcx), %rdx
	movq	%rdx, 176(%rsp)
	movq	144(%rcx), %rdx
	movq	%rdx, 184(%rsp)
	movq	152(%rcx), %rdx
	movq	%rdx, 192(%rsp)
	movq	160(%rcx), %rdx
	movq	%rdx, 200(%rsp)
	movq	168(%rcx), %rdx
	movq	%rdx, 208(%rsp)
	movq	176(%rcx), %rdx
	movq	%rdx, 216(%rsp)
	movq	184(%rcx), %rdx
	movq	%rdx, 224(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rdx
	movq	%rdx, 24(%rcx)
	movq	32(%rax), %rdx
	movq	%rdx, 32(%rcx)
	movq	40(%rax), %rdx
	movq	%rdx, 40(%rcx)
	movq	48(%rax), %rdx
	movq	%rdx, 48(%rcx)
	movq	56(%rax), %rdx
	movq	%rdx, 56(%rcx)
	movq	64(%rax), %rdx
	movq	%rdx, 64(%rcx)
	movq	72(%rax), %rdx
	movq	%rdx, 72(%rcx)
	movq	80(%rax), %rdx
	movq	%rdx, 80(%rcx)
	movq	88(%rax), %rdx
	movq	%rdx, 88(%rcx)
	movq	96(%rax), %rdx
	movq	%rdx, 96(%rcx)
	movq	104(%rax), %rdx
	movq	%rdx, 104(%rcx)
	movq	112(%rax), %rdx
	movq	%rdx, 112(%rcx)
	movq	120(%rax), %rdx
	movq	%rdx, 120(%rcx)
	movq	128(%rax), %rdx
	movq	%rdx, 128(%rcx)
	movq	136(%rax), %rdx
	movq	%rdx, 136(%rcx)
	movq	144(%rax), %rdx
	movq	%rdx, 144(%rcx)
	movq	152(%rax), %rdx
	movq	%rdx, 152(%rcx)
	movq	160(%rax), %rdx
	movq	%rdx, 160(%rcx)
	movq	168(%rax), %rdx
	movq	%rdx, 168(%rcx)
	movq	176(%rax), %rdx
	movq	%rdx, 176(%rcx)
	movq	184(%rax), %rdx
	movq	%rdx, 184(%rcx)
	movq	40(%rsp), %rcx
	movq	%rcx, (%rax)
	movq	48(%rsp), %rcx
	movq	%rcx, 8(%rax)
	movq	56(%rsp), %rcx
	movq	%rcx, 16(%rax)
	movq	64(%rsp), %rcx
	movq	%rcx, 24(%rax)
	movq	72(%rsp), %rcx
	movq	%rcx, 32(%rax)
	movq	80(%rsp), %rcx
	movq	%rcx, 40(%rax)
	movq	88(%rsp), %rcx
	movq	%rcx, 48(%rax)
	movq	96(%rsp), %rcx
	movq	%rcx, 56(%rax)
	movq	104(%rsp), %rcx
	movq	%rcx, 64(%rax)
	movq	112(%rsp), %rcx
	movq	%rcx, 72(%rax)
	movq	120(%rsp), %rcx
	movq	%rcx, 80(%rax)
	movq	128(%rsp), %rcx
	movq	%rcx, 88(%rax)
	movq	136(%rsp), %rcx
	movq	%rcx, 96(%rax)
	movq	144(%rsp), %rcx
	movq	%rcx, 104(%rax)
	movq	152(%rsp), %rcx
	movq	%rcx, 112(%rax)
	movq	160(%rsp), %rcx
	movq	%rcx, 120(%rax)
	movq	168(%rsp), %rcx
	movq	%rcx, 128(%rax)
	movq	176(%rsp), %rcx
	movq	%rcx, 136(%rax)
	movq	184(%rsp), %rcx
	movq	%rcx, 144(%rax)
	movq	192(%rsp), %rcx
	movq	%rcx, 152(%rax)
	movq	200(%rsp), %rcx
	movq	%rcx, 160(%rax)
	movq	208(%rsp), %rcx
	movq	%rcx, 168(%rax)
	movq	216(%rsp), %rcx
	movq	%rcx, 176(%rax)
	movq	224(%rsp), %rcx
	movq	%rcx, 184(%rax)
	movq	16(%rsp), %rax
	addq	$576, %rax
	movq	24(%rsp), %rcx
	addq	$384, %rcx
	movq	(%rcx), %rdx
	movq	%rdx, 40(%rsp)
	movq	8(%rcx), %rdx
	movq	%rdx, 48(%rsp)
	movq	16(%rcx), %rdx
	movq	%rdx, 56(%rsp)
	movq	24(%rcx), %rdx
	movq	%rdx, 64(%rsp)
	movq	32(%rcx), %rdx
	movq	%rdx, 72(%rsp)
	movq	40(%rcx), %rdx
	movq	%rdx, 80(%rsp)
	movq	48(%rcx), %rdx
	movq	%rdx, 88(%rsp)
	movq	56(%rcx), %rdx
	movq	%rdx, 96(%rsp)
	movq	64(%rcx), %rdx
	movq	%rdx, 104(%rsp)
	movq	72(%rcx), %rdx
	movq	%rdx, 112(%rsp)
	movq	80(%rcx), %rdx
	movq	%rdx, 120(%rsp)
	movq	88(%rcx), %rdx
	movq	%rdx, 128(%rsp)
	movq	96(%rcx), %rdx
	movq	%rdx, 136(%rsp)
	movq	104(%rcx), %rdx
	movq	%rdx, 144(%rsp)
	movq	112(%rcx), %rdx
	movq	%rdx, 152(%rsp)
	movq	120(%rcx), %rdx
	movq	%rdx, 160(%rsp)
	movq	128(%rcx), %rdx
	movq	%rdx, 168(%rsp)
	movq	136(%rcx), %rdx
	movq	%rdx, 176(%rsp)
	movq	144(%rcx), %rdx
	movq	%rdx, 184(%rsp)
	movq	152(%rcx), %rdx
	movq	%rdx, 192(%rsp)
	movq	160(%rcx), %rdx
	movq	%rdx, 200(%rsp)
	movq	168(%rcx), %rdx
	movq	%rdx, 208(%rsp)
	movq	176(%rcx), %rdx
	movq	%rdx, 216(%rsp)
	movq	184(%rcx), %rdx
	movq	%rdx, 224(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rdx
	movq	%rdx, 24(%rcx)
	movq	32(%rax), %rdx
	movq	%rdx, 32(%rcx)
	movq	40(%rax), %rdx
	movq	%rdx, 40(%rcx)
	movq	48(%rax), %rdx
	movq	%rdx, 48(%rcx)
	movq	56(%rax), %rdx
	movq	%rdx, 56(%rcx)
	movq	64(%rax), %rdx
	movq	%rdx, 64(%rcx)
	movq	72(%rax), %rdx
	movq	%rdx, 72(%rcx)
	movq	80(%rax), %rdx
	movq	%rdx, 80(%rcx)
	movq	88(%rax), %rdx
	movq	%rdx, 88(%rcx)
	movq	96(%rax), %rdx
	movq	%rdx, 96(%rcx)
	movq	104(%rax), %rdx
	movq	%rdx, 104(%rcx)
	movq	112(%rax), %rdx
	movq	%rdx, 112(%rcx)
	movq	120(%rax), %rdx
	movq	%rdx, 120(%rcx)
	movq	128(%rax), %rdx
	movq	%rdx, 128(%rcx)
	movq	136(%rax), %rdx
	movq	%rdx, 136(%rcx)
	movq	144(%rax), %rdx
	movq	%rdx, 144(%rcx)
	movq	152(%rax), %rdx
	movq	%rdx, 152(%rcx)
	movq	160(%rax), %rdx
	movq	%rdx, 160(%rcx)
	movq	168(%rax), %rdx
	movq	%rdx, 168(%rcx)
	movq	176(%rax), %rdx
	movq	%rdx, 176(%rcx)
	movq	184(%rax), %rdx
	movq	%rdx, 184(%rcx)
	movq	40(%rsp), %rcx
	movq	%rcx, (%rax)
	movq	48(%rsp), %rcx
	movq	%rcx, 8(%rax)
	movq	56(%rsp), %rcx
	movq	%rcx, 16(%rax)
	movq	64(%rsp), %rcx
	movq	%rcx, 24(%rax)
	movq	72(%rsp), %rcx
	movq	%rcx, 32(%rax)
	movq	80(%rsp), %rcx
	movq	%rcx, 40(%rax)
	movq	88(%rsp), %rcx
	movq	%rcx, 48(%rax)
	movq	96(%rsp), %rcx
	movq	%rcx, 56(%rax)
	movq	104(%rsp), %rcx
	movq	%rcx, 64(%rax)
	movq	112(%rsp), %rcx
	movq	%rcx, 72(%rax)
	movq	120(%rsp), %rcx
	movq	%rcx, 80(%rax)
	movq	128(%rsp), %rcx
	movq	%rcx, 88(%rax)
	movq	136(%rsp), %rcx
	movq	%rcx, 96(%rax)
	movq	144(%rsp), %rcx
	movq	%rcx, 104(%rax)
	movq	152(%rsp), %rcx
	movq	%rcx, 112(%rax)
	movq	160(%rsp), %rcx
	movq	%rcx, 120(%rax)
	movq	168(%rsp), %rcx
	movq	%rcx, 128(%rax)
	movq	176(%rsp), %rcx
	movq	%rcx, 136(%rax)
	movq	184(%rsp), %rcx
	movq	%rcx, 144(%rax)
	movq	192(%rsp), %rcx
	movq	%rcx, 152(%rax)
	movq	200(%rsp), %rcx
	movq	%rcx, 160(%rax)
	movq	208(%rsp), %rcx
	movq	%rcx, 168(%rax)
	movq	216(%rsp), %rcx
	movq	%rcx, 176(%rax)
	movq	224(%rsp), %rcx
	movq	%rcx, 184(%rax)
	movq	16(%rsp), %rax
	addq	$768, %rax
	movq	32(%rsp), %rcx
	addq	$384, %rcx
	movq	(%rcx), %rdx
	movq	%rdx, 40(%rsp)
	movq	8(%rcx), %rdx
	movq	%rdx, 48(%rsp)
	movq	16(%rcx), %rdx
	movq	%rdx, 56(%rsp)
	movq	24(%rcx), %rdx
	movq	%rdx, 64(%rsp)
	movq	32(%rcx), %rdx
	movq	%rdx, 72(%rsp)
	movq	40(%rcx), %rdx
	movq	%rdx, 80(%rsp)
	movq	48(%rcx), %rdx
	movq	%rdx, 88(%rsp)
	movq	56(%rcx), %rdx
	movq	%rdx, 96(%rsp)
	movq	64(%rcx), %rdx
	movq	%rdx, 104(%rsp)
	movq	72(%rcx), %rdx
	movq	%rdx, 112(%rsp)
	movq	80(%rcx), %rdx
	movq	%rdx, 120(%rsp)
	movq	88(%rcx), %rdx
	movq	%rdx, 128(%rsp)
	movq	96(%rcx), %rdx
	movq	%rdx, 136(%rsp)
	movq	104(%rcx), %rdx
	movq	%rdx, 144(%rsp)
	movq	112(%rcx), %rdx
	movq	%rdx, 152(%rsp)
	movq	120(%rcx), %rdx
	movq	%rdx, 160(%rsp)
	movq	128(%rcx), %rdx
	movq	%rdx, 168(%rsp)
	movq	136(%rcx), %rdx
	movq	%rdx, 176(%rsp)
	movq	144(%rcx), %rdx
	movq	%rdx, 184(%rsp)
	movq	152(%rcx), %rdx
	movq	%rdx, 192(%rsp)
	movq	160(%rcx), %rdx
	movq	%rdx, 200(%rsp)
	movq	168(%rcx), %rdx
	movq	%rdx, 208(%rsp)
	movq	176(%rcx), %rdx
	movq	%rdx, 216(%rsp)
	movq	184(%rcx), %rdx
	movq	%rdx, 224(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rdx
	movq	%rdx, 24(%rcx)
	movq	32(%rax), %rdx
	movq	%rdx, 32(%rcx)
	movq	40(%rax), %rdx
	movq	%rdx, 40(%rcx)
	movq	48(%rax), %rdx
	movq	%rdx, 48(%rcx)
	movq	56(%rax), %rdx
	movq	%rdx, 56(%rcx)
	movq	64(%rax), %rdx
	movq	%rdx, 64(%rcx)
	movq	72(%rax), %rdx
	movq	%rdx, 72(%rcx)
	movq	80(%rax), %rdx
	movq	%rdx, 80(%rcx)
	movq	88(%rax), %rdx
	movq	%rdx, 88(%rcx)
	movq	96(%rax), %rdx
	movq	%rdx, 96(%rcx)
	movq	104(%rax), %rdx
	movq	%rdx, 104(%rcx)
	movq	112(%rax), %rdx
	movq	%rdx, 112(%rcx)
	movq	120(%rax), %rdx
	movq	%rdx, 120(%rcx)
	movq	128(%rax), %rdx
	movq	%rdx, 128(%rcx)
	movq	136(%rax), %rdx
	movq	%rdx, 136(%rcx)
	movq	144(%rax), %rdx
	movq	%rdx, 144(%rcx)
	movq	152(%rax), %rdx
	movq	%rdx, 152(%rcx)
	movq	160(%rax), %rdx
	movq	%rdx, 160(%rcx)
	movq	168(%rax), %rdx
	movq	%rdx, 168(%rcx)
	movq	176(%rax), %rdx
	movq	%rdx, 176(%rcx)
	movq	184(%rax), %rdx
	movq	%rdx, 184(%rcx)
	movq	40(%rsp), %rcx
	movq	%rcx, (%rax)
	movq	48(%rsp), %rcx
	movq	%rcx, 8(%rax)
	movq	56(%rsp), %rcx
	movq	%rcx, 16(%rax)
	movq	64(%rsp), %rcx
	movq	%rcx, 24(%rax)
	movq	72(%rsp), %rcx
	movq	%rcx, 32(%rax)
	movq	80(%rsp), %rcx
	movq	%rcx, 40(%rax)
	movq	88(%rsp), %rcx
	movq	%rcx, 48(%rax)
	movq	96(%rsp), %rcx
	movq	%rcx, 56(%rax)
	movq	104(%rsp), %rcx
	movq	%rcx, 64(%rax)
	movq	112(%rsp), %rcx
	movq	%rcx, 72(%rax)
	movq	120(%rsp), %rcx
	movq	%rcx, 80(%rax)
	movq	128(%rsp), %rcx
	movq	%rcx, 88(%rax)
	movq	136(%rsp), %rcx
	movq	%rcx, 96(%rax)
	movq	144(%rsp), %rcx
	movq	%rcx, 104(%rax)
	movq	152(%rsp), %rcx
	movq	%rcx, 112(%rax)
	movq	160(%rsp), %rcx
	movq	%rcx, 120(%rax)
	movq	168(%rsp), %rcx
	movq	%rcx, 128(%rax)
	movq	176(%rsp), %rcx
	movq	%rcx, 136(%rax)
	movq	184(%rsp), %rcx
	movq	%rcx, 144(%rax)
	movq	192(%rsp), %rcx
	movq	%rcx, 152(%rax)
	movq	200(%rsp), %rcx
	movq	%rcx, 160(%rax)
	movq	208(%rsp), %rcx
	movq	%rcx, 168(%rax)
	movq	216(%rsp), %rcx
	movq	%rcx, 176(%rax)
	movq	224(%rsp), %rcx
	movq	%rcx, 184(%rax)
	movq	24(%rsp), %rax
	addq	$768, %rax
	movq	32(%rsp), %rcx
	addq	$576, %rcx
	movq	(%rcx), %rdx
	movq	%rdx, 40(%rsp)
	movq	8(%rcx), %rdx
	movq	%rdx, 48(%rsp)
	movq	16(%rcx), %rdx
	movq	%rdx, 56(%rsp)
	movq	24(%rcx), %rdx
	movq	%rdx, 64(%rsp)
	movq	32(%rcx), %rdx
	movq	%rdx, 72(%rsp)
	movq	40(%rcx), %rdx
	movq	%rdx, 80(%rsp)
	movq	48(%rcx), %rdx
	movq	%rdx, 88(%rsp)
	movq	56(%rcx), %rdx
	movq	%rdx, 96(%rsp)
	movq	64(%rcx), %rdx
	movq	%rdx, 104(%rsp)
	movq	72(%rcx), %rdx
	movq	%rdx, 112(%rsp)
	movq	80(%rcx), %rdx
	movq	%rdx, 120(%rsp)
	movq	88(%rcx), %rdx
	movq	%rdx, 128(%rsp)
	movq	96(%rcx), %rdx
	movq	%rdx, 136(%rsp)
	movq	104(%rcx), %rdx
	movq	%rdx, 144(%rsp)
	movq	112(%rcx), %rdx
	movq	%rdx, 152(%rsp)
	movq	120(%rcx), %rdx
	movq	%rdx, 160(%rsp)
	movq	128(%rcx), %rdx
	movq	%rdx, 168(%rsp)
	movq	136(%rcx), %rdx
	movq	%rdx, 176(%rsp)
	movq	144(%rcx), %rdx
	movq	%rdx, 184(%rsp)
	movq	152(%rcx), %rdx
	movq	%rdx, 192(%rsp)
	movq	160(%rcx), %rdx
	movq	%rdx, 200(%rsp)
	movq	168(%rcx), %rdx
	movq	%rdx, 208(%rsp)
	movq	176(%rcx), %rdx
	movq	%rdx, 216(%rsp)
	movq	184(%rcx), %rdx
	movq	%rdx, 224(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rdx
	movq	%rdx, 24(%rcx)
	movq	32(%rax), %rdx
	movq	%rdx, 32(%rcx)
	movq	40(%rax), %rdx
	movq	%rdx, 40(%rcx)
	movq	48(%rax), %rdx
	movq	%rdx, 48(%rcx)
	movq	56(%rax), %rdx
	movq	%rdx, 56(%rcx)
	movq	64(%rax), %rdx
	movq	%rdx, 64(%rcx)
	movq	72(%rax), %rdx
	movq	%rdx, 72(%rcx)
	movq	80(%rax), %rdx
	movq	%rdx, 80(%rcx)
	movq	88(%rax), %rdx
	movq	%rdx, 88(%rcx)
	movq	96(%rax), %rdx
	movq	%rdx, 96(%rcx)
	movq	104(%rax), %rdx
	movq	%rdx, 104(%rcx)
	movq	112(%rax), %rdx
	movq	%rdx, 112(%rcx)
	movq	120(%rax), %rdx
	movq	%rdx, 120(%rcx)
	movq	128(%rax), %rdx
	movq	%rdx, 128(%rcx)
	movq	136(%rax), %rdx
	movq	%rdx, 136(%rcx)
	movq	144(%rax), %rdx
	movq	%rdx, 144(%rcx)
	movq	152(%rax), %rdx
	movq	%rdx, 152(%rcx)
	movq	160(%rax), %rdx
	movq	%rdx, 160(%rcx)
	movq	168(%rax), %rdx
	movq	%rdx, 168(%rcx)
	movq	176(%rax), %rdx
	movq	%rdx, 176(%rcx)
	movq	184(%rax), %rdx
	movq	%rdx, 184(%rcx)
	movq	40(%rsp), %rcx
	movq	%rcx, (%rax)
	movq	48(%rsp), %rcx
	movq	%rcx, 8(%rax)
	movq	56(%rsp), %rcx
	movq	%rcx, 16(%rax)
	movq	64(%rsp), %rcx
	movq	%rcx, 24(%rax)
	movq	72(%rsp), %rcx
	movq	%rcx, 32(%rax)
	movq	80(%rsp), %rcx
	movq	%rcx, 40(%rax)
	movq	88(%rsp), %rcx
	movq	%rcx, 48(%rax)
	movq	96(%rsp), %rcx
	movq	%rcx, 56(%rax)
	movq	104(%rsp), %rcx
	movq	%rcx, 64(%rax)
	movq	112(%rsp), %rcx
	movq	%rcx, 72(%rax)
	movq	120(%rsp), %rcx
	movq	%rcx, 80(%rax)
	movq	128(%rsp), %rcx
	movq	%rcx, 88(%rax)
	movq	136(%rsp), %rcx
	movq	%rcx, 96(%rax)
	movq	144(%rsp), %rcx
	movq	%rcx, 104(%rax)
	movq	152(%rsp), %rcx
	movq	%rcx, 112(%rax)
	movq	160(%rsp), %rcx
	movq	%rcx, 120(%rax)
	movq	168(%rsp), %rcx
	movq	%rcx, 128(%rax)
	movq	176(%rsp), %rcx
	movq	%rcx, 136(%rax)
	movq	184(%rsp), %rcx
	movq	%rcx, 144(%rax)
	movq	192(%rsp), %rcx
	movq	%rcx, 152(%rax)
	movq	200(%rsp), %rcx
	movq	%rcx, 160(%rax)
	movq	208(%rsp), %rcx
	movq	%rcx, 168(%rax)
	movq	216(%rsp), %rcx
	movq	%rcx, 176(%rax)
	movq	224(%rsp), %rcx
	movq	%rcx, 184(%rax)
	movq	%r10, %rsp
	ret 
_out_end5:
out_end5:
	movq	%rsp, %rax
	leaq	-40(%rsp), %rsp
	andq	$-8, %rsp
	movq	%rax, 24(%rsp)
	movq	%r12, 32(%rsp)
	movq	%rdi, (%rsp)
	movq	%rsi, 8(%rsp)
	movq	(%rsp), %rax
	movq	(%rax), %rcx
	movq	%rcx, (%rsi)
	movq	8(%rax), %rcx
	movq	%rcx, 8(%rsi)
	movq	16(%rax), %rcx
	movq	%rcx, 16(%rsi)
	movq	24(%rax), %rax
	movq	%rax, 24(%rsi)
	movq	(%rsp), %rax
	addq	$32, %rax
	movq	%rax, 16(%rsp)
	movq	16(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lout_end5$9(%rip), 	%r12
	jmp 	L_addm$1
Lout_end5$9:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	(%rsp), %rax
	addq	$64, %rax
	movq	%rax, 16(%rsp)
	movq	16(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lout_end5$8(%rip), 	%r12
	jmp 	L_addm$1
Lout_end5$8:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	(%rsp), %rax
	addq	$96, %rax
	movq	%rax, 16(%rsp)
	movq	16(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lout_end5$7(%rip), 	%r12
	jmp 	L_addm$1
Lout_end5$7:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	(%rsp), %rax
	addq	$128, %rax
	movq	%rax, 16(%rsp)
	movq	16(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lout_end5$6(%rip), 	%r12
	jmp 	L_addm$1
Lout_end5$6:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	(%rsp), %rax
	addq	$160, %rax
	movq	%rax, 16(%rsp)
	movq	16(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lout_end5$5(%rip), 	%r12
	jmp 	L_addm$1
Lout_end5$5:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	(%rsp), %rax
	addq	$192, %rax
	movq	%rax, 16(%rsp)
	movq	16(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lout_end5$4(%rip), 	%r12
	jmp 	L_addm$1
Lout_end5$4:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	(%rsp), %rax
	addq	$192, %rax
	addq	$32, %rax
	movq	%rax, 16(%rsp)
	movq	16(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lout_end5$3(%rip), 	%r12
	jmp 	L_addm$1
Lout_end5$3:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	(%rsp), %rax
	addq	$192, %rax
	addq	$96, %rax
	movq	%rax, 16(%rsp)
	movq	16(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lout_end5$2(%rip), 	%r12
	jmp 	L_addm$1
Lout_end5$2:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	(%rsp), %rax
	addq	$384, %rax
	addq	$32, %rax
	movq	%rax, (%rsp)
	movq	(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lout_end5$1(%rip), 	%r12
	jmp 	L_addm$1
Lout_end5$1:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	32(%rsp), %r12
	movq	24(%rsp), %rsp
	ret 
_out_start5:
out_start5:
	imulq	$6, %rsi, %rax
	imulq	$4, %rax, %rax
	imulq	$8, %rax, %rax
	addq	%rax, %rdi
	movq	%rdx, %rax
	movq	(%rdi), %rcx
	movq	%rcx, (%rax)
	movq	8(%rdi), %rcx
	movq	%rcx, 8(%rax)
	movq	16(%rdi), %rcx
	movq	%rcx, 16(%rax)
	movq	24(%rdi), %rcx
	movq	%rcx, 24(%rax)
	movq	32(%rdi), %rcx
	movq	%rcx, 32(%rax)
	movq	40(%rdi), %rcx
	movq	%rcx, 40(%rax)
	movq	48(%rdi), %rcx
	movq	%rcx, 48(%rax)
	movq	56(%rdi), %rcx
	movq	%rcx, 56(%rax)
	movq	64(%rdi), %rcx
	movq	%rcx, 64(%rax)
	movq	72(%rdi), %rcx
	movq	%rcx, 72(%rax)
	movq	80(%rdi), %rcx
	movq	%rcx, 80(%rax)
	movq	88(%rdi), %rcx
	movq	%rcx, 88(%rax)
	movq	96(%rdi), %rcx
	movq	%rcx, 96(%rax)
	movq	104(%rdi), %rcx
	movq	%rcx, 104(%rax)
	movq	112(%rdi), %rcx
	movq	%rcx, 112(%rax)
	movq	120(%rdi), %rcx
	movq	%rcx, 120(%rax)
	movq	128(%rdi), %rcx
	movq	%rcx, 128(%rax)
	movq	136(%rdi), %rcx
	movq	%rcx, 136(%rax)
	movq	144(%rdi), %rcx
	movq	%rcx, 144(%rax)
	movq	152(%rdi), %rcx
	movq	%rcx, 152(%rax)
	movq	160(%rdi), %rcx
	movq	%rcx, 160(%rax)
	movq	168(%rdi), %rcx
	movq	%rcx, 168(%rax)
	movq	176(%rdi), %rcx
	movq	%rcx, 176(%rax)
	movq	184(%rdi), %rcx
	movq	%rcx, 184(%rax)
	movq	%rdx, %rax
	addq	$192, %rax
	movq	(%rdi), %rcx
	movq	%rcx, (%rax)
	movq	8(%rdi), %rcx
	movq	%rcx, 8(%rax)
	movq	16(%rdi), %rcx
	movq	%rcx, 16(%rax)
	movq	24(%rdi), %rcx
	movq	%rcx, 24(%rax)
	movq	32(%rdi), %rcx
	movq	%rcx, 32(%rax)
	movq	40(%rdi), %rcx
	movq	%rcx, 40(%rax)
	movq	48(%rdi), %rcx
	movq	%rcx, 48(%rax)
	movq	56(%rdi), %rcx
	movq	%rcx, 56(%rax)
	movq	64(%rdi), %rcx
	movq	%rcx, 64(%rax)
	movq	72(%rdi), %rcx
	movq	%rcx, 72(%rax)
	movq	80(%rdi), %rcx
	movq	%rcx, 80(%rax)
	movq	88(%rdi), %rcx
	movq	%rcx, 88(%rax)
	movq	96(%rdi), %rcx
	movq	%rcx, 96(%rax)
	movq	104(%rdi), %rcx
	movq	%rcx, 104(%rax)
	movq	112(%rdi), %rcx
	movq	%rcx, 112(%rax)
	movq	120(%rdi), %rcx
	movq	%rcx, 120(%rax)
	movq	128(%rdi), %rcx
	movq	%rcx, 128(%rax)
	movq	136(%rdi), %rcx
	movq	%rcx, 136(%rax)
	movq	144(%rdi), %rcx
	movq	%rcx, 144(%rax)
	movq	152(%rdi), %rcx
	movq	%rcx, 152(%rax)
	movq	160(%rdi), %rcx
	movq	%rcx, 160(%rax)
	movq	168(%rdi), %rcx
	movq	%rcx, 168(%rax)
	movq	176(%rdi), %rcx
	movq	%rcx, 176(%rax)
	movq	184(%rdi), %rcx
	movq	%rcx, 184(%rax)
	movq	%rdx, %rax
	addq	$384, %rax
	movq	(%rdi), %rcx
	movq	%rcx, (%rax)
	movq	8(%rdi), %rcx
	movq	%rcx, 8(%rax)
	movq	16(%rdi), %rcx
	movq	%rcx, 16(%rax)
	movq	24(%rdi), %rcx
	movq	%rcx, 24(%rax)
	movq	32(%rdi), %rcx
	movq	%rcx, 32(%rax)
	movq	40(%rdi), %rcx
	movq	%rcx, 40(%rax)
	movq	48(%rdi), %rcx
	movq	%rcx, 48(%rax)
	movq	56(%rdi), %rcx
	movq	%rcx, 56(%rax)
	movq	64(%rdi), %rcx
	movq	%rcx, 64(%rax)
	movq	72(%rdi), %rcx
	movq	%rcx, 72(%rax)
	movq	80(%rdi), %rcx
	movq	%rcx, 80(%rax)
	movq	88(%rdi), %rcx
	movq	%rcx, 88(%rax)
	movq	96(%rdi), %rcx
	movq	%rcx, 96(%rax)
	movq	104(%rdi), %rcx
	movq	%rcx, 104(%rax)
	movq	112(%rdi), %rcx
	movq	%rcx, 112(%rax)
	movq	120(%rdi), %rcx
	movq	%rcx, 120(%rax)
	movq	128(%rdi), %rcx
	movq	%rcx, 128(%rax)
	movq	136(%rdi), %rcx
	movq	%rcx, 136(%rax)
	movq	144(%rdi), %rcx
	movq	%rcx, 144(%rax)
	movq	152(%rdi), %rcx
	movq	%rcx, 152(%rax)
	movq	160(%rdi), %rcx
	movq	%rcx, 160(%rax)
	movq	168(%rdi), %rcx
	movq	%rcx, 168(%rax)
	movq	176(%rdi), %rcx
	movq	%rcx, 176(%rax)
	movq	184(%rdi), %rcx
	movq	%rcx, 184(%rax)
	movq	%rdx, %rax
	addq	$576, %rax
	movq	(%rdi), %rcx
	movq	%rcx, (%rax)
	movq	8(%rdi), %rcx
	movq	%rcx, 8(%rax)
	movq	16(%rdi), %rcx
	movq	%rcx, 16(%rax)
	movq	24(%rdi), %rcx
	movq	%rcx, 24(%rax)
	movq	32(%rdi), %rcx
	movq	%rcx, 32(%rax)
	movq	40(%rdi), %rcx
	movq	%rcx, 40(%rax)
	movq	48(%rdi), %rcx
	movq	%rcx, 48(%rax)
	movq	56(%rdi), %rcx
	movq	%rcx, 56(%rax)
	movq	64(%rdi), %rcx
	movq	%rcx, 64(%rax)
	movq	72(%rdi), %rcx
	movq	%rcx, 72(%rax)
	movq	80(%rdi), %rcx
	movq	%rcx, 80(%rax)
	movq	88(%rdi), %rcx
	movq	%rcx, 88(%rax)
	movq	96(%rdi), %rcx
	movq	%rcx, 96(%rax)
	movq	104(%rdi), %rcx
	movq	%rcx, 104(%rax)
	movq	112(%rdi), %rcx
	movq	%rcx, 112(%rax)
	movq	120(%rdi), %rcx
	movq	%rcx, 120(%rax)
	movq	128(%rdi), %rcx
	movq	%rcx, 128(%rax)
	movq	136(%rdi), %rcx
	movq	%rcx, 136(%rax)
	movq	144(%rdi), %rcx
	movq	%rcx, 144(%rax)
	movq	152(%rdi), %rcx
	movq	%rcx, 152(%rax)
	movq	160(%rdi), %rcx
	movq	%rcx, 160(%rax)
	movq	168(%rdi), %rcx
	movq	%rcx, 168(%rax)
	movq	176(%rdi), %rcx
	movq	%rcx, 176(%rax)
	movq	184(%rdi), %rcx
	movq	%rcx, 184(%rax)
	addq	$768, %rdx
	movq	(%rdi), %rax
	movq	%rax, (%rdx)
	movq	8(%rdi), %rax
	movq	%rax, 8(%rdx)
	movq	16(%rdi), %rax
	movq	%rax, 16(%rdx)
	movq	24(%rdi), %rax
	movq	%rax, 24(%rdx)
	movq	32(%rdi), %rax
	movq	%rax, 32(%rdx)
	movq	40(%rdi), %rax
	movq	%rax, 40(%rdx)
	movq	48(%rdi), %rax
	movq	%rax, 48(%rdx)
	movq	56(%rdi), %rax
	movq	%rax, 56(%rdx)
	movq	64(%rdi), %rax
	movq	%rax, 64(%rdx)
	movq	72(%rdi), %rax
	movq	%rax, 72(%rdx)
	movq	80(%rdi), %rax
	movq	%rax, 80(%rdx)
	movq	88(%rdi), %rax
	movq	%rax, 88(%rdx)
	movq	96(%rdi), %rax
	movq	%rax, 96(%rdx)
	movq	104(%rdi), %rax
	movq	%rax, 104(%rdx)
	movq	112(%rdi), %rax
	movq	%rax, 112(%rdx)
	movq	120(%rdi), %rax
	movq	%rax, 120(%rdx)
	movq	128(%rdi), %rax
	movq	%rax, 128(%rdx)
	movq	136(%rdi), %rax
	movq	%rax, 136(%rdx)
	movq	144(%rdi), %rax
	movq	%rax, 144(%rdx)
	movq	152(%rdi), %rax
	movq	%rax, 152(%rdx)
	movq	160(%rdi), %rax
	movq	%rax, 160(%rdx)
	movq	168(%rdi), %rax
	movq	%rax, 168(%rdx)
	movq	176(%rdi), %rax
	movq	%rax, 176(%rdx)
	movq	184(%rdi), %rax
	movq	%rax, 184(%rdx)
	ret 
_mult_end5:
mult_end5:
	movq	%rsp, %rax
	leaq	-64(%rsp), %rsp
	andq	$-8, %rsp
	movq	%rax, 48(%rsp)
	movq	%r12, 56(%rsp)
	movq	%rdx, (%rsp)
	imulq	$6, %rdx, %rax
	imulq	$4, %rax, %rax
	imulq	$8, %rax, %rax
	movq	%rdi, 8(%rsp)
	addq	%rax, %rsi
	movq	%rsi, 16(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 24(%rsp)
	movq	24(%rsp), %rax
	movq	16(%rsp), %rcx
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rax
	movq	%rax, 24(%rcx)
	movq	24(%rsp), %rax
	addq	$32, %rax
	movq	16(%rsp), %rcx
	addq	$32, %rcx
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rax
	movq	%rax, 24(%rcx)
	movq	24(%rsp), %rax
	addq	$64, %rax
	movq	16(%rsp), %rcx
	addq	$64, %rcx
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rax
	movq	%rax, 24(%rcx)
	movq	24(%rsp), %rax
	addq	$96, %rax
	movq	16(%rsp), %rcx
	addq	$96, %rcx
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rax
	movq	%rax, 24(%rcx)
	movq	24(%rsp), %rax
	addq	$128, %rax
	movq	16(%rsp), %rcx
	addq	$128, %rcx
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rax
	movq	%rax, 24(%rcx)
	movq	24(%rsp), %rax
	addq	$160, %rax
	movq	16(%rsp), %rcx
	addq	$160, %rcx
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rax
	movq	%rax, 24(%rcx)
	movq	8(%rsp), %rax
	addq	$192, %rax
	movq	%rax, 24(%rsp)
	movq	24(%rsp), %rax
	movq	%rax, 32(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 40(%rsp)
	movq	32(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	40(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_end5$24(%rip), 	%r12
	jmp 	L_addm$1
Lmult_end5$24:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	24(%rsp), %rax
	addq	$32, %rax
	movq	%rax, 40(%rsp)
	movq	16(%rsp), %rax
	addq	$32, %rax
	movq	%rax, 32(%rsp)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	32(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_end5$23(%rip), 	%r12
	jmp 	L_addm$1
Lmult_end5$23:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	32(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	24(%rsp), %rax
	addq	$64, %rax
	movq	%rax, 32(%rsp)
	movq	16(%rsp), %rax
	addq	$64, %rax
	movq	%rax, 40(%rsp)
	movq	32(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	40(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_end5$22(%rip), 	%r12
	jmp 	L_addm$1
Lmult_end5$22:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	24(%rsp), %rax
	addq	$96, %rax
	movq	%rax, 40(%rsp)
	movq	16(%rsp), %rax
	addq	$96, %rax
	movq	%rax, 32(%rsp)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	32(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_end5$21(%rip), 	%r12
	jmp 	L_addm$1
Lmult_end5$21:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	32(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	24(%rsp), %rax
	addq	$128, %rax
	movq	%rax, 32(%rsp)
	movq	16(%rsp), %rax
	addq	$128, %rax
	movq	%rax, 40(%rsp)
	movq	32(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	40(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_end5$20(%rip), 	%r12
	jmp 	L_addm$1
Lmult_end5$20:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	24(%rsp), %rax
	addq	$160, %rax
	movq	%rax, 24(%rsp)
	movq	16(%rsp), %rax
	addq	$160, %rax
	movq	%rax, 40(%rsp)
	movq	24(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	40(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_end5$19(%rip), 	%r12
	jmp 	L_addm$1
Lmult_end5$19:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	8(%rsp), %rax
	addq	$384, %rax
	movq	%rax, 40(%rsp)
	movq	40(%rsp), %rax
	movq	%rax, 24(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 32(%rsp)
	movq	24(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	32(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_end5$18(%rip), 	%r12
	jmp 	L_addm$1
Lmult_end5$18:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	32(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	40(%rsp), %rax
	addq	$32, %rax
	movq	%rax, 32(%rsp)
	movq	16(%rsp), %rax
	addq	$32, %rax
	movq	%rax, 24(%rsp)
	movq	32(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	24(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_end5$17(%rip), 	%r12
	jmp 	L_addm$1
Lmult_end5$17:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	24(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	40(%rsp), %rax
	addq	$64, %rax
	movq	%rax, 24(%rsp)
	movq	16(%rsp), %rax
	addq	$64, %rax
	movq	%rax, 32(%rsp)
	movq	24(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	32(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_end5$16(%rip), 	%r12
	jmp 	L_addm$1
Lmult_end5$16:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	32(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	40(%rsp), %rax
	addq	$96, %rax
	movq	%rax, 32(%rsp)
	movq	16(%rsp), %rax
	addq	$96, %rax
	movq	%rax, 24(%rsp)
	movq	32(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	24(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_end5$15(%rip), 	%r12
	jmp 	L_addm$1
Lmult_end5$15:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	24(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	40(%rsp), %rax
	addq	$128, %rax
	movq	%rax, 24(%rsp)
	movq	16(%rsp), %rax
	addq	$128, %rax
	movq	%rax, 32(%rsp)
	movq	24(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	32(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_end5$14(%rip), 	%r12
	jmp 	L_addm$1
Lmult_end5$14:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	32(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	40(%rsp), %rax
	addq	$160, %rax
	movq	%rax, 40(%rsp)
	movq	16(%rsp), %rax
	addq	$160, %rax
	movq	%rax, 32(%rsp)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	32(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_end5$13(%rip), 	%r12
	jmp 	L_addm$1
Lmult_end5$13:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	32(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	8(%rsp), %rax
	addq	$576, %rax
	movq	%rax, 32(%rsp)
	movq	32(%rsp), %rax
	movq	%rax, 40(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 24(%rsp)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	24(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_end5$12(%rip), 	%r12
	jmp 	L_addm$1
Lmult_end5$12:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	24(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	32(%rsp), %rax
	addq	$32, %rax
	movq	%rax, 24(%rsp)
	movq	16(%rsp), %rax
	addq	$32, %rax
	movq	%rax, 40(%rsp)
	movq	24(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	40(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_end5$11(%rip), 	%r12
	jmp 	L_addm$1
Lmult_end5$11:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	32(%rsp), %rax
	addq	$64, %rax
	movq	%rax, 40(%rsp)
	movq	16(%rsp), %rax
	addq	$64, %rax
	movq	%rax, 24(%rsp)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	24(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_end5$10(%rip), 	%r12
	jmp 	L_addm$1
Lmult_end5$10:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	24(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	32(%rsp), %rax
	addq	$96, %rax
	movq	%rax, 24(%rsp)
	movq	16(%rsp), %rax
	addq	$96, %rax
	movq	%rax, 40(%rsp)
	movq	24(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	40(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_end5$9(%rip), 	%r12
	jmp 	L_addm$1
Lmult_end5$9:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	32(%rsp), %rax
	addq	$128, %rax
	movq	%rax, 40(%rsp)
	movq	16(%rsp), %rax
	addq	$128, %rax
	movq	%rax, 24(%rsp)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	24(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_end5$8(%rip), 	%r12
	jmp 	L_addm$1
Lmult_end5$8:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	24(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	32(%rsp), %rax
	addq	$160, %rax
	movq	%rax, 32(%rsp)
	movq	16(%rsp), %rax
	addq	$160, %rax
	movq	%rax, 24(%rsp)
	movq	32(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	24(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_end5$7(%rip), 	%r12
	jmp 	L_addm$1
Lmult_end5$7:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	24(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	8(%rsp), %rax
	addq	$768, %rax
	movq	%rax, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 24(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 32(%rsp)
	movq	24(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	32(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_end5$6(%rip), 	%r12
	jmp 	L_addm$1
Lmult_end5$6:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	32(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	8(%rsp), %rax
	addq	$32, %rax
	movq	%rax, 32(%rsp)
	movq	16(%rsp), %rax
	addq	$32, %rax
	movq	%rax, 24(%rsp)
	movq	32(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	24(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_end5$5(%rip), 	%r12
	jmp 	L_addm$1
Lmult_end5$5:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	24(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	8(%rsp), %rax
	addq	$64, %rax
	movq	%rax, 24(%rsp)
	movq	16(%rsp), %rax
	addq	$64, %rax
	movq	%rax, 32(%rsp)
	movq	24(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	32(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_end5$4(%rip), 	%r12
	jmp 	L_addm$1
Lmult_end5$4:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	32(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	8(%rsp), %rax
	addq	$96, %rax
	movq	%rax, 32(%rsp)
	movq	16(%rsp), %rax
	addq	$96, %rax
	movq	%rax, 24(%rsp)
	movq	32(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	24(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_end5$3(%rip), 	%r12
	jmp 	L_addm$1
Lmult_end5$3:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	24(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	8(%rsp), %rax
	addq	$128, %rax
	movq	%rax, 24(%rsp)
	movq	16(%rsp), %rax
	addq	$128, %rax
	movq	%rax, 32(%rsp)
	movq	24(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	32(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_end5$2(%rip), 	%r12
	jmp 	L_addm$1
Lmult_end5$2:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	32(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	8(%rsp), %rax
	addq	$160, %rax
	movq	%rax, 8(%rsp)
	movq	16(%rsp), %rax
	addq	$160, %rax
	movq	%rax, 16(%rsp)
	movq	8(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	16(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_end5$1(%rip), 	%r12
	jmp 	L_addm$1
Lmult_end5$1:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	16(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	(%rsp), %rax
	incq	%rax
	movq	56(%rsp), %r12
	movq	48(%rsp), %rsp
	ret 
_mult_start5:
mult_start5:
	movq	%rsp, %rax
	leaq	-152(%rsp), %rsp
	andq	$-8, %rsp
	movq	%rax, 96(%rsp)
	movq	%rbx, 104(%rsp)
	movq	%rbp, 112(%rsp)
	movq	%r12, 120(%rsp)
	movq	%r13, 128(%rsp)
	movq	%r14, 136(%rsp)
	movq	%r15, 144(%rsp)
	movq	$0, (%rcx)
	movq	$0, 8(%rcx)
	movq	$0, 16(%rcx)
	movq	$0, 24(%rcx)
	movq	%r8, (%rsp)
	movq	%rcx, 8(%rsp)
	movq	%rdi, 16(%rsp)
	movq	%rsi, 24(%rsp)
	movq	%rdx, 32(%rsp)
	addq	$32, %rcx
	movq	%rcx, 40(%rsp)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	imulq	$6, 32(%rsp), %rcx
	imulq	$4, %rcx, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 56(%rsp)
	movq	48(%rsp), %rax
	movq	(%rax), %rcx
	movq	%rcx, 64(%rsp)
	movq	8(%rax), %rcx
	movq	%rcx, 72(%rsp)
	movq	16(%rax), %rcx
	movq	%rcx, 80(%rsp)
	movq	24(%rax), %rax
	movq	%rax, 88(%rsp)
	movq	56(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	leaq	64(%rsp), %rdi
	leaq	-8(%rsp), %rsp
	leaq	Lmult_start5$49(%rip), 	%r8
	movq	%r8, (%rsp)
	jmp 	L_mulm$1
Lmult_start5$49:
	leaq	8(%rsp), %rsp
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_start5$48(%rip), 	%r12
	jmp 	L_addm$1
Lmult_start5$48:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	imulq	$6, 32(%rsp), %rcx
	imulq	$4, %rcx, %rcx
	addq	$4, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 56(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 48(%rsp)
	movq	56(%rsp), %rax
	movq	(%rax), %rcx
	movq	%rcx, 64(%rsp)
	movq	8(%rax), %rcx
	movq	%rcx, 72(%rsp)
	movq	16(%rax), %rcx
	movq	%rcx, 80(%rsp)
	movq	24(%rax), %rax
	movq	%rax, 88(%rsp)
	movq	48(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	leaq	64(%rsp), %rdi
	leaq	-8(%rsp), %rsp
	leaq	Lmult_start5$47(%rip), 	%r8
	movq	%r8, (%rsp)
	jmp 	L_mulm$1
Lmult_start5$47:
	leaq	8(%rsp), %rsp
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_start5$46(%rip), 	%r12
	jmp 	L_addm$1
Lmult_start5$46:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	imulq	$6, 32(%rsp), %rcx
	imulq	$4, %rcx, %rcx
	addq	$8, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 56(%rsp)
	movq	48(%rsp), %rax
	movq	(%rax), %rcx
	movq	%rcx, 64(%rsp)
	movq	8(%rax), %rcx
	movq	%rcx, 72(%rsp)
	movq	16(%rax), %rcx
	movq	%rcx, 80(%rsp)
	movq	24(%rax), %rax
	movq	%rax, 88(%rsp)
	movq	56(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	leaq	64(%rsp), %rdi
	leaq	-8(%rsp), %rsp
	leaq	Lmult_start5$45(%rip), 	%r8
	movq	%r8, (%rsp)
	jmp 	L_mulm$1
Lmult_start5$45:
	leaq	8(%rsp), %rsp
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_start5$44(%rip), 	%r12
	jmp 	L_addm$1
Lmult_start5$44:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	imulq	$6, 32(%rsp), %rcx
	imulq	$4, %rcx, %rcx
	addq	$16, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 56(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 48(%rsp)
	movq	56(%rsp), %rax
	movq	(%rax), %rcx
	movq	%rcx, 64(%rsp)
	movq	8(%rax), %rcx
	movq	%rcx, 72(%rsp)
	movq	16(%rax), %rcx
	movq	%rcx, 80(%rsp)
	movq	24(%rax), %rax
	movq	%rax, 88(%rsp)
	movq	48(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	leaq	64(%rsp), %rdi
	leaq	-8(%rsp), %rsp
	leaq	Lmult_start5$43(%rip), 	%r8
	movq	%r8, (%rsp)
	jmp 	L_mulm$1
Lmult_start5$43:
	leaq	8(%rsp), %rsp
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_start5$42(%rip), 	%r12
	jmp 	L_addm$1
Lmult_start5$42:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	addq	$4, %rax
	imulq	$6, 32(%rsp), %rcx
	imulq	$4, %rcx, %rcx
	addq	$12, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 56(%rsp)
	movq	48(%rsp), %rax
	movq	(%rax), %rcx
	movq	%rcx, 64(%rsp)
	movq	8(%rax), %rcx
	movq	%rcx, 72(%rsp)
	movq	16(%rax), %rcx
	movq	%rcx, 80(%rsp)
	movq	24(%rax), %rax
	movq	%rax, 88(%rsp)
	movq	56(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	leaq	64(%rsp), %rdi
	leaq	-8(%rsp), %rsp
	leaq	Lmult_start5$41(%rip), 	%r8
	movq	%r8, (%rsp)
	jmp 	L_mulm$1
Lmult_start5$41:
	leaq	8(%rsp), %rsp
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_start5$40(%rip), 	%r12
	jmp 	L_addm$1
Lmult_start5$40:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	addq	$4, %rax
	imulq	$6, 32(%rsp), %rcx
	imulq	$4, %rcx, %rcx
	addq	$16, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 56(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 48(%rsp)
	movq	56(%rsp), %rax
	movq	(%rax), %rcx
	movq	%rcx, 64(%rsp)
	movq	8(%rax), %rcx
	movq	%rcx, 72(%rsp)
	movq	16(%rax), %rcx
	movq	%rcx, 80(%rsp)
	movq	24(%rax), %rax
	movq	%rax, 88(%rsp)
	movq	48(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	leaq	64(%rsp), %rdi
	leaq	-8(%rsp), %rsp
	leaq	Lmult_start5$39(%rip), 	%r8
	movq	%r8, (%rsp)
	jmp 	L_mulm$1
Lmult_start5$39:
	leaq	8(%rsp), %rsp
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_start5$38(%rip), 	%r12
	jmp 	L_addm$1
Lmult_start5$38:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	addq	$4, %rax
	imulq	$6, 32(%rsp), %rcx
	imulq	$4, %rcx, %rcx
	addq	$20, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 56(%rsp)
	movq	48(%rsp), %rax
	movq	(%rax), %rcx
	movq	%rcx, 64(%rsp)
	movq	8(%rax), %rcx
	movq	%rcx, 72(%rsp)
	movq	16(%rax), %rcx
	movq	%rcx, 80(%rsp)
	movq	24(%rax), %rax
	movq	%rax, 88(%rsp)
	movq	56(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	leaq	64(%rsp), %rdi
	leaq	-8(%rsp), %rsp
	leaq	Lmult_start5$37(%rip), 	%r8
	movq	%r8, (%rsp)
	jmp 	L_mulm$1
Lmult_start5$37:
	leaq	8(%rsp), %rsp
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_start5$36(%rip), 	%r12
	jmp 	L_addm$1
Lmult_start5$36:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	addq	$8, %rax
	imulq	$6, 32(%rsp), %rcx
	imulq	$4, %rcx, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 56(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 48(%rsp)
	movq	56(%rsp), %rax
	movq	(%rax), %rcx
	movq	%rcx, 64(%rsp)
	movq	8(%rax), %rcx
	movq	%rcx, 72(%rsp)
	movq	16(%rax), %rcx
	movq	%rcx, 80(%rsp)
	movq	24(%rax), %rax
	movq	%rax, 88(%rsp)
	movq	48(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	leaq	64(%rsp), %rdi
	leaq	-8(%rsp), %rsp
	leaq	Lmult_start5$35(%rip), 	%r8
	movq	%r8, (%rsp)
	jmp 	L_mulm$1
Lmult_start5$35:
	leaq	8(%rsp), %rsp
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_start5$34(%rip), 	%r12
	jmp 	L_addm$1
Lmult_start5$34:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	addq	$8, %rax
	imulq	$6, 32(%rsp), %rcx
	imulq	$4, %rcx, %rcx
	addq	$8, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 56(%rsp)
	movq	48(%rsp), %rax
	movq	(%rax), %rcx
	movq	%rcx, 64(%rsp)
	movq	8(%rax), %rcx
	movq	%rcx, 72(%rsp)
	movq	16(%rax), %rcx
	movq	%rcx, 80(%rsp)
	movq	24(%rax), %rax
	movq	%rax, 88(%rsp)
	movq	56(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	leaq	64(%rsp), %rdi
	leaq	-8(%rsp), %rsp
	leaq	Lmult_start5$33(%rip), 	%r8
	movq	%r8, (%rsp)
	jmp 	L_mulm$1
Lmult_start5$33:
	leaq	8(%rsp), %rsp
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_start5$32(%rip), 	%r12
	jmp 	L_addm$1
Lmult_start5$32:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	addq	$8, %rax
	imulq	$6, 32(%rsp), %rcx
	imulq	$4, %rcx, %rcx
	addq	$12, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 56(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 48(%rsp)
	movq	56(%rsp), %rax
	movq	(%rax), %rcx
	movq	%rcx, 64(%rsp)
	movq	8(%rax), %rcx
	movq	%rcx, 72(%rsp)
	movq	16(%rax), %rcx
	movq	%rcx, 80(%rsp)
	movq	24(%rax), %rax
	movq	%rax, 88(%rsp)
	movq	48(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	leaq	64(%rsp), %rdi
	leaq	-8(%rsp), %rsp
	leaq	Lmult_start5$31(%rip), 	%r8
	movq	%r8, (%rsp)
	jmp 	L_mulm$1
Lmult_start5$31:
	leaq	8(%rsp), %rsp
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_start5$30(%rip), 	%r12
	jmp 	L_addm$1
Lmult_start5$30:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	addq	$8, %rax
	imulq	$6, 32(%rsp), %rcx
	imulq	$4, %rcx, %rcx
	addq	$16, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 56(%rsp)
	movq	48(%rsp), %rax
	movq	(%rax), %rcx
	movq	%rcx, 64(%rsp)
	movq	8(%rax), %rcx
	movq	%rcx, 72(%rsp)
	movq	16(%rax), %rcx
	movq	%rcx, 80(%rsp)
	movq	24(%rax), %rax
	movq	%rax, 88(%rsp)
	movq	56(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	leaq	64(%rsp), %rdi
	leaq	-8(%rsp), %rsp
	leaq	Lmult_start5$29(%rip), 	%r8
	movq	%r8, (%rsp)
	jmp 	L_mulm$1
Lmult_start5$29:
	leaq	8(%rsp), %rsp
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_start5$28(%rip), 	%r12
	jmp 	L_addm$1
Lmult_start5$28:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	addq	$12, %rax
	imulq	$6, 32(%rsp), %rcx
	imulq	$4, %rcx, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 56(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 48(%rsp)
	movq	56(%rsp), %rax
	movq	(%rax), %rcx
	movq	%rcx, 64(%rsp)
	movq	8(%rax), %rcx
	movq	%rcx, 72(%rsp)
	movq	16(%rax), %rcx
	movq	%rcx, 80(%rsp)
	movq	24(%rax), %rax
	movq	%rax, 88(%rsp)
	movq	48(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	leaq	64(%rsp), %rdi
	leaq	-8(%rsp), %rsp
	leaq	Lmult_start5$27(%rip), 	%r8
	movq	%r8, (%rsp)
	jmp 	L_mulm$1
Lmult_start5$27:
	leaq	8(%rsp), %rsp
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_start5$26(%rip), 	%r12
	jmp 	L_addm$1
Lmult_start5$26:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	addq	$12, %rax
	imulq	$6, 32(%rsp), %rcx
	imulq	$4, %rcx, %rcx
	addq	$4, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 56(%rsp)
	movq	48(%rsp), %rax
	movq	(%rax), %rcx
	movq	%rcx, 64(%rsp)
	movq	8(%rax), %rcx
	movq	%rcx, 72(%rsp)
	movq	16(%rax), %rcx
	movq	%rcx, 80(%rsp)
	movq	24(%rax), %rax
	movq	%rax, 88(%rsp)
	movq	56(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	leaq	64(%rsp), %rdi
	leaq	-8(%rsp), %rsp
	leaq	Lmult_start5$25(%rip), 	%r8
	movq	%r8, (%rsp)
	jmp 	L_mulm$1
Lmult_start5$25:
	leaq	8(%rsp), %rsp
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_start5$24(%rip), 	%r12
	jmp 	L_addm$1
Lmult_start5$24:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	addq	$12, %rax
	imulq	$6, 32(%rsp), %rcx
	imulq	$4, %rcx, %rcx
	addq	$8, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 56(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 48(%rsp)
	movq	56(%rsp), %rax
	movq	(%rax), %rcx
	movq	%rcx, 64(%rsp)
	movq	8(%rax), %rcx
	movq	%rcx, 72(%rsp)
	movq	16(%rax), %rcx
	movq	%rcx, 80(%rsp)
	movq	24(%rax), %rax
	movq	%rax, 88(%rsp)
	movq	48(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	leaq	64(%rsp), %rdi
	leaq	-8(%rsp), %rsp
	leaq	Lmult_start5$23(%rip), 	%r8
	movq	%r8, (%rsp)
	jmp 	L_mulm$1
Lmult_start5$23:
	leaq	8(%rsp), %rsp
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_start5$22(%rip), 	%r12
	jmp 	L_addm$1
Lmult_start5$22:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	addq	$12, %rax
	imulq	$6, 32(%rsp), %rcx
	imulq	$4, %rcx, %rcx
	addq	$20, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 56(%rsp)
	movq	48(%rsp), %rax
	movq	(%rax), %rcx
	movq	%rcx, 64(%rsp)
	movq	8(%rax), %rcx
	movq	%rcx, 72(%rsp)
	movq	16(%rax), %rcx
	movq	%rcx, 80(%rsp)
	movq	24(%rax), %rax
	movq	%rax, 88(%rsp)
	movq	56(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	leaq	64(%rsp), %rdi
	leaq	-8(%rsp), %rsp
	leaq	Lmult_start5$21(%rip), 	%r8
	movq	%r8, (%rsp)
	jmp 	L_mulm$1
Lmult_start5$21:
	leaq	8(%rsp), %rsp
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_start5$20(%rip), 	%r12
	jmp 	L_addm$1
Lmult_start5$20:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	addq	$16, %rax
	imulq	$6, 32(%rsp), %rcx
	imulq	$4, %rcx, %rcx
	addq	$4, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 56(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 48(%rsp)
	movq	56(%rsp), %rax
	movq	(%rax), %rcx
	movq	%rcx, 64(%rsp)
	movq	8(%rax), %rcx
	movq	%rcx, 72(%rsp)
	movq	16(%rax), %rcx
	movq	%rcx, 80(%rsp)
	movq	24(%rax), %rax
	movq	%rax, 88(%rsp)
	movq	48(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	leaq	64(%rsp), %rdi
	leaq	-8(%rsp), %rsp
	leaq	Lmult_start5$19(%rip), 	%r8
	movq	%r8, (%rsp)
	jmp 	L_mulm$1
Lmult_start5$19:
	leaq	8(%rsp), %rsp
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_start5$18(%rip), 	%r12
	jmp 	L_addm$1
Lmult_start5$18:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	addq	$16, %rax
	imulq	$6, 32(%rsp), %rcx
	imulq	$4, %rcx, %rcx
	addq	$8, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 56(%rsp)
	movq	48(%rsp), %rax
	movq	(%rax), %rcx
	movq	%rcx, 64(%rsp)
	movq	8(%rax), %rcx
	movq	%rcx, 72(%rsp)
	movq	16(%rax), %rcx
	movq	%rcx, 80(%rsp)
	movq	24(%rax), %rax
	movq	%rax, 88(%rsp)
	movq	56(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	leaq	64(%rsp), %rdi
	leaq	-8(%rsp), %rsp
	leaq	Lmult_start5$17(%rip), 	%r8
	movq	%r8, (%rsp)
	jmp 	L_mulm$1
Lmult_start5$17:
	leaq	8(%rsp), %rsp
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_start5$16(%rip), 	%r12
	jmp 	L_addm$1
Lmult_start5$16:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	addq	$16, %rax
	imulq	$6, 32(%rsp), %rcx
	imulq	$4, %rcx, %rcx
	addq	$12, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 56(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 48(%rsp)
	movq	56(%rsp), %rax
	movq	(%rax), %rcx
	movq	%rcx, 64(%rsp)
	movq	8(%rax), %rcx
	movq	%rcx, 72(%rsp)
	movq	16(%rax), %rcx
	movq	%rcx, 80(%rsp)
	movq	24(%rax), %rax
	movq	%rax, 88(%rsp)
	movq	48(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	leaq	64(%rsp), %rdi
	leaq	-8(%rsp), %rsp
	leaq	Lmult_start5$15(%rip), 	%r8
	movq	%r8, (%rsp)
	jmp 	L_mulm$1
Lmult_start5$15:
	leaq	8(%rsp), %rsp
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_start5$14(%rip), 	%r12
	jmp 	L_addm$1
Lmult_start5$14:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	addq	$20, %rax
	imulq	$6, 32(%rsp), %rcx
	imulq	$4, %rcx, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 56(%rsp)
	movq	48(%rsp), %rax
	movq	(%rax), %rcx
	movq	%rcx, 64(%rsp)
	movq	8(%rax), %rcx
	movq	%rcx, 72(%rsp)
	movq	16(%rax), %rcx
	movq	%rcx, 80(%rsp)
	movq	24(%rax), %rax
	movq	%rax, 88(%rsp)
	movq	56(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	leaq	64(%rsp), %rdi
	leaq	-8(%rsp), %rsp
	leaq	Lmult_start5$13(%rip), 	%r8
	movq	%r8, (%rsp)
	jmp 	L_mulm$1
Lmult_start5$13:
	leaq	8(%rsp), %rsp
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_start5$12(%rip), 	%r12
	jmp 	L_addm$1
Lmult_start5$12:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	addq	$20, %rax
	imulq	$6, 32(%rsp), %rcx
	imulq	$4, %rcx, %rcx
	addq	$12, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 32(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 16(%rsp)
	movq	32(%rsp), %rax
	movq	(%rax), %rcx
	movq	%rcx, 64(%rsp)
	movq	8(%rax), %rcx
	movq	%rcx, 72(%rsp)
	movq	16(%rax), %rcx
	movq	%rcx, 80(%rsp)
	movq	24(%rax), %rax
	movq	%rax, 88(%rsp)
	movq	16(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	leaq	64(%rsp), %rdi
	leaq	-8(%rsp), %rsp
	leaq	Lmult_start5$11(%rip), 	%r8
	movq	%r8, (%rsp)
	jmp 	L_mulm$1
Lmult_start5$11:
	leaq	8(%rsp), %rsp
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_start5$10(%rip), 	%r12
	jmp 	L_addm$1
Lmult_start5$10:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	40(%rsp), %rdx
	movq	%rax, 16(%rsp)
	movq	(%rcx), %rax
	movq	%rax, (%rdx)
	movq	8(%rcx), %rax
	movq	%rax, 8(%rdx)
	movq	16(%rcx), %rax
	movq	%rax, 16(%rdx)
	movq	24(%rcx), %rax
	movq	%rax, 24(%rdx)
	movq	(%rsp), %rax
	addq	$32, %rax
	movq	%rax, 32(%rsp)
	movq	40(%rsp), %rax
	movq	%rax, 24(%rsp)
	movq	32(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	24(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_start5$9(%rip), 	%r12
	jmp 	L_addm$1
Lmult_start5$9:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	24(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	(%rsp), %rax
	addq	$64, %rax
	movq	%rax, 24(%rsp)
	movq	40(%rsp), %rax
	movq	%rax, 32(%rsp)
	movq	24(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	32(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_start5$8(%rip), 	%r12
	jmp 	L_addm$1
Lmult_start5$8:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	32(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	(%rsp), %rax
	addq	$96, %rax
	movq	%rax, 32(%rsp)
	movq	40(%rsp), %rax
	movq	%rax, 24(%rsp)
	movq	32(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	24(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_start5$7(%rip), 	%r12
	jmp 	L_addm$1
Lmult_start5$7:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	24(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	(%rsp), %rax
	addq	$128, %rax
	movq	%rax, 24(%rsp)
	movq	40(%rsp), %rax
	movq	%rax, 32(%rsp)
	movq	24(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	32(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_start5$6(%rip), 	%r12
	jmp 	L_addm$1
Lmult_start5$6:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	32(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	(%rsp), %rax
	addq	$160, %rax
	movq	%rax, 32(%rsp)
	movq	40(%rsp), %rax
	movq	%rax, 24(%rsp)
	movq	32(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	24(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_start5$5(%rip), 	%r12
	jmp 	L_addm$1
Lmult_start5$5:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	24(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	(%rsp), %rax
	addq	$192, %rax
	movq	%rax, 24(%rsp)
	movq	40(%rsp), %rax
	movq	%rax, 32(%rsp)
	movq	24(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	32(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_start5$4(%rip), 	%r12
	jmp 	L_addm$1
Lmult_start5$4:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	32(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	(%rsp), %rax
	addq	$224, %rax
	movq	%rax, 32(%rsp)
	movq	40(%rsp), %rax
	movq	%rax, 24(%rsp)
	movq	32(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	24(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_start5$3(%rip), 	%r12
	jmp 	L_addm$1
Lmult_start5$3:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	24(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	(%rsp), %rax
	addq	$256, %rax
	movq	%rax, 24(%rsp)
	movq	40(%rsp), %rax
	movq	%rax, 40(%rsp)
	movq	24(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	40(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_start5$2(%rip), 	%r12
	jmp 	L_addm$1
Lmult_start5$2:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	16(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	40(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lmult_start5$1(%rip), 	%r12
	jmp 	L_subm$1
Lmult_start5$1:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	(%rsp), %rax
	movq	%rax, %rcx
	movq	8(%rsp), %rdx
	addq	$160, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$64, %rdx
	addq	$256, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$224, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$128, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$192, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$32, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$64, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	addq	$32, %rdx
	movq	8(%rsp), %rcx
	addq	$32, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$96, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$256, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$224, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$192, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$64, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$160, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	addq	$32, %rdx
	movq	8(%rsp), %rcx
	addq	$32, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$96, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$96, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$256, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$128, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$192, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$32, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$224, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$128, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$32, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$64, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	addq	$32, %rdx
	addq	$160, %rax
	movq	(%rax), %rcx
	movq	%rcx, (%rdx)
	movq	8(%rax), %rcx
	movq	%rcx, 8(%rdx)
	movq	16(%rax), %rcx
	movq	%rcx, 16(%rdx)
	movq	24(%rax), %rax
	movq	%rax, 24(%rdx)
	movq	104(%rsp), %rbx
	movq	112(%rsp), %rbp
	movq	120(%rsp), %r12
	movq	128(%rsp), %r13
	movq	136(%rsp), %r14
	movq	144(%rsp), %r15
	movq	96(%rsp), %rsp
	ret 
_Smult5:
Smult5:
	movq	%rsp, %rax
	leaq	-136(%rsp), %rsp
	andq	$-8, %rsp
	movq	%rax, 80(%rsp)
	movq	%rbx, 88(%rsp)
	movq	%rbp, 96(%rsp)
	movq	%r12, 104(%rsp)
	movq	%r13, 112(%rsp)
	movq	%r14, 120(%rsp)
	movq	%r15, 128(%rsp)
	movq	%rdi, (%rsp)
	movq	%rsi, 8(%rsp)
	movq	%rcx, 16(%rsp)
	imulq	$6, %rdx, %rax
	imulq	$4, %rax, %rax
	imulq	$8, %rax, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 24(%rsp)
	movq	8(%rsp), %rax
	movq	16(%rsp), %rcx
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	imulq	$6, %rcx, %rcx
	imulq	$4, %rcx, %rcx
	imulq	$8, %rax, %rax
	movq	(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 32(%rsp)
	imulq	$8, %rcx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	movq	32(%rsp), %rax
	movq	(%rax), %rcx
	movq	%rcx, 48(%rsp)
	movq	8(%rax), %rcx
	movq	%rcx, 56(%rsp)
	movq	16(%rax), %rcx
	movq	%rcx, 64(%rsp)
	movq	24(%rax), %rax
	movq	%rax, 72(%rsp)
	movq	24(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	leaq	48(%rsp), %rdi
	leaq	-8(%rsp), %rsp
	leaq	LSmult5$6(%rip), 	%r8
	movq	%r8, (%rsp)
	jmp 	L_mulm$1
LSmult5$6:
	leaq	8(%rsp), %rsp
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	8(%rsp), %rax
	movq	16(%rsp), %rcx
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	addq	$4, %rax
	imulq	$6, %rcx, %rcx
	imulq	$4, %rcx, %rcx
	addq	$4, %rcx
	imulq	$8, %rax, %rax
	movq	(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 40(%rsp)
	imulq	$8, %rcx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 32(%rsp)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	%rcx, 48(%rsp)
	movq	8(%rax), %rcx
	movq	%rcx, 56(%rsp)
	movq	16(%rax), %rcx
	movq	%rcx, 64(%rsp)
	movq	24(%rax), %rax
	movq	%rax, 72(%rsp)
	movq	24(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	leaq	48(%rsp), %rdi
	leaq	-8(%rsp), %rsp
	leaq	LSmult5$5(%rip), 	%r8
	movq	%r8, (%rsp)
	jmp 	L_mulm$1
LSmult5$5:
	leaq	8(%rsp), %rsp
	movq	32(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	8(%rsp), %rax
	movq	16(%rsp), %rcx
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	addq	$8, %rax
	imulq	$6, %rcx, %rcx
	imulq	$4, %rcx, %rcx
	addq	$8, %rcx
	imulq	$8, %rax, %rax
	movq	(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 32(%rsp)
	imulq	$8, %rcx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	movq	32(%rsp), %rax
	movq	(%rax), %rcx
	movq	%rcx, 48(%rsp)
	movq	8(%rax), %rcx
	movq	%rcx, 56(%rsp)
	movq	16(%rax), %rcx
	movq	%rcx, 64(%rsp)
	movq	24(%rax), %rax
	movq	%rax, 72(%rsp)
	movq	24(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	leaq	48(%rsp), %rdi
	leaq	-8(%rsp), %rsp
	leaq	LSmult5$4(%rip), 	%r8
	movq	%r8, (%rsp)
	jmp 	L_mulm$1
LSmult5$4:
	leaq	8(%rsp), %rsp
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	8(%rsp), %rax
	movq	16(%rsp), %rcx
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	addq	$12, %rax
	imulq	$6, %rcx, %rcx
	imulq	$4, %rcx, %rcx
	addq	$12, %rcx
	imulq	$8, %rax, %rax
	movq	(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 40(%rsp)
	imulq	$8, %rcx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 32(%rsp)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	%rcx, 48(%rsp)
	movq	8(%rax), %rcx
	movq	%rcx, 56(%rsp)
	movq	16(%rax), %rcx
	movq	%rcx, 64(%rsp)
	movq	24(%rax), %rax
	movq	%rax, 72(%rsp)
	movq	24(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	leaq	48(%rsp), %rdi
	leaq	-8(%rsp), %rsp
	leaq	LSmult5$3(%rip), 	%r8
	movq	%r8, (%rsp)
	jmp 	L_mulm$1
LSmult5$3:
	leaq	8(%rsp), %rsp
	movq	32(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	8(%rsp), %rax
	movq	16(%rsp), %rcx
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	addq	$16, %rax
	imulq	$6, %rcx, %rcx
	imulq	$4, %rcx, %rcx
	addq	$16, %rcx
	imulq	$8, %rax, %rax
	movq	(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 32(%rsp)
	imulq	$8, %rcx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	movq	32(%rsp), %rax
	movq	(%rax), %rcx
	movq	%rcx, 48(%rsp)
	movq	8(%rax), %rcx
	movq	%rcx, 56(%rsp)
	movq	16(%rax), %rcx
	movq	%rcx, 64(%rsp)
	movq	24(%rax), %rax
	movq	%rax, 72(%rsp)
	movq	24(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	leaq	48(%rsp), %rdi
	leaq	-8(%rsp), %rsp
	leaq	LSmult5$2(%rip), 	%r8
	movq	%r8, (%rsp)
	jmp 	L_mulm$1
LSmult5$2:
	leaq	8(%rsp), %rsp
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	8(%rsp), %rax
	movq	16(%rsp), %rcx
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	addq	$20, %rax
	imulq	$6, %rcx, %rcx
	imulq	$4, %rcx, %rcx
	addq	$20, %rcx
	imulq	$8, %rax, %rax
	movq	(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 8(%rsp)
	imulq	$8, %rcx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, (%rsp)
	movq	8(%rsp), %rax
	movq	(%rax), %rcx
	movq	%rcx, 48(%rsp)
	movq	8(%rax), %rcx
	movq	%rcx, 56(%rsp)
	movq	16(%rax), %rcx
	movq	%rcx, 64(%rsp)
	movq	24(%rax), %rax
	movq	%rax, 72(%rsp)
	movq	24(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	leaq	48(%rsp), %rdi
	leaq	-8(%rsp), %rsp
	leaq	LSmult5$1(%rip), 	%r8
	movq	%r8, (%rsp)
	jmp 	L_mulm$1
LSmult5$1:
	leaq	8(%rsp), %rsp
	movq	(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	16(%rsp), %rax
	incq	%rax
	movq	88(%rsp), %rbx
	movq	96(%rsp), %rbp
	movq	104(%rsp), %r12
	movq	112(%rsp), %r13
	movq	120(%rsp), %r14
	movq	128(%rsp), %r15
	movq	80(%rsp), %rsp
	ret 
_const_end5:
const_end5:
	movq	%rdx, %rax
	imulq	$6, %rax, %rcx
	imulq	$4, %rcx, %rcx
	imulq	$8, %rcx, %rcx
	addq	%rcx, %rsi
	movq	(%rdi), %rcx
	movq	%rcx, (%rsi)
	movq	8(%rdi), %rcx
	movq	%rcx, 8(%rsi)
	movq	16(%rdi), %rcx
	movq	%rcx, 16(%rsi)
	movq	24(%rdi), %rcx
	movq	%rcx, 24(%rsi)
	movq	32(%rdi), %rcx
	movq	%rcx, 32(%rsi)
	movq	40(%rdi), %rcx
	movq	%rcx, 40(%rsi)
	movq	48(%rdi), %rcx
	movq	%rcx, 48(%rsi)
	movq	56(%rdi), %rcx
	movq	%rcx, 56(%rsi)
	movq	64(%rdi), %rcx
	movq	%rcx, 64(%rsi)
	movq	72(%rdi), %rcx
	movq	%rcx, 72(%rsi)
	movq	80(%rdi), %rcx
	movq	%rcx, 80(%rsi)
	movq	88(%rdi), %rcx
	movq	%rcx, 88(%rsi)
	movq	96(%rdi), %rcx
	movq	%rcx, 96(%rsi)
	movq	104(%rdi), %rcx
	movq	%rcx, 104(%rsi)
	movq	112(%rdi), %rcx
	movq	%rcx, 112(%rsi)
	movq	120(%rdi), %rcx
	movq	%rcx, 120(%rsi)
	movq	128(%rdi), %rcx
	movq	%rcx, 128(%rsi)
	movq	136(%rdi), %rcx
	movq	%rcx, 136(%rsi)
	movq	144(%rdi), %rcx
	movq	%rcx, 144(%rsi)
	movq	152(%rdi), %rcx
	movq	%rcx, 152(%rsi)
	movq	160(%rdi), %rcx
	movq	%rcx, 160(%rsi)
	movq	168(%rdi), %rcx
	movq	%rcx, 168(%rsi)
	movq	176(%rdi), %rcx
	movq	%rcx, 176(%rsi)
	movq	184(%rdi), %rcx
	movq	%rcx, 184(%rsi)
	incq	%rax
	ret 
_const_start5:
const_start5:
	movq	%rsp, %rax
	leaq	-40(%rsp), %rsp
	andq	$-8, %rsp
	movq	%rax, 24(%rsp)
	movq	%r12, 32(%rsp)
	movq	%rdi, (%rsp)
	movq	%rsi, 8(%rsp)
	movq	$0, (%rsi)
	movq	$0, 8(%rsi)
	movq	$0, 16(%rsi)
	movq	$0, 24(%rsi)
	addq	$64, %rsi
	movq	%rsi, 16(%rsp)
	movq	8(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Lconst_start5$1(%rip), 	%r12
	jmp 	L_subm$1
Lconst_start5$1:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	16(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	(%rsp), %rax
	movq	16(%rsp), %rcx
	movq	8(%rsp), %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rax), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rax), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rax), %rsi
	movq	%rsi, 24(%rdx)
	addq	$32, %rdx
	movq	$0, (%rdx)
	movq	$0, 8(%rdx)
	movq	$0, 16(%rdx)
	movq	$0, 24(%rdx)
	addq	$32, %rdx
	addq	$32, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rax), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rax), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rax), %rsi
	movq	%rsi, 24(%rdx)
	addq	$32, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rsi
	movq	%rsi, 24(%rdx)
	addq	$32, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rax), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rax), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rax), %rsi
	movq	%rsi, 24(%rdx)
	addq	$32, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rax), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rax), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rax), %rsi
	movq	%rsi, 24(%rdx)
	addq	$32, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rsi
	movq	%rsi, 24(%rdx)
	addq	$32, %rdx
	movq	$0, (%rdx)
	movq	$0, 8(%rdx)
	movq	$0, 16(%rdx)
	movq	$0, 24(%rdx)
	addq	$32, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rax), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rax), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rax), %rsi
	movq	%rsi, 24(%rdx)
	addq	$32, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rsi
	movq	%rsi, 24(%rdx)
	addq	$32, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rax), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rax), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rax), %rsi
	movq	%rsi, 24(%rdx)
	addq	$32, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rax), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rax), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rax), %rsi
	movq	%rsi, 24(%rdx)
	addq	$32, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rsi
	movq	%rsi, 24(%rdx)
	addq	$32, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rsi
	movq	%rsi, 24(%rdx)
	addq	$32, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rax), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rax), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rax), %rsi
	movq	%rsi, 24(%rdx)
	addq	$32, %rdx
	movq	$0, (%rdx)
	movq	$0, 8(%rdx)
	movq	$0, 16(%rdx)
	movq	$0, 24(%rdx)
	addq	$32, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rax), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rax), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rax), %rsi
	movq	%rsi, 24(%rdx)
	addq	$32, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rax), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rax), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rax), %rsi
	movq	%rsi, 24(%rdx)
	addq	$32, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rsi
	movq	%rsi, 24(%rdx)
	addq	$32, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rsi
	movq	%rsi, 24(%rdx)
	addq	$32, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rax), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rax), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rax), %rsi
	movq	%rsi, 24(%rdx)
	addq	$32, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rsi
	movq	%rsi, 24(%rdx)
	addq	$32, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rax), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rax), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rax), %rsi
	movq	%rsi, 24(%rdx)
	addq	$32, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rax), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rax), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rax), %rsi
	movq	%rsi, 24(%rdx)
	addq	$32, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rsi
	movq	%rsi, 24(%rdx)
	addq	$32, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rsi
	movq	%rsi, 24(%rdx)
	addq	$32, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rax), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rax), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rax), %rsi
	movq	%rsi, 24(%rdx)
	addq	$32, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	addq	$32, %rdx
	movq	(%rax), %rcx
	movq	%rcx, (%rdx)
	movq	8(%rax), %rcx
	movq	%rcx, 8(%rdx)
	movq	16(%rax), %rcx
	movq	%rcx, 16(%rdx)
	movq	24(%rax), %rax
	movq	%rax, 24(%rdx)
	movq	32(%rsp), %r12
	movq	24(%rsp), %rsp
	ret 
_input_end5:
input_end5:
	movq	%rdx, %rax
	imulq	$6, %rax, %rcx
	imulq	$4, %rcx, %rcx
	imulq	$8, %rcx, %rcx
	addq	%rcx, %rsi
	movq	(%rdi), %rcx
	movq	%rcx, (%rsi)
	movq	8(%rdi), %rcx
	movq	%rcx, 8(%rsi)
	movq	16(%rdi), %rcx
	movq	%rcx, 16(%rsi)
	movq	24(%rdi), %rcx
	movq	%rcx, 24(%rsi)
	movq	32(%rdi), %rcx
	movq	%rcx, 32(%rsi)
	movq	40(%rdi), %rcx
	movq	%rcx, 40(%rsi)
	movq	48(%rdi), %rcx
	movq	%rcx, 48(%rsi)
	movq	56(%rdi), %rcx
	movq	%rcx, 56(%rsi)
	movq	64(%rdi), %rcx
	movq	%rcx, 64(%rsi)
	movq	72(%rdi), %rcx
	movq	%rcx, 72(%rsi)
	movq	80(%rdi), %rcx
	movq	%rcx, 80(%rsi)
	movq	88(%rdi), %rcx
	movq	%rcx, 88(%rsi)
	movq	96(%rdi), %rcx
	movq	%rcx, 96(%rsi)
	movq	104(%rdi), %rcx
	movq	%rcx, 104(%rsi)
	movq	112(%rdi), %rcx
	movq	%rcx, 112(%rsi)
	movq	120(%rdi), %rcx
	movq	%rcx, 120(%rsi)
	movq	128(%rdi), %rcx
	movq	%rcx, 128(%rsi)
	movq	136(%rdi), %rcx
	movq	%rcx, 136(%rsi)
	movq	144(%rdi), %rcx
	movq	%rcx, 144(%rsi)
	movq	152(%rdi), %rcx
	movq	%rcx, 152(%rsi)
	movq	160(%rdi), %rcx
	movq	%rcx, 160(%rsi)
	movq	168(%rdi), %rcx
	movq	%rcx, 168(%rsi)
	movq	176(%rdi), %rcx
	movq	%rcx, 176(%rsi)
	movq	184(%rdi), %rcx
	movq	%rcx, 184(%rsi)
	incq	%rax
	ret 
_input_start5:
input_start5:
	movq	%rsp, %rax
	leaq	-64(%rsp), %rsp
	andq	$-8, %rsp
	movq	%rax, 48(%rsp)
	movq	%r12, 56(%rsp)
	movq	%rsi, (%rsp)
	addq	$32, %rsi
	movq	%rsi, 8(%rsp)
	movq	%rdx, 16(%rsp)
	movq	16(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	%rdi, 24(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rax
	movq	%rax, 24(%rcx)
	movq	16(%rsp), %rax
	addq	$32, %rax
	movq	%rax, 32(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 40(%rsp)
	movq	32(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	40(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Linput_start5$9(%rip), 	%r12
	jmp 	L_addm$1
Linput_start5$9:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	16(%rsp), %rax
	addq	$64, %rax
	movq	%rax, 40(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 32(%rsp)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	32(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Linput_start5$8(%rip), 	%r12
	jmp 	L_addm$1
Linput_start5$8:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	32(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	16(%rsp), %rax
	addq	$96, %rax
	movq	%rax, 32(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 40(%rsp)
	movq	32(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	40(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Linput_start5$7(%rip), 	%r12
	jmp 	L_addm$1
Linput_start5$7:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	16(%rsp), %rax
	addq	$128, %rax
	movq	%rax, 40(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 32(%rsp)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	32(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Linput_start5$6(%rip), 	%r12
	jmp 	L_addm$1
Linput_start5$6:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	32(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	16(%rsp), %rax
	addq	$160, %rax
	movq	%rax, 32(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 40(%rsp)
	movq	32(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	40(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Linput_start5$5(%rip), 	%r12
	jmp 	L_addm$1
Linput_start5$5:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	16(%rsp), %rax
	addq	$192, %rax
	movq	%rax, 40(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 32(%rsp)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	32(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Linput_start5$4(%rip), 	%r12
	jmp 	L_addm$1
Linput_start5$4:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	32(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	16(%rsp), %rax
	addq	$224, %rax
	movq	%rax, 32(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 40(%rsp)
	movq	32(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	40(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Linput_start5$3(%rip), 	%r12
	jmp 	L_addm$1
Linput_start5$3:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	40(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	16(%rsp), %rax
	addq	$256, %rax
	movq	%rax, 40(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	movq	40(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Linput_start5$2(%rip), 	%r12
	jmp 	L_addm$1
Linput_start5$2:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	24(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Linput_start5$1(%rip), 	%r12
	jmp 	L_subm$1
Linput_start5$1:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	8(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	16(%rsp), %rax
	movq	%rax, %rcx
	movq	(%rsp), %rdx
	addq	$160, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$64, %rdx
	addq	$256, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$224, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$128, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$192, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$32, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$64, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	addq	$32, %rdx
	movq	(%rsp), %rcx
	addq	$32, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$96, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$256, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$224, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$192, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$64, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$160, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	addq	$32, %rdx
	movq	(%rsp), %rcx
	addq	$32, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$96, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$96, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$256, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$128, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$192, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$32, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$224, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$128, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$32, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	movq	%rax, %rcx
	addq	$32, %rdx
	addq	$64, %rcx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	movq	8(%rcx), %rsi
	movq	%rsi, 8(%rdx)
	movq	16(%rcx), %rsi
	movq	%rsi, 16(%rdx)
	movq	24(%rcx), %rcx
	movq	%rcx, 24(%rdx)
	addq	$32, %rdx
	addq	$160, %rax
	movq	(%rax), %rcx
	movq	%rcx, (%rdx)
	movq	8(%rax), %rcx
	movq	%rcx, 8(%rdx)
	movq	16(%rax), %rcx
	movq	%rcx, 16(%rdx)
	movq	24(%rax), %rax
	movq	%rax, 24(%rdx)
	movq	56(%rsp), %r12
	movq	48(%rsp), %rsp
	ret 
_add5:
add5:
	movq	%rsp, %rax
	leaq	-72(%rsp), %rsp
	andq	$-8, %rsp
	movq	%rax, 56(%rsp)
	movq	%r12, 64(%rsp)
	movq	%rdi, (%rsp)
	movq	%rsi, 8(%rsp)
	movq	%rdx, 16(%rsp)
	movq	%rcx, 24(%rsp)
	movq	8(%rsp), %rax
	movq	16(%rsp), %rcx
	movq	24(%rsp), %rdx
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	imulq	$6, %rcx, %rcx
	imulq	$4, %rcx, %rcx
	imulq	$6, %rdx, %rdx
	imulq	$4, %rdx, %rdx
	imulq	$8, %rax, %rax
	movq	(%rsp), %rsi
	addq	%rax, %rsi
	movq	%rsi, 32(%rsp)
	imulq	$8, %rcx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	imulq	$8, %rdx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 48(%rsp)
	movq	32(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	40(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Ladd5$6(%rip), 	%r12
	jmp 	L_addm$1
Ladd5$6:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	48(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	8(%rsp), %rax
	movq	16(%rsp), %rcx
	movq	24(%rsp), %rdx
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	addq	$4, %rax
	imulq	$6, %rcx, %rcx
	imulq	$4, %rcx, %rcx
	addq	$4, %rcx
	imulq	$6, %rdx, %rdx
	imulq	$4, %rdx, %rdx
	addq	$4, %rdx
	imulq	$8, %rax, %rax
	movq	(%rsp), %rsi
	addq	%rax, %rsi
	movq	%rsi, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	imulq	$8, %rdx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 32(%rsp)
	movq	48(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	40(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Ladd5$5(%rip), 	%r12
	jmp 	L_addm$1
Ladd5$5:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	32(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	8(%rsp), %rax
	movq	16(%rsp), %rcx
	movq	24(%rsp), %rdx
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	addq	$8, %rax
	imulq	$6, %rcx, %rcx
	imulq	$4, %rcx, %rcx
	addq	$8, %rcx
	imulq	$6, %rdx, %rdx
	imulq	$4, %rdx, %rdx
	addq	$8, %rdx
	imulq	$8, %rax, %rax
	movq	(%rsp), %rsi
	addq	%rax, %rsi
	movq	%rsi, 32(%rsp)
	imulq	$8, %rcx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	imulq	$8, %rdx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 48(%rsp)
	movq	32(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	40(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Ladd5$4(%rip), 	%r12
	jmp 	L_addm$1
Ladd5$4:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	48(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	8(%rsp), %rax
	movq	16(%rsp), %rcx
	movq	24(%rsp), %rdx
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	addq	$12, %rax
	imulq	$6, %rcx, %rcx
	imulq	$4, %rcx, %rcx
	addq	$12, %rcx
	imulq	$6, %rdx, %rdx
	imulq	$4, %rdx, %rdx
	addq	$12, %rdx
	imulq	$8, %rax, %rax
	movq	(%rsp), %rsi
	addq	%rax, %rsi
	movq	%rsi, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	imulq	$8, %rdx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 32(%rsp)
	movq	48(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	40(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Ladd5$3(%rip), 	%r12
	jmp 	L_addm$1
Ladd5$3:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	32(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	8(%rsp), %rax
	movq	16(%rsp), %rcx
	movq	24(%rsp), %rdx
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	addq	$16, %rax
	imulq	$6, %rcx, %rcx
	imulq	$4, %rcx, %rcx
	addq	$16, %rcx
	imulq	$6, %rdx, %rdx
	imulq	$4, %rdx, %rdx
	addq	$16, %rdx
	imulq	$8, %rax, %rax
	movq	(%rsp), %rsi
	addq	%rax, %rsi
	movq	%rsi, 32(%rsp)
	imulq	$8, %rcx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	imulq	$8, %rdx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 48(%rsp)
	movq	32(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	40(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Ladd5$2(%rip), 	%r12
	jmp 	L_addm$1
Ladd5$2:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	48(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	8(%rsp), %rax
	movq	16(%rsp), %rcx
	movq	24(%rsp), %rdx
	imulq	$6, %rax, %rax
	imulq	$4, %rax, %rax
	addq	$20, %rax
	imulq	$6, %rcx, %rcx
	imulq	$4, %rcx, %rcx
	addq	$20, %rcx
	imulq	$6, %rdx, %rdx
	imulq	$4, %rdx, %rdx
	addq	$20, %rdx
	imulq	$8, %rax, %rax
	movq	(%rsp), %rsi
	addq	%rax, %rsi
	movq	%rsi, 16(%rsp)
	imulq	$8, %rcx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 8(%rsp)
	imulq	$8, %rdx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, (%rsp)
	movq	16(%rsp), %rax
	movq	(%rax), %rcx
	movq	8(%rax), %rdx
	movq	16(%rax), %rsi
	movq	24(%rax), %rax
	movq	8(%rsp), %rdi
	movq	(%rdi), %r8
	movq	8(%rdi), %r9
	movq	16(%rdi), %r10
	movq	24(%rdi), %rdi
	leaq	Ladd5$1(%rip), 	%r12
	jmp 	L_addm$1
Ladd5$1:
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	movq	(%rsp), %rdi
	movq	%rax, (%rdi)
	movq	%rcx, 8(%rdi)
	movq	%rdx, 16(%rdi)
	movq	%rsi, 24(%rdi)
	movq	24(%rsp), %rax
	incq	%rax
	movq	64(%rsp), %r12
	movq	56(%rsp), %rsp
	ret 
L_subm$1:
	subq	%r8, %rcx
	sbbq	%r9, %rdx
	sbbq	%r10, %rsi
	sbbq	%rdi, %rax
	movq	$-19, %rdi
	movq	$-1, %r8
	movq	$-1, %r9
	movq	$9223372036854775807, %r10
	movq	$0, %r11
	cmovnb	%r11, %rdi
	cmovnb	%r11, %r8
	cmovnb	%r11, %r9
	cmovnb	%r11, %r10
	addq	%rdi, %rcx
	adcq	%r8, %rdx
	adcq	%r9, %rsi
	adcq	%r10, %rax
	movq	%rax, %rdi
	jmp 	*%r12
L_addm$1:
	addq	%r8, %rcx
	adcq	%r9, %rdx
	adcq	%r10, %rsi
	adcq	%rdi, %rax
	movq	%rcx, %rdi
	movq	%rdx, %r8
	movq	%rsi, %r9
	movq	%rax, %r10
	movq	$1, %r11
	shlq	$63, %r11
	addq	$19, %rdi
	adcq	$0, %r8
	adcq	$0, %r9
	adcq	%r11, %r10
	cmovb	%rdi, %rcx
	cmovb	%r8, %rdx
	cmovb	%r9, %rsi
	cmovb	%r10, %rax
	movq	%rax, %rdi
	jmp 	*%r12
L_mulm$1:
	movq	%rdx, %r8
	movq	(%rdi), %rdx
	xorq	%r9, %r9
	MULXq	%rcx, %r11, %r10
	MULXq	%r8, %rbx, %rbp
	adcxq	%rbx, %r10
	MULXq	%rsi, %r12, %rbx
	adcxq	%r12, %rbp
	MULXq	%rax, %rdx, %r12
	adcxq	%rdx, %rbx
	adcxq	%r9, %r12
	movq	8(%rdi), %rdx
	MULXq	%rcx, %r14, %r13
	adoxq	%r14, %r10
	adcxq	%r13, %rbp
	MULXq	%r8, %r14, %r13
	adoxq	%r14, %rbp
	adcxq	%r13, %rbx
	MULXq	%rsi, %r14, %r13
	adoxq	%r14, %rbx
	adcxq	%r13, %r12
	MULXq	%rax, %rdx, %r13
	adoxq	%rdx, %r12
	adcxq	%r9, %r13
	adoxq	%r9, %r13
	movq	16(%rdi), %rdx
	MULXq	%rcx, %r15, %r14
	adoxq	%r15, %rbp
	adcxq	%r14, %rbx
	MULXq	%r8, %r15, %r14
	adoxq	%r15, %rbx
	adcxq	%r14, %r12
	MULXq	%rsi, %r15, %r14
	adoxq	%r15, %r12
	adcxq	%r14, %r13
	MULXq	%rax, %rdx, %r14
	adoxq	%rdx, %r13
	adcxq	%r9, %r14
	adoxq	%r9, %r14
	movq	24(%rdi), %rdx
	MULXq	%rcx, %rdi, %rcx
	adoxq	%rdi, %rbx
	adcxq	%rcx, %r12
	MULXq	%r8, %rdi, %rcx
	adoxq	%rdi, %r12
	adcxq	%rcx, %r13
	MULXq	%rsi, %rsi, %rcx
	adoxq	%rsi, %r13
	adcxq	%rcx, %r14
	MULXq	%rax, %rcx, %rax
	adoxq	%rcx, %r14
	adcxq	%r9, %rax
	adoxq	%r9, %rax
	movq	$38, %rdx
	movq	$0, %rcx
	movq	%r12, %rsi
	movq	%r13, %rdi
	movq	%r14, %r8
	MULXq	%rsi, %r9, %rsi
	adoxq	%r9, %r11
	adcxq	%rsi, %r10
	MULXq	%rdi, %rdi, %rsi
	adoxq	%rdi, %r10
	adcxq	%rsi, %rbp
	MULXq	%r8, %rdi, %rsi
	adoxq	%rdi, %rbp
	adcxq	%rsi, %rbx
	MULXq	%rax, %rdx, %rax
	adoxq	%rdx, %rbx
	adcxq	%rcx, %rax
	adoxq	%rcx, %rax
	imulq	$38, %rax, %rax
	movq	%r11, %rcx
	movq	%r10, %rdx
	movq	%rbp, %rsi
	movq	%rbx, %rdi
	addq	%rax, %rcx
	adcq	$0, %rdx
	adcq	$0, %rsi
	adcq	$0, %rdi
	sbbq	%rax, %rax
	andq	$38, %rax
	addq	%rax, %rcx
	movq	%rcx, %rax
	movq	%rdx, %r8
	movq	%rsi, %r9
	movq	%rdi, %r10
	movq	$1, %r11
	shlq	$63, %r11
	addq	$19, %rax
	adcq	$0, %r8
	adcq	$0, %r9
	adcq	%r11, %r10
	cmovb	%rax, %rcx
	cmovb	%r8, %rdx
	cmovb	%r9, %rsi
	cmovb	%r10, %rdi
	movq	%rcx, %rax
	movq	%rdx, %r8
	movq	%rsi, %r9
	movq	%rdi, %r10
	movq	$1, %r11
	shlq	$63, %r11
	addq	$19, %rax
	adcq	$0, %r8
	adcq	$0, %r9
	adcq	%r11, %r10
	cmovb	%rax, %rcx
	cmovb	%r8, %rdx
	cmovb	%r9, %rsi
	cmovb	%r10, %rdi
	movq	%rcx, %rax
	movq	%rdx, %rcx
	movq	%rsi, %rdx
	movq	%rdi, %rsi
	jmp 	*(%rsp)
