	.text
	.p2align	5
	.globl	_dispatch
	.globl	dispatch
	.globl	_out_end5
	.globl	out_end5
	.globl	_out_start5
	.globl	out_start5
	.globl	_mult_end5
	.globl	mult_end5
	.globl	_mult_start5
	.globl	mult_start5
	.globl	_Smult5
	.globl	Smult5
	.globl	_const_end5
	.globl	const_end5
	.globl	_const_start5
	.globl	const_start5
	.globl	_input_end5
	.globl	input_end5
	.globl	_input_start5
	.globl	input_start5
	.globl	_add5
	.globl	add5
_dispatch:
dispatch:
	movq	%rsp, %r10
	leaq	-232(%rsp), %rsp
	andq	$-8, %rsp
	movq	%rdi, (%rsp)
	movq	%rsi, 8(%rsp)
	movq	%rdx, 16(%rsp)
	movq	%rcx, 24(%rsp)
	movq	%r8, 32(%rsp)
	movq	(%rsp), %rax
	addq	$48, %rax
	movq	8(%rsp), %rcx
	movq	(%rcx), %rdx
	movq	%rdx, 40(%rsp)
	movq	8(%rcx), %rdx
	movq	%rdx, 48(%rsp)
	movq	16(%rcx), %rdx
	movq	%rdx, 56(%rsp)
	movq	24(%rcx), %rdx
	movq	%rdx, 64(%rsp)
	movq	32(%rcx), %rdx
	movq	%rdx, 72(%rsp)
	movq	40(%rcx), %rdx
	movq	%rdx, 80(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rdx
	movq	%rdx, 24(%rcx)
	movq	32(%rax), %rdx
	movq	%rdx, 32(%rcx)
	movq	40(%rax), %rdx
	movq	%rdx, 40(%rcx)
	movq	40(%rsp), %rcx
	movq	%rcx, (%rax)
	movq	48(%rsp), %rcx
	movq	%rcx, 8(%rax)
	movq	56(%rsp), %rcx
	movq	%rcx, 16(%rax)
	movq	64(%rsp), %rcx
	movq	%rcx, 24(%rax)
	movq	72(%rsp), %rcx
	movq	%rcx, 32(%rax)
	movq	80(%rsp), %rcx
	movq	%rcx, 40(%rax)
	movq	(%rsp), %rax
	addq	$96, %rax
	movq	16(%rsp), %rcx
	movq	(%rcx), %rdx
	movq	%rdx, 40(%rsp)
	movq	8(%rcx), %rdx
	movq	%rdx, 48(%rsp)
	movq	16(%rcx), %rdx
	movq	%rdx, 56(%rsp)
	movq	24(%rcx), %rdx
	movq	%rdx, 64(%rsp)
	movq	32(%rcx), %rdx
	movq	%rdx, 72(%rsp)
	movq	40(%rcx), %rdx
	movq	%rdx, 80(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rdx
	movq	%rdx, 24(%rcx)
	movq	32(%rax), %rdx
	movq	%rdx, 32(%rcx)
	movq	40(%rax), %rdx
	movq	%rdx, 40(%rcx)
	movq	40(%rsp), %rcx
	movq	%rcx, (%rax)
	movq	48(%rsp), %rcx
	movq	%rcx, 8(%rax)
	movq	56(%rsp), %rcx
	movq	%rcx, 16(%rax)
	movq	64(%rsp), %rcx
	movq	%rcx, 24(%rax)
	movq	72(%rsp), %rcx
	movq	%rcx, 32(%rax)
	movq	80(%rsp), %rcx
	movq	%rcx, 40(%rax)
	movq	(%rsp), %rax
	addq	$144, %rax
	movq	24(%rsp), %rcx
	movq	(%rcx), %rdx
	movq	%rdx, 40(%rsp)
	movq	8(%rcx), %rdx
	movq	%rdx, 48(%rsp)
	movq	16(%rcx), %rdx
	movq	%rdx, 56(%rsp)
	movq	24(%rcx), %rdx
	movq	%rdx, 64(%rsp)
	movq	32(%rcx), %rdx
	movq	%rdx, 72(%rsp)
	movq	40(%rcx), %rdx
	movq	%rdx, 80(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rdx
	movq	%rdx, 24(%rcx)
	movq	32(%rax), %rdx
	movq	%rdx, 32(%rcx)
	movq	40(%rax), %rdx
	movq	%rdx, 40(%rcx)
	movq	40(%rsp), %rcx
	movq	%rcx, (%rax)
	movq	48(%rsp), %rcx
	movq	%rcx, 8(%rax)
	movq	56(%rsp), %rcx
	movq	%rcx, 16(%rax)
	movq	64(%rsp), %rcx
	movq	%rcx, 24(%rax)
	movq	72(%rsp), %rcx
	movq	%rcx, 32(%rax)
	movq	80(%rsp), %rcx
	movq	%rcx, 40(%rax)
	movq	(%rsp), %rax
	addq	$192, %rax
	movq	32(%rsp), %rcx
	movq	(%rcx), %rdx
	movq	%rdx, 40(%rsp)
	movq	8(%rcx), %rdx
	movq	%rdx, 48(%rsp)
	movq	16(%rcx), %rdx
	movq	%rdx, 56(%rsp)
	movq	24(%rcx), %rdx
	movq	%rdx, 64(%rsp)
	movq	32(%rcx), %rdx
	movq	%rdx, 72(%rsp)
	movq	40(%rcx), %rdx
	movq	%rdx, 80(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rdx
	movq	%rdx, 24(%rcx)
	movq	32(%rax), %rdx
	movq	%rdx, 32(%rcx)
	movq	40(%rax), %rdx
	movq	%rdx, 40(%rcx)
	movq	40(%rsp), %rcx
	movq	%rcx, (%rax)
	movq	48(%rsp), %rcx
	movq	%rcx, 8(%rax)
	movq	56(%rsp), %rcx
	movq	%rcx, 16(%rax)
	movq	64(%rsp), %rcx
	movq	%rcx, 24(%rax)
	movq	72(%rsp), %rcx
	movq	%rcx, 32(%rax)
	movq	80(%rsp), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rax
	addq	$96, %rax
	movq	16(%rsp), %rcx
	addq	$48, %rcx
	movq	(%rcx), %rdx
	movq	%rdx, 40(%rsp)
	movq	8(%rcx), %rdx
	movq	%rdx, 48(%rsp)
	movq	16(%rcx), %rdx
	movq	%rdx, 56(%rsp)
	movq	24(%rcx), %rdx
	movq	%rdx, 64(%rsp)
	movq	32(%rcx), %rdx
	movq	%rdx, 72(%rsp)
	movq	40(%rcx), %rdx
	movq	%rdx, 80(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rdx
	movq	%rdx, 24(%rcx)
	movq	32(%rax), %rdx
	movq	%rdx, 32(%rcx)
	movq	40(%rax), %rdx
	movq	%rdx, 40(%rcx)
	movq	40(%rsp), %rcx
	movq	%rcx, (%rax)
	movq	48(%rsp), %rcx
	movq	%rcx, 8(%rax)
	movq	56(%rsp), %rcx
	movq	%rcx, 16(%rax)
	movq	64(%rsp), %rcx
	movq	%rcx, 24(%rax)
	movq	72(%rsp), %rcx
	movq	%rcx, 32(%rax)
	movq	80(%rsp), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rax
	addq	$144, %rax
	movq	24(%rsp), %rcx
	addq	$48, %rcx
	movq	(%rcx), %rdx
	movq	%rdx, 40(%rsp)
	movq	8(%rcx), %rdx
	movq	%rdx, 48(%rsp)
	movq	16(%rcx), %rdx
	movq	%rdx, 56(%rsp)
	movq	24(%rcx), %rdx
	movq	%rdx, 64(%rsp)
	movq	32(%rcx), %rdx
	movq	%rdx, 72(%rsp)
	movq	40(%rcx), %rdx
	movq	%rdx, 80(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rdx
	movq	%rdx, 24(%rcx)
	movq	32(%rax), %rdx
	movq	%rdx, 32(%rcx)
	movq	40(%rax), %rdx
	movq	%rdx, 40(%rcx)
	movq	40(%rsp), %rcx
	movq	%rcx, (%rax)
	movq	48(%rsp), %rcx
	movq	%rcx, 8(%rax)
	movq	56(%rsp), %rcx
	movq	%rcx, 16(%rax)
	movq	64(%rsp), %rcx
	movq	%rcx, 24(%rax)
	movq	72(%rsp), %rcx
	movq	%rcx, 32(%rax)
	movq	80(%rsp), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rax
	addq	$192, %rax
	movq	32(%rsp), %rcx
	addq	$48, %rcx
	movq	(%rcx), %rdx
	movq	%rdx, 40(%rsp)
	movq	8(%rcx), %rdx
	movq	%rdx, 48(%rsp)
	movq	16(%rcx), %rdx
	movq	%rdx, 56(%rsp)
	movq	24(%rcx), %rdx
	movq	%rdx, 64(%rsp)
	movq	32(%rcx), %rdx
	movq	%rdx, 72(%rsp)
	movq	40(%rcx), %rdx
	movq	%rdx, 80(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rdx
	movq	%rdx, 24(%rcx)
	movq	32(%rax), %rdx
	movq	%rdx, 32(%rcx)
	movq	40(%rax), %rdx
	movq	%rdx, 40(%rcx)
	movq	40(%rsp), %rcx
	movq	%rcx, (%rax)
	movq	48(%rsp), %rcx
	movq	%rcx, 8(%rax)
	movq	56(%rsp), %rcx
	movq	%rcx, 16(%rax)
	movq	64(%rsp), %rcx
	movq	%rcx, 24(%rax)
	movq	72(%rsp), %rcx
	movq	%rcx, 32(%rax)
	movq	80(%rsp), %rcx
	movq	%rcx, 40(%rax)
	movq	16(%rsp), %rax
	addq	$144, %rax
	movq	24(%rsp), %rcx
	addq	$96, %rcx
	movq	(%rcx), %rdx
	movq	%rdx, 40(%rsp)
	movq	8(%rcx), %rdx
	movq	%rdx, 48(%rsp)
	movq	16(%rcx), %rdx
	movq	%rdx, 56(%rsp)
	movq	24(%rcx), %rdx
	movq	%rdx, 64(%rsp)
	movq	32(%rcx), %rdx
	movq	%rdx, 72(%rsp)
	movq	40(%rcx), %rdx
	movq	%rdx, 80(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rdx
	movq	%rdx, 24(%rcx)
	movq	32(%rax), %rdx
	movq	%rdx, 32(%rcx)
	movq	40(%rax), %rdx
	movq	%rdx, 40(%rcx)
	movq	40(%rsp), %rcx
	movq	%rcx, (%rax)
	movq	48(%rsp), %rcx
	movq	%rcx, 8(%rax)
	movq	56(%rsp), %rcx
	movq	%rcx, 16(%rax)
	movq	64(%rsp), %rcx
	movq	%rcx, 24(%rax)
	movq	72(%rsp), %rcx
	movq	%rcx, 32(%rax)
	movq	80(%rsp), %rcx
	movq	%rcx, 40(%rax)
	movq	16(%rsp), %rax
	addq	$192, %rax
	movq	32(%rsp), %rcx
	addq	$96, %rcx
	movq	(%rcx), %rdx
	movq	%rdx, 40(%rsp)
	movq	8(%rcx), %rdx
	movq	%rdx, 48(%rsp)
	movq	16(%rcx), %rdx
	movq	%rdx, 56(%rsp)
	movq	24(%rcx), %rdx
	movq	%rdx, 64(%rsp)
	movq	32(%rcx), %rdx
	movq	%rdx, 72(%rsp)
	movq	40(%rcx), %rdx
	movq	%rdx, 80(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rdx
	movq	%rdx, 24(%rcx)
	movq	32(%rax), %rdx
	movq	%rdx, 32(%rcx)
	movq	40(%rax), %rdx
	movq	%rdx, 40(%rcx)
	movq	40(%rsp), %rcx
	movq	%rcx, (%rax)
	movq	48(%rsp), %rcx
	movq	%rcx, 8(%rax)
	movq	56(%rsp), %rcx
	movq	%rcx, 16(%rax)
	movq	64(%rsp), %rcx
	movq	%rcx, 24(%rax)
	movq	72(%rsp), %rcx
	movq	%rcx, 32(%rax)
	movq	80(%rsp), %rcx
	movq	%rcx, 40(%rax)
	movq	24(%rsp), %rax
	addq	$192, %rax
	movq	32(%rsp), %rcx
	addq	$144, %rcx
	movq	(%rcx), %rdx
	movq	%rdx, 40(%rsp)
	movq	8(%rcx), %rdx
	movq	%rdx, 48(%rsp)
	movq	16(%rcx), %rdx
	movq	%rdx, 56(%rsp)
	movq	24(%rcx), %rdx
	movq	%rdx, 64(%rsp)
	movq	32(%rcx), %rdx
	movq	%rdx, 72(%rsp)
	movq	40(%rcx), %rdx
	movq	%rdx, 80(%rsp)
	movq	(%rax), %rdx
	movq	%rdx, (%rcx)
	movq	8(%rax), %rdx
	movq	%rdx, 8(%rcx)
	movq	16(%rax), %rdx
	movq	%rdx, 16(%rcx)
	movq	24(%rax), %rdx
	movq	%rdx, 24(%rcx)
	movq	32(%rax), %rdx
	movq	%rdx, 32(%rcx)
	movq	40(%rax), %rdx
	movq	%rdx, 40(%rcx)
	movq	40(%rsp), %rcx
	movq	%rcx, (%rax)
	movq	48(%rsp), %rcx
	movq	%rcx, 8(%rax)
	movq	56(%rsp), %rcx
	movq	%rcx, 16(%rax)
	movq	64(%rsp), %rcx
	movq	%rcx, 24(%rax)
	movq	72(%rsp), %rcx
	movq	%rcx, 32(%rax)
	movq	80(%rsp), %rcx
	movq	%rcx, 40(%rax)
	movq	%r10, %rsp
	ret 
_out_end5:
out_end5:
	movq	%rsp, %r10
	leaq	-24(%rsp), %rsp
	andq	$-8, %rsp
	movq	%rsi, (%rsp)
	movq	%rdx, 8(%rsp)
	movq	(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, (%rdx)
	movq	(%rsp), %rax
	addq	$8, %rax
	movq	%rax, 16(%rsp)
	movq	16(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	(%rsp), %rax
	addq	$16, %rax
	movq	%rax, 16(%rsp)
	movq	16(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	(%rsp), %rax
	addq	$24, %rax
	movq	%rax, 16(%rsp)
	movq	16(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	(%rsp), %rax
	addq	$32, %rax
	movq	%rax, 16(%rsp)
	movq	16(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	(%rsp), %rax
	addq	$40, %rax
	movq	%rax, 16(%rsp)
	movq	16(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	(%rsp), %rax
	addq	$48, %rax
	movq	%rax, 16(%rsp)
	movq	16(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	(%rsp), %rax
	addq	$48, %rax
	addq	$8, %rax
	movq	%rax, 16(%rsp)
	movq	16(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	(%rsp), %rax
	addq	$48, %rax
	addq	$24, %rax
	movq	%rax, 16(%rsp)
	movq	16(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	(%rsp), %rax
	addq	$96, %rax
	addq	$8, %rax
	movq	%rax, (%rsp)
	movq	(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	%r10, %rsp
	ret 
_out_start5:
out_start5:
	imulq	$6, %rdx, %rax
	imulq	$8, %rax, %rax
	addq	%rax, %rsi
	movq	%rcx, %rax
	movq	(%rsi), %rdx
	movq	%rdx, (%rax)
	movq	8(%rsi), %rdx
	movq	%rdx, 8(%rax)
	movq	16(%rsi), %rdx
	movq	%rdx, 16(%rax)
	movq	24(%rsi), %rdx
	movq	%rdx, 24(%rax)
	movq	32(%rsi), %rdx
	movq	%rdx, 32(%rax)
	movq	40(%rsi), %rdx
	movq	%rdx, 40(%rax)
	movq	%rcx, %rax
	addq	$48, %rax
	movq	(%rsi), %rdx
	movq	%rdx, (%rax)
	movq	8(%rsi), %rdx
	movq	%rdx, 8(%rax)
	movq	16(%rsi), %rdx
	movq	%rdx, 16(%rax)
	movq	24(%rsi), %rdx
	movq	%rdx, 24(%rax)
	movq	32(%rsi), %rdx
	movq	%rdx, 32(%rax)
	movq	40(%rsi), %rdx
	movq	%rdx, 40(%rax)
	movq	%rcx, %rax
	addq	$96, %rax
	movq	(%rsi), %rdx
	movq	%rdx, (%rax)
	movq	8(%rsi), %rdx
	movq	%rdx, 8(%rax)
	movq	16(%rsi), %rdx
	movq	%rdx, 16(%rax)
	movq	24(%rsi), %rdx
	movq	%rdx, 24(%rax)
	movq	32(%rsi), %rdx
	movq	%rdx, 32(%rax)
	movq	40(%rsi), %rdx
	movq	%rdx, 40(%rax)
	movq	%rcx, %rax
	addq	$144, %rax
	movq	(%rsi), %rdx
	movq	%rdx, (%rax)
	movq	8(%rsi), %rdx
	movq	%rdx, 8(%rax)
	movq	16(%rsi), %rdx
	movq	%rdx, 16(%rax)
	movq	24(%rsi), %rdx
	movq	%rdx, 24(%rax)
	movq	32(%rsi), %rdx
	movq	%rdx, 32(%rax)
	movq	40(%rsi), %rdx
	movq	%rdx, 40(%rax)
	addq	$192, %rcx
	movq	(%rsi), %rax
	movq	%rax, (%rcx)
	movq	8(%rsi), %rax
	movq	%rax, 8(%rcx)
	movq	16(%rsi), %rax
	movq	%rax, 16(%rcx)
	movq	24(%rsi), %rax
	movq	%rax, 24(%rcx)
	movq	32(%rsi), %rax
	movq	%rax, 32(%rcx)
	movq	40(%rsi), %rax
	movq	%rax, 40(%rcx)
	ret 
_mult_end5:
mult_end5:
	movq	%rsp, %r10
	leaq	-48(%rsp), %rsp
	andq	$-8, %rsp
	movq	%rcx, (%rsp)
	imulq	$6, %rcx, %rax
	imulq	$8, %rax, %rax
	movq	%rsi, 8(%rsp)
	addq	%rax, %rdx
	movq	%rdx, 16(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 24(%rsp)
	movq	24(%rsp), %rax
	movq	16(%rsp), %rcx
	movq	(%rax), %rax
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	addq	$8, %rax
	movq	16(%rsp), %rcx
	addq	$8, %rcx
	movq	(%rax), %rax
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	addq	$16, %rax
	movq	16(%rsp), %rcx
	addq	$16, %rcx
	movq	(%rax), %rax
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	addq	$24, %rax
	movq	16(%rsp), %rcx
	addq	$24, %rcx
	movq	(%rax), %rax
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	addq	$32, %rax
	movq	16(%rsp), %rcx
	addq	$32, %rcx
	movq	(%rax), %rax
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	addq	$40, %rax
	movq	16(%rsp), %rcx
	addq	$40, %rcx
	movq	(%rax), %rax
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	addq	$48, %rax
	movq	%rax, 24(%rsp)
	movq	24(%rsp), %rax
	movq	%rax, 32(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 40(%rsp)
	movq	32(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	40(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	addq	$8, %rax
	movq	%rax, 40(%rsp)
	movq	16(%rsp), %rax
	addq	$8, %rax
	movq	%rax, 32(%rsp)
	movq	40(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	addq	$16, %rax
	movq	%rax, 32(%rsp)
	movq	16(%rsp), %rax
	addq	$16, %rax
	movq	%rax, 40(%rsp)
	movq	32(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	40(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	addq	$24, %rax
	movq	%rax, 40(%rsp)
	movq	16(%rsp), %rax
	addq	$24, %rax
	movq	%rax, 32(%rsp)
	movq	40(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	addq	$32, %rax
	movq	%rax, 32(%rsp)
	movq	16(%rsp), %rax
	addq	$32, %rax
	movq	%rax, 40(%rsp)
	movq	32(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	40(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	addq	$40, %rax
	movq	%rax, 24(%rsp)
	movq	16(%rsp), %rax
	addq	$40, %rax
	movq	%rax, 40(%rsp)
	movq	24(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	40(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	addq	$96, %rax
	movq	%rax, 40(%rsp)
	movq	40(%rsp), %rax
	movq	%rax, 24(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 32(%rsp)
	movq	24(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	40(%rsp), %rax
	addq	$8, %rax
	movq	%rax, 32(%rsp)
	movq	16(%rsp), %rax
	addq	$8, %rax
	movq	%rax, 24(%rsp)
	movq	32(%rsp), %rax
	movq	24(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	24(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	40(%rsp), %rax
	addq	$16, %rax
	movq	%rax, 24(%rsp)
	movq	16(%rsp), %rax
	addq	$16, %rax
	movq	%rax, 32(%rsp)
	movq	24(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	40(%rsp), %rax
	addq	$24, %rax
	movq	%rax, 32(%rsp)
	movq	16(%rsp), %rax
	addq	$24, %rax
	movq	%rax, 24(%rsp)
	movq	32(%rsp), %rax
	movq	24(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	24(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	40(%rsp), %rax
	addq	$32, %rax
	movq	%rax, 24(%rsp)
	movq	16(%rsp), %rax
	addq	$32, %rax
	movq	%rax, 32(%rsp)
	movq	24(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	40(%rsp), %rax
	addq	$40, %rax
	movq	%rax, 40(%rsp)
	movq	16(%rsp), %rax
	addq	$40, %rax
	movq	%rax, 32(%rsp)
	movq	40(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	addq	$144, %rax
	movq	%rax, 32(%rsp)
	movq	32(%rsp), %rax
	movq	%rax, 40(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 24(%rsp)
	movq	40(%rsp), %rax
	movq	24(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	24(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	32(%rsp), %rax
	addq	$8, %rax
	movq	%rax, 24(%rsp)
	movq	16(%rsp), %rax
	addq	$8, %rax
	movq	%rax, 40(%rsp)
	movq	24(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	40(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	32(%rsp), %rax
	addq	$16, %rax
	movq	%rax, 40(%rsp)
	movq	16(%rsp), %rax
	addq	$16, %rax
	movq	%rax, 24(%rsp)
	movq	40(%rsp), %rax
	movq	24(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	24(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	32(%rsp), %rax
	addq	$24, %rax
	movq	%rax, 24(%rsp)
	movq	16(%rsp), %rax
	addq	$24, %rax
	movq	%rax, 40(%rsp)
	movq	24(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	40(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	32(%rsp), %rax
	addq	$32, %rax
	movq	%rax, 40(%rsp)
	movq	16(%rsp), %rax
	addq	$32, %rax
	movq	%rax, 24(%rsp)
	movq	40(%rsp), %rax
	movq	24(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	24(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	32(%rsp), %rax
	addq	$40, %rax
	movq	%rax, 32(%rsp)
	movq	16(%rsp), %rax
	addq	$40, %rax
	movq	%rax, 24(%rsp)
	movq	32(%rsp), %rax
	movq	24(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	24(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	addq	$192, %rax
	movq	%rax, 8(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 24(%rsp)
	movq	16(%rsp), %rax
	movq	%rax, 32(%rsp)
	movq	24(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	addq	$8, %rax
	movq	%rax, 32(%rsp)
	movq	16(%rsp), %rax
	addq	$8, %rax
	movq	%rax, 24(%rsp)
	movq	32(%rsp), %rax
	movq	24(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	24(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	addq	$16, %rax
	movq	%rax, 24(%rsp)
	movq	16(%rsp), %rax
	addq	$16, %rax
	movq	%rax, 32(%rsp)
	movq	24(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	addq	$24, %rax
	movq	%rax, 32(%rsp)
	movq	16(%rsp), %rax
	addq	$24, %rax
	movq	%rax, 24(%rsp)
	movq	32(%rsp), %rax
	movq	24(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	24(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	addq	$32, %rax
	movq	%rax, 24(%rsp)
	movq	16(%rsp), %rax
	addq	$32, %rax
	movq	%rax, 32(%rsp)
	movq	24(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	addq	$40, %rax
	movq	%rax, 8(%rsp)
	movq	16(%rsp), %rax
	addq	$40, %rax
	movq	%rax, 16(%rsp)
	movq	8(%rsp), %rax
	movq	16(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	16(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	(%rsp), %rax
	incq	%rax
	movq	%r10, %rsp
	ret 
_mult_start5:
mult_start5:
	movq	%rsp, %r11
	leaq	-64(%rsp), %rsp
	andq	$-8, %rsp
	movq	$0, (%r8)
	movq	%r9, (%rsp)
	movq	%r8, 8(%rsp)
	movq	%rsi, 16(%rsp)
	movq	%rdx, 24(%rsp)
	movq	%rcx, 32(%rsp)
	addq	$8, %r8
	movq	%r8, 40(%rsp)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	imulq	$6, 32(%rsp), %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 56(%rsp)
	movq	48(%rsp), %rax
	movq	56(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	mulq	%rcx
	divq	%rdi
	movq	40(%rsp), %rax
	movq	%rdx, (%rax)
	movq	40(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	imulq	$6, 32(%rsp), %rcx
	incq	%rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 56(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 48(%rsp)
	movq	56(%rsp), %rax
	movq	48(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	mulq	%rcx
	divq	%rdi
	movq	40(%rsp), %rax
	movq	%rdx, (%rax)
	movq	40(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	imulq	$6, 32(%rsp), %rcx
	addq	$2, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 56(%rsp)
	movq	48(%rsp), %rax
	movq	56(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	mulq	%rcx
	divq	%rdi
	movq	40(%rsp), %rax
	movq	%rdx, (%rax)
	movq	40(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	imulq	$6, 32(%rsp), %rcx
	addq	$4, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 56(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 48(%rsp)
	movq	56(%rsp), %rax
	movq	48(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	mulq	%rcx
	divq	%rdi
	movq	40(%rsp), %rax
	movq	%rdx, (%rax)
	movq	40(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	incq	%rax
	imulq	$6, 32(%rsp), %rcx
	addq	$3, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 56(%rsp)
	movq	48(%rsp), %rax
	movq	56(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	mulq	%rcx
	divq	%rdi
	movq	40(%rsp), %rax
	movq	%rdx, (%rax)
	movq	40(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	incq	%rax
	imulq	$6, 32(%rsp), %rcx
	addq	$4, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 56(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 48(%rsp)
	movq	56(%rsp), %rax
	movq	48(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	mulq	%rcx
	divq	%rdi
	movq	40(%rsp), %rax
	movq	%rdx, (%rax)
	movq	40(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	incq	%rax
	imulq	$6, 32(%rsp), %rcx
	addq	$5, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 56(%rsp)
	movq	48(%rsp), %rax
	movq	56(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	mulq	%rcx
	divq	%rdi
	movq	40(%rsp), %rax
	movq	%rdx, (%rax)
	movq	40(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	addq	$2, %rax
	imulq	$6, 32(%rsp), %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 56(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 48(%rsp)
	movq	56(%rsp), %rax
	movq	48(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	mulq	%rcx
	divq	%rdi
	movq	40(%rsp), %rax
	movq	%rdx, (%rax)
	movq	40(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	addq	$2, %rax
	imulq	$6, 32(%rsp), %rcx
	addq	$2, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 56(%rsp)
	movq	48(%rsp), %rax
	movq	56(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	mulq	%rcx
	divq	%rdi
	movq	40(%rsp), %rax
	movq	%rdx, (%rax)
	movq	40(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	addq	$2, %rax
	imulq	$6, 32(%rsp), %rcx
	addq	$3, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 56(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 48(%rsp)
	movq	56(%rsp), %rax
	movq	48(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	mulq	%rcx
	divq	%rdi
	movq	40(%rsp), %rax
	movq	%rdx, (%rax)
	movq	40(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	addq	$2, %rax
	imulq	$6, 32(%rsp), %rcx
	addq	$4, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 56(%rsp)
	movq	48(%rsp), %rax
	movq	56(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	mulq	%rcx
	divq	%rdi
	movq	40(%rsp), %rax
	movq	%rdx, (%rax)
	movq	40(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	addq	$3, %rax
	imulq	$6, 32(%rsp), %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 56(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 48(%rsp)
	movq	56(%rsp), %rax
	movq	48(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	mulq	%rcx
	divq	%rdi
	movq	40(%rsp), %rax
	movq	%rdx, (%rax)
	movq	40(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	addq	$3, %rax
	imulq	$6, 32(%rsp), %rcx
	incq	%rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 56(%rsp)
	movq	48(%rsp), %rax
	movq	56(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	mulq	%rcx
	divq	%rdi
	movq	40(%rsp), %rax
	movq	%rdx, (%rax)
	movq	40(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	addq	$3, %rax
	imulq	$6, 32(%rsp), %rcx
	addq	$2, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 56(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 48(%rsp)
	movq	56(%rsp), %rax
	movq	48(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	mulq	%rcx
	divq	%rdi
	movq	40(%rsp), %rax
	movq	%rdx, (%rax)
	movq	40(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	addq	$3, %rax
	imulq	$6, 32(%rsp), %rcx
	addq	$5, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 56(%rsp)
	movq	48(%rsp), %rax
	movq	56(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	mulq	%rcx
	divq	%rdi
	movq	40(%rsp), %rax
	movq	%rdx, (%rax)
	movq	40(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	addq	$4, %rax
	imulq	$6, 32(%rsp), %rcx
	incq	%rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 56(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 48(%rsp)
	movq	56(%rsp), %rax
	movq	48(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	mulq	%rcx
	divq	%rdi
	movq	40(%rsp), %rax
	movq	%rdx, (%rax)
	movq	40(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	addq	$4, %rax
	imulq	$6, 32(%rsp), %rcx
	addq	$2, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 56(%rsp)
	movq	48(%rsp), %rax
	movq	56(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	mulq	%rcx
	divq	%rdi
	movq	40(%rsp), %rax
	movq	%rdx, (%rax)
	movq	40(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	addq	$4, %rax
	imulq	$6, 32(%rsp), %rcx
	addq	$3, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 56(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 48(%rsp)
	movq	56(%rsp), %rax
	movq	48(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	mulq	%rcx
	divq	%rdi
	movq	40(%rsp), %rax
	movq	%rdx, (%rax)
	movq	40(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	addq	$5, %rax
	imulq	$6, 32(%rsp), %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 56(%rsp)
	movq	48(%rsp), %rax
	movq	56(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	mulq	%rcx
	divq	%rdi
	movq	40(%rsp), %rax
	movq	%rdx, (%rax)
	movq	40(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	imulq	$6, %rax, %rax
	addq	$5, %rax
	imulq	$6, 32(%rsp), %rcx
	addq	$3, %rcx
	imulq	$8, %rax, %rax
	movq	16(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 32(%rsp)
	imulq	$8, %rcx, %rax
	movq	16(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 16(%rsp)
	movq	32(%rsp), %rax
	movq	16(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	mulq	%rcx
	divq	%rdi
	movq	40(%rsp), %rax
	movq	%rdx, (%rax)
	movq	40(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	40(%rsp), %rdx
	movq	%rax, 16(%rsp)
	movq	(%rcx), %rax
	movq	%rax, (%rdx)
	movq	(%rsp), %rax
	addq	$8, %rax
	movq	%rax, 32(%rsp)
	movq	40(%rsp), %rax
	movq	%rax, 24(%rsp)
	movq	32(%rsp), %rax
	movq	24(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	24(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	(%rsp), %rax
	addq	$16, %rax
	movq	%rax, 24(%rsp)
	movq	40(%rsp), %rax
	movq	%rax, 32(%rsp)
	movq	24(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	(%rsp), %rax
	addq	$24, %rax
	movq	%rax, 32(%rsp)
	movq	40(%rsp), %rax
	movq	%rax, 24(%rsp)
	movq	32(%rsp), %rax
	movq	24(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	24(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	(%rsp), %rax
	addq	$32, %rax
	movq	%rax, 24(%rsp)
	movq	40(%rsp), %rax
	movq	%rax, 32(%rsp)
	movq	24(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	(%rsp), %rax
	addq	$40, %rax
	movq	%rax, 32(%rsp)
	movq	40(%rsp), %rax
	movq	%rax, 24(%rsp)
	movq	32(%rsp), %rax
	movq	24(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	24(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	(%rsp), %rax
	addq	$48, %rax
	movq	%rax, 24(%rsp)
	movq	40(%rsp), %rax
	movq	%rax, 32(%rsp)
	movq	24(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	(%rsp), %rax
	addq	$56, %rax
	movq	%rax, 32(%rsp)
	movq	40(%rsp), %rax
	movq	%rax, 24(%rsp)
	movq	32(%rsp), %rax
	movq	24(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	24(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	(%rsp), %rax
	addq	$64, %rax
	movq	%rax, 24(%rsp)
	movq	40(%rsp), %rax
	movq	%rax, 40(%rsp)
	movq	24(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	40(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	subq	%rcx, %rax
	cmovb	%rdi, %rdx
	addq	%rdx, %rax
	movq	40(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	(%rsp), %rax
	movq	%rax, %rcx
	movq	8(%rsp), %rdx
	addq	$40, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$16, %rdx
	addq	$64, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$56, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$32, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$48, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$8, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$16, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	addq	$8, %rdx
	movq	8(%rsp), %rcx
	addq	$8, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$24, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$64, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$56, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$48, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$16, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$40, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	addq	$8, %rdx
	movq	8(%rsp), %rcx
	addq	$8, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$24, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$24, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$64, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$32, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$48, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$8, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$56, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$32, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$8, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$16, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	addq	$8, %rdx
	addq	$40, %rax
	movq	(%rax), %rax
	movq	%rax, (%rdx)
	movq	%r11, %rsp
	ret 
_Smult5:
Smult5:
	movq	%rsp, %r10
	leaq	-48(%rsp), %rsp
	andq	$-8, %rsp
	movq	%rsi, (%rsp)
	movq	%rdx, 8(%rsp)
	movq	%r8, 16(%rsp)
	imulq	$6, %rcx, %rax
	imulq	$8, %rax, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 24(%rsp)
	movq	8(%rsp), %rax
	movq	16(%rsp), %rcx
	imulq	$6, %rax, %rax
	imulq	$6, %rcx, %rcx
	imulq	$8, %rax, %rax
	movq	(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 32(%rsp)
	imulq	$8, %rcx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	movq	32(%rsp), %rax
	movq	24(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	mulq	%rcx
	divq	%rdi
	movq	40(%rsp), %rax
	movq	%rdx, (%rax)
	movq	8(%rsp), %rax
	movq	16(%rsp), %rcx
	imulq	$6, %rax, %rax
	incq	%rax
	imulq	$6, %rcx, %rcx
	incq	%rcx
	imulq	$8, %rax, %rax
	movq	(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 40(%rsp)
	imulq	$8, %rcx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 32(%rsp)
	movq	40(%rsp), %rax
	movq	24(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	mulq	%rcx
	divq	%rdi
	movq	32(%rsp), %rax
	movq	%rdx, (%rax)
	movq	8(%rsp), %rax
	movq	16(%rsp), %rcx
	imulq	$6, %rax, %rax
	addq	$2, %rax
	imulq	$6, %rcx, %rcx
	addq	$2, %rcx
	imulq	$8, %rax, %rax
	movq	(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 32(%rsp)
	imulq	$8, %rcx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	movq	32(%rsp), %rax
	movq	24(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	mulq	%rcx
	divq	%rdi
	movq	40(%rsp), %rax
	movq	%rdx, (%rax)
	movq	8(%rsp), %rax
	movq	16(%rsp), %rcx
	imulq	$6, %rax, %rax
	addq	$3, %rax
	imulq	$6, %rcx, %rcx
	addq	$3, %rcx
	imulq	$8, %rax, %rax
	movq	(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 40(%rsp)
	imulq	$8, %rcx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 32(%rsp)
	movq	40(%rsp), %rax
	movq	24(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	mulq	%rcx
	divq	%rdi
	movq	32(%rsp), %rax
	movq	%rdx, (%rax)
	movq	8(%rsp), %rax
	movq	16(%rsp), %rcx
	imulq	$6, %rax, %rax
	addq	$4, %rax
	imulq	$6, %rcx, %rcx
	addq	$4, %rcx
	imulq	$8, %rax, %rax
	movq	(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 32(%rsp)
	imulq	$8, %rcx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	movq	32(%rsp), %rax
	movq	24(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	mulq	%rcx
	divq	%rdi
	movq	40(%rsp), %rax
	movq	%rdx, (%rax)
	movq	8(%rsp), %rax
	movq	16(%rsp), %rcx
	imulq	$6, %rax, %rax
	addq	$5, %rax
	imulq	$6, %rcx, %rcx
	addq	$5, %rcx
	imulq	$8, %rax, %rax
	movq	(%rsp), %rdx
	addq	%rax, %rdx
	movq	%rdx, 8(%rsp)
	imulq	$8, %rcx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, (%rsp)
	movq	8(%rsp), %rax
	movq	24(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	mulq	%rcx
	divq	%rdi
	movq	(%rsp), %rax
	movq	%rdx, (%rax)
	movq	16(%rsp), %rax
	incq	%rax
	movq	%r10, %rsp
	ret 
_const_end5:
const_end5:
	movq	%rcx, %rax
	imulq	$6, %rax, %rcx
	imulq	$8, %rcx, %rcx
	addq	%rcx, %rdx
	movq	(%rsi), %rcx
	movq	%rcx, (%rdx)
	movq	8(%rsi), %rcx
	movq	%rcx, 8(%rdx)
	movq	16(%rsi), %rcx
	movq	%rcx, 16(%rdx)
	movq	24(%rsi), %rcx
	movq	%rcx, 24(%rdx)
	movq	32(%rsi), %rcx
	movq	%rcx, 32(%rdx)
	movq	40(%rsi), %rcx
	movq	%rcx, 40(%rdx)
	incq	%rax
	ret 
_const_start5:
const_start5:
	movq	%rsp, %r10
	leaq	-24(%rsp), %rsp
	andq	$-8, %rsp
	movq	%rsi, (%rsp)
	movq	%rdx, 8(%rsp)
	movq	$0, (%rdx)
	addq	$16, %rdx
	movq	%rdx, 16(%rsp)
	movq	8(%rsp), %rax
	movq	(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	subq	%rcx, %rax
	cmovb	%rdi, %rdx
	addq	%rdx, %rax
	movq	16(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	(%rsp), %rax
	movq	16(%rsp), %rcx
	movq	8(%rsp), %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	$0, (%rdx)
	addq	$8, %rdx
	addq	$8, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	$0, (%rdx)
	addq	$8, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	$0, (%rdx)
	addq	$8, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rcx), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rax), %rsi
	movq	%rsi, (%rdx)
	addq	$8, %rdx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	addq	$8, %rdx
	movq	(%rax), %rax
	movq	%rax, (%rdx)
	movq	%r10, %rsp
	ret 
_input_end5:
input_end5:
	movq	%rcx, %rax
	imulq	$6, %rax, %rcx
	imulq	$8, %rcx, %rcx
	addq	%rcx, %rdx
	movq	(%rsi), %rcx
	movq	%rcx, (%rdx)
	movq	8(%rsi), %rcx
	movq	%rcx, 8(%rdx)
	movq	16(%rsi), %rcx
	movq	%rcx, 16(%rdx)
	movq	24(%rsi), %rcx
	movq	%rcx, 24(%rdx)
	movq	32(%rsi), %rcx
	movq	%rcx, 32(%rdx)
	movq	40(%rsi), %rcx
	movq	%rcx, 40(%rdx)
	incq	%rax
	ret 
_input_start5:
input_start5:
	movq	%rsp, %r10
	leaq	-48(%rsp), %rsp
	andq	$-8, %rsp
	movq	%rdx, (%rsp)
	addq	$8, %rdx
	movq	%rdx, 8(%rsp)
	movq	%rcx, 16(%rsp)
	movq	16(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	%rsi, 24(%rsp)
	movq	(%rax), %rax
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$8, %rax
	movq	%rax, 32(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 40(%rsp)
	movq	32(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	40(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$16, %rax
	movq	%rax, 40(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 32(%rsp)
	movq	40(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$24, %rax
	movq	%rax, 32(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 40(%rsp)
	movq	32(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	40(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$32, %rax
	movq	%rax, 40(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 32(%rsp)
	movq	40(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$40, %rax
	movq	%rax, 32(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 40(%rsp)
	movq	32(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	40(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$48, %rax
	movq	%rax, 40(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 32(%rsp)
	movq	40(%rsp), %rax
	movq	32(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$56, %rax
	movq	%rax, 32(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 40(%rsp)
	movq	32(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	40(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	addq	$64, %rax
	movq	%rax, 40(%rsp)
	movq	8(%rsp), %rax
	movq	%rax, 8(%rsp)
	movq	40(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	subq	%rcx, %rax
	cmovb	%rdi, %rdx
	addq	%rdx, %rax
	movq	8(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	16(%rsp), %rax
	movq	%rax, %rcx
	movq	(%rsp), %rdx
	addq	$40, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$16, %rdx
	addq	$64, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$56, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$32, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$48, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$8, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$16, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	addq	$8, %rdx
	movq	(%rsp), %rcx
	addq	$8, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$24, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$64, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$56, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$48, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$16, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$40, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	addq	$8, %rdx
	movq	(%rsp), %rcx
	addq	$8, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$24, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$24, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$64, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$32, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$48, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$8, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$56, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$32, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$8, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	movq	%rax, %rcx
	addq	$8, %rdx
	addq	$16, %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rdx)
	addq	$8, %rdx
	addq	$40, %rax
	movq	(%rax), %rax
	movq	%rax, (%rdx)
	movq	%r10, %rsp
	ret 
_add5:
add5:
	movq	%rsp, %r10
	leaq	-56(%rsp), %rsp
	andq	$-8, %rsp
	movq	%rsi, (%rsp)
	movq	%rdx, 8(%rsp)
	movq	%rcx, 16(%rsp)
	movq	%r8, 24(%rsp)
	movq	8(%rsp), %rax
	movq	16(%rsp), %rcx
	movq	24(%rsp), %rdx
	imulq	$6, %rax, %rax
	imulq	$6, %rcx, %rcx
	imulq	$6, %rdx, %rdx
	imulq	$8, %rax, %rax
	movq	(%rsp), %rsi
	addq	%rax, %rsi
	movq	%rsi, 32(%rsp)
	imulq	$8, %rcx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	imulq	$8, %rdx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 48(%rsp)
	movq	32(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	48(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	movq	16(%rsp), %rcx
	movq	24(%rsp), %rdx
	imulq	$6, %rax, %rax
	incq	%rax
	imulq	$6, %rcx, %rcx
	incq	%rcx
	imulq	$6, %rdx, %rdx
	incq	%rdx
	imulq	$8, %rax, %rax
	movq	(%rsp), %rsi
	addq	%rax, %rsi
	movq	%rsi, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	imulq	$8, %rdx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 32(%rsp)
	movq	48(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	movq	16(%rsp), %rcx
	movq	24(%rsp), %rdx
	imulq	$6, %rax, %rax
	addq	$2, %rax
	imulq	$6, %rcx, %rcx
	addq	$2, %rcx
	imulq	$6, %rdx, %rdx
	addq	$2, %rdx
	imulq	$8, %rax, %rax
	movq	(%rsp), %rsi
	addq	%rax, %rsi
	movq	%rsi, 32(%rsp)
	imulq	$8, %rcx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	imulq	$8, %rdx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 48(%rsp)
	movq	32(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	48(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	movq	16(%rsp), %rcx
	movq	24(%rsp), %rdx
	imulq	$6, %rax, %rax
	addq	$3, %rax
	imulq	$6, %rcx, %rcx
	addq	$3, %rcx
	imulq	$6, %rdx, %rdx
	addq	$3, %rdx
	imulq	$8, %rax, %rax
	movq	(%rsp), %rsi
	addq	%rax, %rsi
	movq	%rsi, 48(%rsp)
	imulq	$8, %rcx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	imulq	$8, %rdx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 32(%rsp)
	movq	48(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	32(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	movq	16(%rsp), %rcx
	movq	24(%rsp), %rdx
	imulq	$6, %rax, %rax
	addq	$4, %rax
	imulq	$6, %rcx, %rcx
	addq	$4, %rcx
	imulq	$6, %rdx, %rdx
	addq	$4, %rdx
	imulq	$8, %rax, %rax
	movq	(%rsp), %rsi
	addq	%rax, %rsi
	movq	%rsi, 32(%rsp)
	imulq	$8, %rcx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 40(%rsp)
	imulq	$8, %rdx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 48(%rsp)
	movq	32(%rsp), %rax
	movq	40(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	48(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	8(%rsp), %rax
	movq	16(%rsp), %rcx
	movq	24(%rsp), %rdx
	imulq	$6, %rax, %rax
	addq	$5, %rax
	imulq	$6, %rcx, %rcx
	addq	$5, %rcx
	imulq	$6, %rdx, %rdx
	addq	$5, %rdx
	imulq	$8, %rax, %rax
	movq	(%rsp), %rsi
	addq	%rax, %rsi
	movq	%rsi, 16(%rsp)
	imulq	$8, %rcx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, 8(%rsp)
	imulq	$8, %rdx, %rax
	movq	(%rsp), %rcx
	addq	%rax, %rcx
	movq	%rcx, (%rsp)
	movq	16(%rsp), %rax
	movq	8(%rsp), %rcx
	movq	(%rax), %rax
	movq	(%rcx), %rcx
	movq	$0, %rdx
	movq	$0, %rsi
	addq	%rcx, %rax
	cmovb	%rdi, %rdx
	subq	%rdi, %rax
	cmovb	%rdi, %rsi
	addq	%rsi, %rax
	subq	%rdx, %rax
	movq	(%rsp), %rcx
	movq	%rax, (%rcx)
	movq	24(%rsp), %rax
	incq	%rax
	movq	%r10, %rsp
	ret 
